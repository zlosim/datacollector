{"class":"org.apache.spark.ml.feature.Tokenizer","paramMap":{"inputCol":"text","outputCol":"words"},"sparkVersion":"2.2.0","timestamp":1502235658783,"uid":"tok_7d08e403189d"}