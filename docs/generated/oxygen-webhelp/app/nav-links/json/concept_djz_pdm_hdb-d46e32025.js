define({"topics" : [{"title":"File Name Pattern and Mode","shortdesc":"\n               <p class=\"shortdesc\">Use a file name pattern to define the files that the Hadoop FS Standalone origin         processes. <span class=\"ph\">You can use either a glob pattern or a regular expression to define                 the file name pattern. </span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_exc_22h_ldb","attributes": {"data-id":"concept_exc_22h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_exc_22h_ldb-d46e32212","topics":[]},{"title":"Read Order","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_ogz_q3h_ldb","attributes": {"data-id":"concept_ogz_q3h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_ogz_q3h_ldb-d46e32239","topics":[]},{"title":"Multithreaded Processing","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin uses multiple concurrent threads to process data         based on the Number of Threads property.\n                  \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_fgx_1jh_ldb","attributes": {"data-id":"concept_fgx_1jh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_fgx_1jh_ldb-d46e32271","topics":[]},{"title":"Reading from Subdirectories","shortdesc":"\n               <p class=\"shortdesc\">When using the Last Modified Timestamp read order, the Hadoop FS Standalone origin         can read files in subdirectories\n                  of the specified file directory. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_bwq_nyj_mdb","attributes": {"data-id":"concept_bwq_nyj_mdb",},"menu": {"hasChildren":true,},"tocID":"concept_bwq_nyj_mdb-d46e32316","next":"concept_bwq_nyj_mdb-d46e32316",},{"title":"First File for Processing","shortdesc":"\n               <p class=\"shortdesc\">Configure a first file for processing when you want Hadoop FS Standalone to ignore         one or more existing files in the\n                  directory.\n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_a2q_4kh_ldb","attributes": {"data-id":"concept_a2q_4kh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_a2q_4kh_ldb-d46e32437","topics":[]},{"title":"Reading from Azure HDInsight","shortdesc":"\n               <p class=\"shortdesc\">You can use the HDP stage libraries to access Azure blob storage using the WASB         protocol. This enables the Hadoop\n                  FS Standalone origin to read from Azure HDInsight. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vfk_yrv_ldb","attributes": {"data-id":"concept_vfk_yrv_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vfk_yrv_ldb-d46e32513","topics":[]},{"title":"Record Header Attributes","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin <span class=\"ph\">creates record header                 attributes that include <span class=\"ph\">information about the originating file for                     the record</span>.</span>     \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_asp_lfh_ldb","attributes": {"data-id":"concept_asp_lfh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_asp_lfh_ldb-d46e32599","topics":[]},{"title":"Event Generation","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_zlx_5rh_ldb","attributes": {"data-id":"concept_zlx_5rh_ldb",},"menu": {"hasChildren":true,},"tocID":"concept_zlx_5rh_ldb-d46e32701","next":"concept_zlx_5rh_ldb-d46e32701",},{"title":"Buffer Limit and Error Handling","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin <span class=\"ph\">passes each record to a buffer. The size of the buffer determines                 the maximum size of the record that can\n                     be processed. Decrease the buffer limit when                 memory on the <span class=\"ph\">Data Collector</span>                 machine is limited. Increase the buffer limit to process larger records when memory                 is available.</span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_jbn_md3_ldb","attributes": {"data-id":"concept_jbn_md3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_jbn_md3_ldb-d46e32917","topics":[]},{"title":"Kerberos Authentication","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vvd_4zp_ldb","attributes": {"data-id":"concept_vvd_4zp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vvd_4zp_ldb-d46e33048","topics":[]},{"title":"HDFS Properties and Configuration Files","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_zx5_yzp_ldb","attributes": {"data-id":"concept_zx5_yzp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_zx5_yzp_ldb-d46e33182","topics":[]},{"title":"HDFS User","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_ub1_zwp_ldb","attributes": {"data-id":"concept_ub1_zwp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_ub1_zwp_ldb-d46e33325","topics":[]},{"title":"Data Formats","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vym_zd3_ldb","attributes": {"data-id":"concept_vym_zd3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vym_zd3_ldb-d46e33478","topics":[]},{"title":"Configuring a Hadoop FS Standalone Origin","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#task_l3t_sdm_hdb","attributes": {"data-id":"task_l3t_sdm_hdb",},"menu": {"hasChildren":false,},"tocID":"task_l3t_sdm_hdb-d46e33641","topics":[]}]});