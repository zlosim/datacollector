define({"topics" : [{"title":"File Directory","shortdesc":"\n               <p class=\"shortdesc\"></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_wcp_zxk_1hb","attributes": {"data-id":"concept_wcp_zxk_1hb",},"menu": {"hasChildren":false,},"tocID":"concept_wcp_zxk_1hb-d46e39411","topics":[]},{"title":"File Name Pattern and Mode","shortdesc":"\n               <p class=\"shortdesc\">Use a file name pattern to define the files that the Hadoop FS Standalone origin         processes. <span class=\"ph\">You can use either a glob pattern or a regular expression to define                 the file name pattern. </span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_exc_22h_ldb","attributes": {"data-id":"concept_exc_22h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_exc_22h_ldb-d46e39435","topics":[]},{"title":"Read Order","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_ogz_q3h_ldb","attributes": {"data-id":"concept_ogz_q3h_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_ogz_q3h_ldb-d46e39472","topics":[]},{"title":"Multithreaded Processing","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin uses multiple concurrent threads to process data         based on the Number of Threads property.\n                  \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_fgx_1jh_ldb","attributes": {"data-id":"concept_fgx_1jh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_fgx_1jh_ldb-d46e39514","topics":[]},{"title":"Reading from Subdirectories","shortdesc":"\n               <p class=\"shortdesc\">When using the Last Modified Timestamp read order, the Hadoop FS Standalone origin         can read files in subdirectories\n                  of the specified file directory. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_bwq_nyj_mdb","attributes": {"data-id":"concept_bwq_nyj_mdb",},"menu": {"hasChildren":true,},"tocID":"concept_bwq_nyj_mdb-d46e39569","next":"concept_bwq_nyj_mdb-d46e39569",},{"title":"First File for Processing","shortdesc":"\n               <p class=\"shortdesc\">Configure a first file for processing when you want Hadoop FS Standalone to ignore         one or more existing files in the\n                  directory.\n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_a2q_4kh_ldb","attributes": {"data-id":"concept_a2q_4kh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_a2q_4kh_ldb-d46e39711","topics":[]},{"title":"Reading from Azure Data Lake Storage","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin can read data directly from Azure Data Lake Storage         using the ADL protocol provided\n                  by Hadoop. The origin can connect using Azure Active         Directory Service Principal or refresh-token authentication.\n                  \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_hzz_tjr_1gb","attributes": {"data-id":"concept_hzz_tjr_1gb",},"menu": {"hasChildren":false,},"tocID":"concept_hzz_tjr_1gb-d46e39797","topics":[]},{"title":"Reading from Azure HDInsight","shortdesc":"\n               <p class=\"shortdesc\">You can use the HDP stage libraries to access Azure blob storage using the WASB         protocol. This enables the Hadoop\n                  FS Standalone origin to read from Azure HDInsight. \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vfk_yrv_ldb","attributes": {"data-id":"concept_vfk_yrv_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vfk_yrv_ldb-d46e39893","topics":[]},{"title":"Record Header Attributes","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin <span class=\"ph\">creates record header                 attributes that include <span class=\"ph\">information about the originating file for                     the record</span>.</span>     \n               </p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_asp_lfh_ldb","attributes": {"data-id":"concept_asp_lfh_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_asp_lfh_ldb-d46e39999","topics":[]},{"title":"Event Generation","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_zlx_5rh_ldb","attributes": {"data-id":"concept_zlx_5rh_ldb",},"menu": {"hasChildren":true,},"tocID":"concept_zlx_5rh_ldb-d46e40121","next":"concept_zlx_5rh_ldb-d46e40121",},{"title":"Buffer Limit and Error Handling","shortdesc":"\n               <p class=\"shortdesc\">The Hadoop FS Standalone origin <span class=\"ph\">passes each record to a buffer. The size of the buffer determines                 the maximum size of the record that can\n                     be processed. Decrease the buffer limit when                 memory on the <span class=\"ph\">Data Collector</span>                 machine is limited. Increase the buffer limit to process larger records when memory                 is available.</span></p>\n            ","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_jbn_md3_ldb","attributes": {"data-id":"concept_jbn_md3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_jbn_md3_ldb-d46e40378","topics":[]},{"title":"Kerberos Authentication","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vvd_4zp_ldb","attributes": {"data-id":"concept_vvd_4zp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vvd_4zp_ldb-d46e40529","topics":[]},{"title":"HDFS Properties and Configuration Files","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_zx5_yzp_ldb","attributes": {"data-id":"concept_zx5_yzp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_zx5_yzp_ldb-d46e40682","topics":[]},{"title":"HDFS User","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_ub1_zwp_ldb","attributes": {"data-id":"concept_ub1_zwp_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_ub1_zwp_ldb-d46e40845","topics":[]},{"title":"Data Formats","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#concept_vym_zd3_ldb","attributes": {"data-id":"concept_vym_zd3_ldb",},"menu": {"hasChildren":false,},"tocID":"concept_vym_zd3_ldb-d46e41018","topics":[]},{"title":"Configuring a Hadoop FS Standalone Origin","href":"datacollector\/UserGuide\/Origins\/HDFSStandalone.html#task_l3t_sdm_hdb","attributes": {"data-id":"task_l3t_sdm_hdb",},"menu": {"hasChildren":false,},"tocID":"task_l3t_sdm_hdb-d46e41201","topics":[]}]});