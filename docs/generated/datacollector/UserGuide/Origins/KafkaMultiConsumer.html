
<!DOCTYPE html
  PUBLIC "" "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:whc="http://www.oxygenxml.com/webhelp/components" xml:lang="en-us" lang="en-us">
    <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="shortcut icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><link rel="icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><meta name="description" content="The Kafka Multitopic Consumer origin reads data from multiple topics in an Apache Kafka cluster. The origin can use multiple threads to enable parallel processing of data. When preferred, you can use ..." /><meta name="copyright" content="(C) Copyright 2018" /><meta name="DC.rights.owner" content="(C) Copyright 2018" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Kafka Multitopic Consumer" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/Origins_title.html" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/KConsumer.html#concept_msz_wnr_5q" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Origins/KinConsumer.html#concept_anh_4y3_yr" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="DC.Date.Created" content="2014-10-31" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_ccs_fn4_x1b" /><title>Kafka Multitopic Consumer</title><!--  Generated with Oxygen version 20.0-SNAPSHOT, build number 2018042310.  --><meta name="wh-path2root" content="../../../" /><meta name="wh-toc-id" content="concept_ccs_fn4_x1b-d46e45936" />         
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- Latest compiled and minified Bootstrap CSS -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap.min.css" />

        <!-- Bootstrap Optional theme -->
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap-theme.min.css" />
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/jquery-ui/jquery-ui.min.css" />

        <!-- Template default styles  -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/app/topic-page.css?buildId=2018042310" />
        

        <script type="text/javascript" src="../../../oxygen-webhelp/lib/jquery/jquery-3.1.1.min.js"><!----></script>

        <script data-main="../../../oxygen-webhelp/app/topic-page.js" src="../../../oxygen-webhelp/lib/requirejs/require.js"></script>
        
        <!-- Skin resources -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/template/light.css?buildId=2018042310" />
        <!-- EXM-36950 - Expand the args.hdf parameter here -->
        
        
    <link rel="stylesheet" type="text/css" href="../../../skin.css" /></head>

    <body class="wh_topic_page frmBody">
        <!-- EXM-36950 - Expand the args.hdr parameter here -->
        
        
        
<nav class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div class="wh_header_flex_container">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <!--
                            This component will be generated when the next parameters are specified in the transformation scenario:
                            'webhelp.logo.image' and 'webhelp.logo.image.target.url'.
                            See: http://oxygenxml.com/doc/versions/17.1/ug-editor/#topics/dita_webhelp_output.html.
                    -->
                    <a href="../../../index.html" class=" wh_logo hidden-xs "></a>
                    <div class=" wh_publication_title "><a href="../../../index.html"><span class="booktitle">  <span class="ph mainbooktitle"><span class="ph">Data Collector</span> User Guide</span>  </span></a></div>
                    
                </div>
                
                <!-- The menu button for mobile devices is copied in the output only when the 'webhelp.show.top.menu' parameter is set to 'yes' -->
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse">
                
                
                <div class=" wh_indexterms_link "><a href="../../../indexTerms.html" title="Index"><span>Index</span></a></div>
                
            </div>
        </div>
    </div>
</nav>

        <div class=" wh_search_input "><form id="searchForm" method="get" action="../../../search.html"><div><input type="search" placeholder="Search " class="wh_search_textfield" id="textToSearch" name="searchQuery" /><button type="submit" class="wh_search_button"><span>Search</span></button></div><script><!--
                                    $(document).ready(function () {
                                        $('#searchForm').submit(function (e) {
                                            if ($('.wh_search_textfield').val().length < 1) {
                                                e.preventDefault();
                                            }
                                        });
                                    });
                                --></script></form></div>
        
        <div class="container-fluid">
            <div class="row">

                <nav class="wh_tools hidden-print">
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol xmlns:html="http://www.w3.org/1999/xhtml" class="hidden-print"><li><span class="home"><a href="../../../index.html"><span>Home</span></a></span></li>
   <li><span class="topicref" data-id="concept_yjl_nc5_jq"><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span></li>
   <li class="active"><span class="topicref" data-id="concept_ccs_fn4_x1b"><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_ccs_fn4_x1b">Kafka Multitopic Consumer</a></span></span></li>
</ol></div>

                    <div class="wh_right_tools hidden-sm hidden-xs">
                        <div class=" wh_navigation_links "><span id="topic_navigation_links" class="navheader">
  
<span class="navprev"><a class="link" href="../../../datacollector/UserGuide/Origins/KConsumer.html#concept_msz_wnr_5q" title="Kafka Consumer"></a></span>  
<span class="navnext"><a class="link" href="../../../datacollector/UserGuide/Origins/KinConsumer.html#concept_anh_4y3_yr" title="Kinesis Consumer"></a></span>  </span></div>
                        <button class="wh_hide_highlight" title="Toggle search highlights"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" title="Collapse sections"></button>
                        <div class=" wh_print_link print "><a href="javascript:window.print();" title="Print this page"></a></div>
                    </div>
                </nav>
            </div>

            <div class="wh_content_area">
                <div class="row">
                    
                        <nav role="navigation" id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-3 hidden-xs navbar hidden-print">
                            <div class=" wh_publication_toc " data-tooltip-position="right"><ul>
   <li><span data-tocid="concept_htw_ghg_jq-d46e54" class="topicref" data-id="concept_htw_ghg_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Getting_Started/GettingStarted_Title.html#concept_htw_ghg_jq">Getting Started</a></span></span></li>
   <li><span data-tocid="concept_hz3_5fk_fy-d46e804" class="topicref" data-id="concept_hz3_5fk_fy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/WhatsNew/WhatsNew_Title.html#concept_hz3_5fk_fy">What's New</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_l4q_flb_kr-d46e5240" class="topicref" data-id="concept_l4q_flb_kr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Installation/Install_title.html">Installation</a></span></span></li>
   <li><span data-tocid="concept_ylh_yyz_ky-d46e7307" class="topicref" data-id="concept_ylh_yyz_ky" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Configuration/Config_title.html">Configuration</a></span></span></li>
   <li><span data-tocid="concept_ejk_f1f_5v-d46e15527" class="topicref" data-id="concept_ejk_f1f_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Upgrade/Upgrade_title.html">Upgrade</a></span></span></li>
   <li><span data-tocid="concept_qsw_cjy_bt-d46e20362" class="topicref" data-id="concept_qsw_cjy_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Design/PipelineDesign_title.html">Pipeline Concepts and Design</a></span></span></li>
   <li><span data-tocid="concept_qn1_wn4_kq-d46e22042" class="topicref" data-id="concept_qn1_wn4_kq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Configuration/PipelineConfiguration_title.html">Pipeline Configuration</a></span></span></li>
   <li><span data-tocid="concept_hdr_gyw_41b-d46e24539" class="topicref" data-id="concept_hdr_gyw_41b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Formats/DataFormats-Title.html">Data Formats</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e26354" class="topicref" data-id="concept_yjl_nc5_jq" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span><ul class="nav nav-list">
         <li><span data-tocid="concept_hpr_twm_jq-d46e26376" class="topicref" data-id="concept_hpr_twm_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_overview.html#concept_hpr_twm_jq">Origins</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">An origin stage represents the source for the pipeline. You can use a single origin     stage in a pipeline.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kvs_3hh_ht-d46e26946" class="topicref" data-id="concept_kvs_3hh_ht" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AmazonS3.html#concept_kvs_3hh_ht">Amazon S3</a></span></span></li>
         <li><span data-tocid="concept_xsh_knm_5bb-d46e27886" class="topicref" data-id="concept_xsh_knm_5bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AmazonSQS.html#concept_xsh_knm_5bb">Amazon SQS Consumer</a></span></span></li>
         <li><span data-tocid="concept_c1z_15q_1bb-d46e28350" class="topicref" data-id="concept_c1z_15q_1bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/AzureEventHub.html#concept_c1z_15q_1bb">Azure IoT/Event Hub Consumer</a></span></span></li>
         <li><span data-tocid="concept_wfy_ghn_sz-d46e28632" class="topicref" data-id="concept_wfy_ghn_sz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/CoAPServer.html#concept_wfy_ghn_sz">CoAP Server</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">Constrained Application Protocol (CoAP) is a web transfer protocol designed for         machine-to-machine devices. The CoAP
                        Server origin is a multithreaded origin that listens on         a CoAP endpoint and processes the contents of all authorized
                        CoAP requests. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_qcq_54n_jq-d46e28927" class="topicref" data-id="concept_qcq_54n_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Directory.html#concept_qcq_54n_jq">Directory</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Directory origin reads data from files in a directory. The origin can use         multiple threads to enable the parallel
                        processing of files. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_f1q_vpm_2z-d46e30199" class="topicref" data-id="concept_f1q_vpm_2z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Elasticsearch.html#concept_f1q_vpm_2z">Elasticsearch </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Elasticsearch origin is a multithreaded origin that reads data from an Elasticsearch         cluster, including Elastic
                        Cloud clusters (formerly Found clusters). The origin generates a         record for each Elasticsearch document.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_n1y_qyp_5q-d46e30583" class="topicref" data-id="concept_n1y_qyp_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/FileTail.html#concept_n1y_qyp_5q">File Tail</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The File Tail origin reads lines of data as they are written to an active file after         reading related archived files
                        in the same directory. File Tail generates a record for each         line of data.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_cg3_y3v_q1b-d46e31832" class="topicref" data-id="concept_cg3_y3v_q1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/BigQuery.html#concept_cg3_y3v_q1b">Google BigQuery</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Google BigQuery origin executes a query job and reads the result from Google         BigQuery. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_iyd_wql_nbb-d46e32302" class="topicref" data-id="concept_iyd_wql_nbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/GCS.html#concept_iyd_wql_nbb">Google Cloud Storage</a></span></span></li>
         <li><span data-tocid="concept_pjw_qtl_r1b-d46e32864" class="topicref" data-id="concept_pjw_qtl_r1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PubSub.html#concept_pjw_qtl_r1b">Google Pub/Sub Subscriber</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Google Pub/Sub Subscriber origin consumes messages from a Google Pub/Sub         subscription. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_lw2_tnm_vs-d46e33334" class="topicref" data-id="concept_lw2_tnm_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HadoopFS-origin.html#concept_lw2_tnm_vs">Hadoop FS</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS), Amazon     S3, or other file systems using
                        the Hadoop FileSystem interface. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_djz_pdm_hdb-d46e33913" class="topicref" data-id="concept_djz_pdm_hdb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HDFSStandalone.html#concept_djz_pdm_hdb">Hadoop FS Standalone</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hadoop FS Standalone origin reads files in HDFS. The origin can use multiple         threads to enable the parallel processing
                        of files. The files to be processed must all share         a file name pattern and be fully written. You can also configure
                        the origin to read from         Azure HDInsight.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_wk4_bjz_5r-d46e35702" class="topicref" data-id="concept_wk4_bjz_5r" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPClient.html#concept_wk4_bjz_5r">HTTP Client</a></span></span></li>
         <li><span data-tocid="concept_s2p_5hb_4y-d46e38100" class="topicref" data-id="concept_s2p_5hb_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPServer.html#concept_s2p_5hb_4y">HTTP Server</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The HTTP Server origin is a multithreaded origin that listens on an HTTP endpoint and         processes the contents of all
                        authorized HTTP POST and PUT requests. Use the HTTP Server         origin to read high volumes of HTTP POST and PUT requests
                        using multiple threads. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_izh_mqd_dy-d46e38567" class="topicref" data-id="concept_izh_mqd_dy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/HTTPtoKafka.html#concept_izh_mqd_dy">HTTP to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_zp3_wnw_4y-d46e39128" class="topicref" data-id="concept_zp3_wnw_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MultiTableJDBCConsumer.html#concept_zp3_wnw_4y">JDBC Multitable Consumer</a></span></span></li>
         <li><span data-tocid="concept_qhf_hjr_bs-d46e42994" class="topicref" data-id="concept_qhf_hjr_bs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JDBCConsumer.html#concept_qhf_hjr_bs">JDBC Query Consumer</a></span></span></li>
         <li><span data-tocid="concept_rhh_4nj_dt-d46e44756" class="topicref" data-id="concept_rhh_4nj_dt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/JMS.html#concept_rhh_4nj_dt">JMS Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The JMS Consumer origin reads data from a Java Messaging Service (JMS). </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_msz_wnr_5q-d46e45127" class="topicref" data-id="concept_msz_wnr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KConsumer.html#concept_msz_wnr_5q">Kafka Consumer</a></span></span></li>
         <li class="active"><span data-tocid="concept_ccs_fn4_x1b-d46e45936" class="topicref" data-id="concept_ccs_fn4_x1b" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_ccs_fn4_x1b">Kafka Multitopic Consumer</a></span></span><ul class="nav nav-list">
               <li><span data-tocid="concept_zlc_ppn_js-d46e46069" class="topicref" data-id="concept_zlc_ppn_js" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_zlc_ppn_js">Offset Management</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The first time that a Kafka Multitopic Consumer origin identified by a consumer group     receives messages from a topic,
                              an offset entry is created for that consumer group and topic.     The offset entry is created in Kafka.
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_ifs_wtm_3z-d46e46129" class="topicref" data-id="concept_ifs_wtm_3z" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_ifs_wtm_3z">Multithreaded Processing</a></span></span></li>
               <li><span data-tocid="concept_d5f_n2g_vq-d46e46171" class="topicref" data-id="concept_d5f_n2g_vq" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_d5f_n2g_vq">Additional Kafka Properties</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">You can add custom Kafka configuration properties to the Kafka Multitopic         Consumer.</p>
                           </span></span></span></li>
               <li><span data-tocid="concept_tlj_3g1_2z-d46e46226" class="topicref" data-id="concept_tlj_3g1_2z" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_tlj_3g1_2z">Record Header Attributes</a></span></span></li>
               <li><span data-tocid="concept_yg3_k31_t5-d46e46288" class="topicref" data-id="concept_yg3_k31_t5" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_yg3_k31_t5">Enabling Security</a></span></span></li>
               <li><span data-tocid="concept_xgs_nlc_wr-d46e46639" class="topicref" data-id="concept_xgs_nlc_wr" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#concept_xgs_nlc_wr">Data Formats</a></span></span></li>
               <li><span data-tocid="task_ost_3n4_x1b-d46e46752" class="topicref" data-id="task_ost_3n4_x1b" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KafkaMultiConsumer.html#task_ost_3n4_x1b">Configuring a Kafka Multitopic Consumer</a></span></span></li>
            </ul>
         </li>
         <li><span data-tocid="concept_anh_4y3_yr-d46e46876" class="topicref" data-id="concept_anh_4y3_yr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/KinConsumer.html#concept_anh_4y3_yr">Kinesis Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Kinesis Consumer origin reads data from Amazon Kinesis Streams. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_qwj_5vm_pbb-d46e47349" class="topicref" data-id="concept_qwj_5vm_pbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRdbCDC.html#concept_qwj_5vm_pbb">MapR DB CDC</a></span></span></li>
         <li><span data-tocid="concept_ywh_k15_3y-d46e47631" class="topicref" data-id="concept_ywh_k15_3y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRDBJSON.html#concept_ywh_k15_3y">MapR DB JSON</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR DB JSON origin reads JSON documents from MapR DB JSON tables. The origin         converts each document into a record.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_psz_db4_lx-d46e47733" class="topicref" data-id="concept_psz_db4_lx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRFS.html#concept_psz_db4_lx">MapR FS</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR FS origin reads files from MapR FS. Use this origin only in pipelines         configured for cluster batch pipeline
                        execution mode. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_b43_3qc_mdb-d46e48119" class="topicref" data-id="concept_b43_3qc_mdb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRFSStandalone.html#concept_b43_3qc_mdb">MapR FS Standalone</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR FS Standalone origin reads files in MapR. The origin can use multiple         threads to enable the parallel processing
                        of files. The files to be processed must all share         a file name pattern and be fully written. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hvd_hww_lbb-d46e49732" class="topicref" data-id="concept_hvd_hww_lbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRStreamsMultiConsumer.html#concept_hvd_hww_lbb">MapR Multitopic Streams Consumer</a></span></span></li>
         <li><span data-tocid="concept_cvy_xsf_2v-d46e50193" class="topicref" data-id="concept_cvy_xsf_2v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MapRStreamsCons.html#concept_cvy_xsf_2v">MapR Streams Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR Streams Consumer origin reads messages from MapR Streams.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_bk4_2rs_ns-d46e50485" class="topicref" data-id="concept_bk4_2rs_ns" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MongoDB.html#concept_bk4_2rs_ns">MongoDB</a></span></span></li>
         <li><span data-tocid="concept_mjn_yqw_4y-d46e51046" class="topicref" data-id="concept_mjn_yqw_4y" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MongoDBOplog.html#concept_mjn_yqw_4y">MongoDB Oplog</a></span></span></li>
         <li><span data-tocid="concept_ukz_3vt_lz-d46e51504" class="topicref" data-id="concept_ukz_3vt_lz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MQTTSubscriber.html#concept_ukz_3vt_lz">MQTT Subscriber</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MQTT Subscriber origin subscribes to topics on an MQTT broker to read messages         from the broker. The origin functions
                        as an MQTT client that receives messages, generating a         record for each message.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kqg_1yh_xx-d46e51723" class="topicref" data-id="concept_kqg_1yh_xx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/MySQLBinaryLog.html#concept_kqg_1yh_xx">MySQL Binary Log</a></span></span></li>
         <li><span data-tocid="concept_dsr_xmw_1s-d46e52294" class="topicref" data-id="concept_dsr_xmw_1s" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Omniture.html#concept_dsr_xmw_1s">Omniture</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Omniture origin processes JSON website usage reports generated by the Omniture   reporting APIs. Omniture is also known
                        as the Adobe Marketing Cloud.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_nmf_1ly_f1b-d46e52351" class="topicref" data-id="concept_nmf_1ly_f1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/OPCUAClient.html#concept_nmf_1ly_f1b">OPC UA Client </a></span></span></li>
         <li><span data-tocid="concept_rs5_hjj_tw-d46e52563" class="topicref" data-id="concept_rs5_hjj_tw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/OracleCDC.html#concept_rs5_hjj_tw">Oracle CDC Client</a></span></span></li>
         <li><span data-tocid="concept_cfs_4m4_n2b-d46e56705" class="topicref" data-id="concept_cfs_4m4_n2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PostgreSQL.html#concept_cfs_4m4_n2b">PostgreSQL CDC Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The PostgreSQL CDC Client origin processes Write-Ahead Logging (WAL) data to generate         change data capture records
                        for a PostgreSQL database. Use the PostgreSQL CDC Client origin         to process WAL data from PostgreSQL 9.4 or later.
                        Earlier versions do not support         WAL.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_o2b_1pc_r2b-d46e57174" class="topicref" data-id="concept_o2b_1pc_r2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/PulsarConsumer.html#concept_o2b_1pc_r2b">Pulsar Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Pulsar Consumer origin reads messages from one or more topics in an Apache Pulsar         cluster.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_dyg_lq1_h5-d46e57651" class="topicref" data-id="concept_dyg_lq1_h5" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/RabbitMQ.html#concept_dyg_lq1_h5">RabbitMQ Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">RabbitMQ Consumer reads AMQP messages from a single RabbitMQ queue.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_plr_t3v_jw-d46e57871" class="topicref" data-id="concept_plr_t3v_jw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Redis.html#concept_plr_t3v_jw">Redis Consumer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Redis Consumer origin reads messages from Redis. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hfg_2sn_p2b-d46e58025" class="topicref" data-id="concept_hfg_2sn_p2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/RESTService.html#concept_hfg_2sn_p2b">REST Service </a></span></span></li>
         <li><span data-tocid="concept_odf_vr3_rx-d46e58592" class="topicref" data-id="concept_odf_vr3_rx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Salesforce.html#concept_odf_vr3_rx">Salesforce</a></span></span></li>
         <li><span data-tocid="concept_agb_5c1_ct-d46e61190" class="topicref" data-id="concept_agb_5c1_ct" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SDC_RPCorigin.html#concept_agb_5c1_ct">SDC RPC </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"> The SDC RPC origin enables connectivity between two SDC RPC pipelines. The SDC RPC     origin reads data passed from an SDC
                        RPC destination. Use the SDC RPC origin as part of an SDC     RPC destination pipeline.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_tdk_slk_pw-d46e61247" class="topicref" data-id="concept_tdk_slk_pw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SDCRPCtoKafka.html#concept_tdk_slk_pw">SDC RPC to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_ic5_bzd_5v-d46e61928" class="topicref" data-id="concept_ic5_bzd_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SFTP.html#concept_ic5_bzd_5v">SFTP/FTP Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The SFTP/FTP Client origin reads files from a server using the Secure File Transfer         Protocol (SFTP) or the File Transfer
                        Protocol (FTP). 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ut3_ywc_v1b-d46e62495" class="topicref" data-id="concept_ut3_ywc_v1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SQLServerCDC.html#concept_ut3_ywc_v1b">SQL Server CDC Client</a></span></span></li>
         <li><span data-tocid="concept_ewq_b2s_r1b-d46e63889" class="topicref" data-id="concept_ewq_b2s_r1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SQLServerChange.html#concept_ewq_b2s_r1b">SQL Server Change Tracking</a></span></span></li>
         <li><span data-tocid="concept_gzy_gmv_32b-d46e64966" class="topicref" data-id="concept_gzy_gmv_32b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/SystemMetrics.html#concept_gzy_gmv_32b">System Metrics</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The System Metrics origin reads system metrics from the edge device where <span class="ph">StreamSets</span>         <span class="ph">Data Collector Edge</span>             (<span class="ph">SDC Edge</span>)         is installed. Use the System Metrics origin only in pipelines configured for edge execution         mode. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ppm_xb1_4z-d46e65132" class="topicref" data-id="concept_ppm_xb1_4z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/TCPServer.html#concept_ppm_xb1_4z">TCP Server</a></span></span></li>
         <li><span data-tocid="concept_wng_g5f_5bb-d46e65590" class="topicref" data-id="concept_wng_g5f_5bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDPMulti.html#concept_wng_g5f_5bb">UDP Multithreaded Source</a></span></span></li>
         <li><span data-tocid="concept_rst_2y5_1s-d46e65955" class="topicref" data-id="concept_rst_2y5_1s" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDP.html#concept_rst_2y5_1s">UDP Source</a></span></span></li>
         <li><span data-tocid="concept_jzq_jcz_pw-d46e66103" class="topicref" data-id="concept_jzq_jcz_pw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/UDPtoKafka.html#concept_jzq_jcz_pw">UDP to Kafka (Deprecated)</a></span></span></li>
         <li><span data-tocid="concept_unk_nzk_fbb-d46e66564" class="topicref" data-id="concept_unk_nzk_fbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WebSocketClient.html#concept_unk_nzk_fbb">WebSocket Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The WebSocket Client origin reads data from a WebSocket server endpoint. Use the origin         to read data from a WebSocket
                        resource URL. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_u2r_gpc_3z-d46e66717" class="topicref" data-id="concept_u2r_gpc_3z" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WebSocketServer.html#concept_u2r_gpc_3z">WebSocket Server</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The WebSocket Server origin is a multithreaded origin that listens on a WebSocket         endpoint and processes the contents
                        of all authorized WebSocket client requests. Use the         WebSocket Server origin to read high volumes of WebSocket client
                        requests using multiple         threads. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_agf_5jv_sbb-d46e67094" class="topicref" data-id="concept_agf_5jv_sbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/WindowsLog.html#concept_agf_5jv_sbb">Windows Event Log</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Windows Event Log origin reads data from a Microsoft Windows event log located on a         Windows machine. The origin
                        generates a record for each event in the log. 
                        
                     </p>
                     </span></span></span></li>
      </ul>
   </li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e67152" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Processors/Processors_title.html">Processors</a></span></span></li>
   <li><span data-tocid="concept_agj_cfj_br-d46e82708" class="topicref" data-id="concept_agj_cfj_br" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations-title.html">Destinations</a></span></span></li>
   <li><span data-tocid="concept_umc_1lk_fx-d46e98685" class="topicref" data-id="concept_umc_1lk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-title.html">Executors</a></span></span></li>
   <li><span data-tocid="concept_fyf_gkq_4bb-d46e104447" class="topicref" data-id="concept_fyf_gkq_4bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Edge_Mode/EdgePipelines_title.html"><span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">StreamSets Data Collector Edge</span></a></span></span></li>
   <li><span data-tocid="concept_ugp_kwf_xw-d46e107046" class="topicref" data-id="concept_ugp_kwf_xw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM_title.html">StreamSets Control Hub</a></span></span></li>
   <li><span data-tocid="concept_xxd_f5r_kx-d46e110447" class="topicref" data-id="concept_xxd_f5r_kx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Event_Handling/EventFramework-Title.html#concept_xxd_f5r_kx">Dataflow Triggers</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fjj_zcf_2w-d46e114361" class="topicref" data-id="concept_fjj_zcf_2w" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w">Drift Synchronization Solution for Hive</a></span></span></li>
   <li><span data-tocid="concept_kgt_pnr_4cb-d46e117187" class="topicref" data-id="concept_kgt_pnr_4cb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/JDBC_DriftSolution/JDBC_DriftSyncSolution_title.html#concept_kgt_pnr_4cb">Drift Synchronization Solution for PostgreSQL</a></span></span></li>
   <li><span data-tocid="concept_wwq_gxc_py-d46e117986" class="topicref" data-id="concept_wwq_gxc_py" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wwq_gxc_py">Multithreaded Pipelines</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_gzw_tdm_p2b-d46e118568" class="topicref" data-id="concept_gzw_tdm_p2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Microservice/Microservice_Title.html#concept_gzw_tdm_p2b">Microservice Pipelines</a></span></span></li>
   <li><span data-tocid="concept_wr1_ktz_bt-d46e118790" class="topicref" data-id="concept_wr1_ktz_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/RPC_Pipelines/SDC_RPCpipelines_title.html#concept_wr1_ktz_bt">SDC RPC Pipelines</a></span></span></li>
   <li><span data-tocid="concept_fpz_5r4_vs-d46e119272" class="topicref" data-id="concept_fpz_5r4_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Cluster_Mode/ClusterPipelines_title.html">Cluster Pipelines</a></span></span></li>
   <li><span data-tocid="concept_jjk_23z_sq-d46e120619" class="topicref" data-id="concept_jjk_23z_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Preview/DataPreview_Title.html#concept_jjk_23z_sq">Data Preview</a></span></span></li>
   <li><span data-tocid="concept_pgk_brx_rr-d46e121588" class="topicref" data-id="concept_pgk_brx_rr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Alerts/RulesAlerts_title.html#concept_pgk_brx_rr">Rules and Alerts</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_asx_fdz_sq-d46e124216" class="topicref" data-id="concept_asx_fdz_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Monitoring/PipelineMonitoring_title.html#concept_asx_fdz_sq">Pipeline Monitoring</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_o3l_dtr_5q-d46e125473" class="topicref" data-id="concept_o3l_dtr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Maintenance/PipelineMaintenance_title.html#concept_o3l_dtr_5q">Pipeline Maintenance</a></span></span></li>
   <li><span data-tocid="concept_yms_ftm_sq-d46e127459" class="topicref" data-id="concept_yms_ftm_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Administration/Administration_title.html#concept_yms_ftm_sq">Administration</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_nls_w1r_ks-d46e131956" class="topicref" data-id="concept_nls_w1r_ks" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Tutorial/Tutorial-title.html">Tutorial</a></span></span></li>
   <li><span data-tocid="concept_sh3_frm_tq-d46e133169" class="topicref" data-id="concept_sh3_frm_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Troubleshooting/Troubleshooting_title.html#concept_sh3_frm_tq">Troubleshooting</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_xbx_rs1_tq-d46e137661" class="topicref" data-id="concept_xbx_rs1_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Glossary/Glossary_title.html#concept_xbx_rs1_tq">Glossary</a></span></span></li>
   <li><span data-tocid="concept_jn1_nzb_kv-d46e137716" class="topicref" data-id="concept_jn1_nzb_kv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-DataFormats/DataFormat_Title.html#concept_jn1_nzb_kv">Data Formats by Stage</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_pvm_yt3_wq-d46e137876" class="topicref" data-id="concept_pvm_yt3_wq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Expression_Language/ExpressionLanguage_title.html">Expression Language</a></span></span></li>
   <li><span data-tocid="concept_vcj_1ws_js-d46e140301" class="topicref" data-id="concept_vcj_1ws_js" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-RegEx/RegEx-Title.html#concept_vcj_1ws_js">Regular Expressions</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_chv_vmj_wr-d46e140524" class="topicref" data-id="concept_chv_vmj_wr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-GrokPatterns/GrokPatterns_title.html#concept_chv_vmj_wr">Grok Patterns</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
</ul></div>
                        </nav>
                    
                    
                    <div class="col-lg-9 col-md-9 col-sm-9 col-xs-12" id="wh_topic_body">
                        <div class=" wh_topic_content body "><main role="main"><article role="article" aria-labelledby="ariaid-title1"><article class="nested0" aria-labelledby="ariaid-title1" id="concept_ccs_fn4_x1b">
 <h1 class="title topictitle1" id="ariaid-title1">Kafka Multitopic Consumer</h1>

 <div class="body conbody">
  <p class="p">The Kafka
            Multitopic Consumer origin reads data from multiple topics in an Apache Kafka cluster.
            The origin can use multiple threads to enable parallel processing of data. When
            preferred, you can use the <a class="xref" href="KConsumer.html#concept_msz_wnr_5q">Kafka
                Consumer</a> to read from a single topic using a single thread. </p>

        <p class="p">When you configure a Kafka Multitopic Consumer, you configure the consumer group name and
            the brokers to use. You also specify the topics to process and the number of threads to
            use. In Kafka, make sure that the <a class="xref" href="KafkaMultiConsumer.html#concept_ifs_wtm_3z">partition
                assignment strategy</a> is configured appropriately. </p>

        <p class="p">You can configure the origin to produce a single record when a message includes multiple
            objects. And you can add additional Kafka configuration properties as needed, including
            Kafka security features.</p>

        <p class="p">When processing Avro data, you can configure the Kafka Multitopic Consumer to work with
            the Confluent Schema Registry. The Confluent Schema Registry is a distributed storage
            layer for Avro schemas which uses Kafka as its underlying storage mechanism.</p>

        <p class="p">Kafka Multitopic Consumer includes record header attributes that enable you to use
            information about the record in pipeline processing. </p>

 </div>

<article class="topic concept nested1" aria-labelledby="ariaid-title2" id="concept_zlc_ppn_js">
 <h2 class="title topictitle2" id="ariaid-title2">Offset Management</h2>

  
 <div class="body conbody"><p class="shortdesc">The first time that a Kafka Multitopic Consumer origin identified by a consumer group
    receives messages from a topic, an offset entry is created for that consumer group and topic.
    The offset entry is created in Kafka.</p>

  <div class="p">The Kafka
      Multitopic Consumer origin begins receiving messages in the topic based on whether or not a
      stored offset entry exists: <dl class="dl">
        
          <dt class="dt dlterm">No stored offset</dt>

          <dd class="dd">When the consumer group and topic combination does not have a previously stored
            offset, the Kafka Multitopic Consumer origin by default receives messages sent to the
            topic after the pipeline starts, processing data from all partitions and ignoring any
            existing messages in the topic.</dd>

          <dd class="dd ddexpand">However, you can set an initial offset for the consumer group so that the origin reads
            the topic from the beginning, as described in <a class="xref" href="KafkaMultiConsumer.html#concept_hdc_fvn_sx" title="You can set an initial offset for the consumer group so that the Kafka Multitopic Consumer origin reads the topic from the beginning.">Setting the Initial Offset</a>.</dd>

        
      </dl>
<dl class="dl">
        
          <dt class="dt dlterm">Previously stored offset</dt>

          <dd class="dd">When the consumer group and topic combination has a previously stored offset, the
            Kafka Multitopic Consumer origin receives messages starting with the next unprocessed
            message after the stored offset. For example, when you stop and restart the pipeline,
            processing resumes from the last committed offset. </dd>

        
      </dl>
</div>

 </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title3" id="concept_hdc_fvn_sx">
    <h3 class="title topictitle3" id="ariaid-title3">Setting the Initial Offset</h3>

    
    <div class="body conbody"><p class="shortdesc">You can set an initial offset for the consumer group so that the Kafka Multitopic
        Consumer origin reads the topic from the beginning.</p>

        <p class="p">By default when the
            consumer group and topic combination does not have a previously stored offset, the Kafka
            Multitopic Consumer origin reads only messages received after the pipeline starts. </p>

        <div class="p">To read the topic from the beginning, add the auto.offset.reset Kafka configuration
            property to the origin:<ol class="ol" id="concept_hdc_fvn_sx__ol_n4r_rvn_sx">
                <li class="li">On the <span class="keyword wintitle">Connection</span> tab, click the <span class="ph uicontrol">Add</span>
                    icon to add a new Kafka configuration property.<p class="p">You can use <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a> to add configuration
                    properties.</p>
</li>

                <li class="li">For the property name, enter <span class="ph uicontrol">auto.offset.reset</span>.</li>

                <li class="li">Set the value for the auto.offset.reset property to
                        <span class="ph uicontrol">earliest</span>.</li>

            </ol>
</div>

        <p class="p">For more information about auto.offset.reset, see the Apache Kafka documentation. For
            more information about adding custom Kafka configuration properties, see <a class="xref" href="KConsumer.html#concept_d5f_n2g_vq" title="You can add custom Kafka configuration properties to the Kafka Consumer.">Additional Kafka Properties</a>.</p>

    </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title4" id="concept_ifs_wtm_3z">
 <h2 class="title topictitle2" id="ariaid-title4">Multithreaded Processing</h2>

 <div class="body conbody">
  <p class="p">The Kafka Multitopic Consumer
            origin performs parallel processing and enables the creation of a multithreaded
            pipeline. The Kafka Multitopic Consumer origin uses multiple concurrent threads based on
            the Number of Threads property and the partition assignment strategy defined in the
            Kafka cluster. </p>

        <div class="p">
            <div class="note important"><span class="importanttitle">Important:</span> In Kafka, make sure that the partition assignment strategy is set
                to the strategy you want to use. For example, in Kafka 0.10.1, you can set
                partition.assignment.strategy property to range or roundrobin. For more information
                about the strategies, see <a class="xref" href="https://kafka.apache.org/documentation/" target="_blank">the Kafka documentation</a>.</div>

        </div>

        <p class="p">When performing multithreaded processing, the Kafka Multitopic Consumer origin checks the
            list of topics to process and creates the specified number of threads. Each thread
            connects to Kafka and creates a batch of data from a partition assigned by the broker
            based on the Kafka partition assignment strategy. Then, it passes the batch to an
            available pipeline runner. </p>

        <p class="p"><span class="ph">A pipeline runner is a <dfn class="term">sourceless
                              pipeline instance</dfn> - an instance of the pipeline that includes
                        all of the processors and destinations in the pipeline and represents all
                        pipeline processing after the origin.</span>
            <span class="ph"> Each pipeline runner processes one batch at a time,
                        just like a pipeline that runs on a single thread. When the flow of data
                        slows, the pipeline runners wait idly until they are needed, generating an
                        empty batch at regular intervals. You can configure the Runner Idle Time
                        pipeline property specify the interval or to opt out of empty batch
                        generation.</span></p>

        <p class="p"><span class="ph">Multithreaded pipelines preserve the order of
                        records within each batch, just like a single-threaded pipeline. But since
                        batches are processed by different pipeline instances, the order that
                        batches are written to destinations is not ensured.</span></p>

        <p class="p">For example, say you set the Number of Threads property to 5. When you start the
            pipeline, <span class="ph">the origin creates five
                              threads, and <span class="ph">Data Collector</span>
                              creates a matching number of pipeline runners.</span> The threads are assigned to different partitions based on the Kafka partition
            assignment strategy. <span class="ph">Upon receiving data, the origin passes a batch to
                              each of the pipeline runners for processing.</span></p>

        <p class="p">At any given moment, the five pipeline runners can each
                  process a batch, so this multithreaded pipeline processes up to five batches at a
                  time. When incoming data slows, the pipeline runners sit idle, available for use
                  as soon as the data flow increases.</p>

        <p class="p">For more information about multithreaded pipelines, see <a class="xref" href="../Multithreaded_Pipelines/MultithreadedPipelines.html#concept_zpp_2xc_py">Multithreaded Pipeline Overview</a>. For more information about the Kafka partition assignment strategies, see the <a class="xref" href="https://kafka.apache.org/documentation/" target="_blank">Kafka
                documentation</a>.</p>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title5" id="concept_d5f_n2g_vq">
 <h2 class="title topictitle2" id="ariaid-title5">Additional Kafka Properties</h2>

 
 <div class="body conbody"><p class="shortdesc">You can add custom Kafka configuration properties to the Kafka Multitopic
        Consumer.</p>

  <p class="p">When you add the
            Kafka configuration property, enter the exact property name and the value. The Kafka
            Multitopic Consumer does not validate the property names or values.</p>

  <div class="p">
   <div class="note note"><span class="notetitle">Note:</span> The Kafka Multitopic Consumer origin uses the following Kafka configuration properties. The
                origin ignores user-defined values for these properties:<div class="p">
                    <ul class="ul" id="concept_d5f_n2g_vq__ul_ajb_c3g_vq">
                        <li class="li">auto.commit.interval.ms</li>

                        <li class="li">bootstrap.servers</li>

                        <li class="li">enable.auto.commit</li>

                        <li class="li">group.id</li>

                        <li class="li">max.poll.records</li>

                    </ul>

                </div>
</div>

  </div>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title6" id="concept_tlj_3g1_2z">
 <h2 class="title topictitle2" id="ariaid-title6">Record Header Attributes</h2>

 <div class="body conbody">
        <p class="p">The
            Kafka Multitopic Consumer origin <span class="ph">creates record header
                attributes that include <span class="ph" id="concept_tlj_3g1_2z__d29e21">information about the originating file for
                    the record</span>.</span> When the origin <span class="ph">processes Avro data, it includes the Avro schema in
                        an avroSchema record header attribute.</span></p>

        <p class="p"><span class="ph" id="concept_tlj_3g1_2z__d30e22">You can use the record:attribute or
                record:attributeOrDefault functions to access the information in the attributes. For
                more information about working with record header attributes, see <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_rd2_ghz_dz">Working with Header Attributes</a>.</span></p>

        <div class="p">The Kafka Multitopic Consumer origin <span class="ph">creates the following record header
                attributes:</span><ul class="ul" id="concept_tlj_3g1_2z__ul_i4q_2qv_jw">
                <li class="li">avroSchema - When processing Avro data, provides the
                              Avro schema.</li>

                <li class="li">offset - The offset where the record originated.</li>

                <li class="li">partition - The partition where the record originated.</li>

                <li class="li">topic - The topic where the record originated.</li>

            </ul>
</div>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title7" id="concept_yg3_k31_t5">
 <h2 class="title topictitle2" id="ariaid-title7">Enabling Security</h2>

    <div class="body conbody">
        <p class="p">You can configure the Kafka
            Multitopic Consumer origin to connect securely to Kafka through SSL/TLS, Kerberos, or
            both. </p>

    </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title8" id="concept_ann_l2b_t5">
    <h3 class="title topictitle3" id="ariaid-title8">Enabling SSL/TLS</h3>

    <div class="body conbody">
        <div class="p">Perform the following steps to enable the Kafka
            Multitopic Consumer origin to use SSL/TLS to connect to Kafka:<ol class="ol" id="concept_ann_l2b_t5__ol_lnb_dc4_gbb">
                <li class="li">To use SSL/TLS to connect, first make sure Kafka is
                    configured for SSL/TLS as described in the <a class="xref" href="http://kafka.apache.org/documentation.html#security_ssl" target="_blank">Kafka documentation</a>. </li>

                <li class="li">On the <strong class="ph b">Kafka</strong> tab, add the <strong class="ph b">security.protocol</strong> Kafka configuration
                    property and set it to <strong class="ph b">SSL</strong>.</li>

                <li class="li">Then add and configure the following SSL Kafka
                        properties:<ul class="ul" id="concept_ann_l2b_t5__d59e58">
                        <li class="li">ssl.truststore.location</li>

                        <li class="li">ssl.truststore.password</li>

                    </ul>
<div class="p">When the Kafka broker requires client authentication - when the
                        ssl.client.auth broker property is set to "required" - add and configure the
                        following properties: <ul class="ul" id="concept_ann_l2b_t5__d59e68">
                            <li class="li">ssl.keystore.location</li>

                            <li class="li">ssl.keystore.password</li>

                            <li class="li">ssl.key.password</li>

                        </ul>
</div>
<div class="p">Some brokers might require adding the following properties as
                            well:<ul class="ul" id="concept_ann_l2b_t5__d59e81">
                            <li class="li">ssl.enabled.protocols</li>

                            <li class="li">ssl.truststore.type</li>

                            <li class="li">ssl.keystore.type</li>

                        </ul>
</div>
<p class="p">For details about these properties, see the Kafka
                        documentation.</p>
</li>

            </ol>
</div>

        <p class="p">For example, the following properties allow the stage to use SSL/TLS to connect to Kafka
            with client authentication:</p>

        <img class="image" id="concept_ann_l2b_t5__image_w3r_mzc_rw" src="../../../reusable-content/datacollector/reusable-topics/../../../datacollector/UserGuide/Graphics/Kafka-SSLoptions.png" height="179" width="549" />
    </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title9" id="concept_w4j_3vb_t5">
 <h3 class="title topictitle3" id="ariaid-title9">Enabling Kerberos (SASL)</h3>

 <div class="body conbody">
  <p class="p">When you use Kerberos authentication, <span class="ph">Data Collector</span>
            uses the Kerberos principal and keytab. </p>

        <div class="p">Perform the following steps to enable the Kafka Multitopic Consumer origin to use
            Kerberos to connect to Kafka:<ol class="ol" id="concept_w4j_3vb_t5__ol_vrj_rb4_gbb">
                <li class="li">To use Kerberos, first make sure Kafka is configured for
                    Kerberos as described in the <a class="xref" href="http://kafka.apache.org/documentation.html#security_sasl" target="_blank">Kafka documentation</a>.</li>
<li class="li">Make sure that Kerberos authentication is enabled for <span class="ph">Data Collector</span>, as described
                    in <a class="xref" href="../Configuration/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Kerberos Authentication</a>.</li>

                <li class="li">Add the Java Authentication and Authorization
                    Service (JAAS) configuration properties required for Kafka clients based on your
                    installation and authentication type:<ul class="ul" id="concept_w4j_3vb_t5__d56e56">
                        <li class="li"><span class="ph uicontrol">RPM, tarball, or Cloudera Manager installation without LDAP
                                authentication</span> - If <span class="ph">Data Collector</span> does
                            not use LDAP authentication, create a separate JAAS configuration file
                            on the <span class="ph">Data Collector</span>
                            machine. Add the following <code class="ph codeph">KafkaClient</code> login section to
                            the
                                file:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</code></pre><div class="p">For
                                example:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</code></pre></div>
<div class="p">Then
                                modify the SDC_JAVA_OPTS environment variable to include the
                                following option that defines the path to the JAAS configuration
                                file:<pre class="pre codeblock"><code>-Djava.security.auth.login.config=&lt;JAAS config path&gt;</code></pre></div>
<p class="p"><a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_zhl_rb3_qcb">Modify environment variables</a> using the method required by your installation
                  type.</p>
</li>

                        <li class="li"><span class="ph uicontrol">RPM or tarball installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in an
                            RPM or tarball installation, add the properties to the JAAS
                            configuration file used by <span class="ph">Data Collector</span> - the
                                <code class="ph codeph">$SDC_CONF/ldap-login.conf</code> file. Add the following
                                <code class="ph codeph">KafkaClient</code> login section to the end of the
                                <code class="ph codeph">ldap-login.conf</code>
                                file:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</code></pre><div class="p">For
                                example:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</code></pre></div>
</li>

                        <li class="li"><span class="ph uicontrol">Cloudera Manager installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in a
                            Cloudera Manager installation, enable the LDAP Config File Substitutions
                            (ldap.login.file.allow.substitutions) property for the StreamSets
                            service in Cloudera Manager.<p class="p">If the Use Safety Valve to Edit LDAP
                                Information (use.ldap.login.file) property is enabled and LDAP
                                authentication is configured in the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for ldap-login.conf field, then
                                add the JAAS configuration properties to the same ldap-login.conf
                                safety valve.</p>
<p class="p">If LDAP authentication is configured through the
                                LDAP properties rather than the ldap-login.conf safety value, add
                                the JAAS configuration properties to the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for
                                generated-ldap-login-append.conf field.</p>
<p class="p">Add the following
                                    <code class="ph codeph">KafkaClient</code> login section to the appropriate
                                field as
                                follows:</p>
<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="&lt;principal name&gt;/_HOST@&lt;realm&gt;";
};</code></pre><div class="p">For
                                example:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="sdc/_HOST@EXAMPLE.COM";
};</code></pre></div>
<p class="p">Cloudera
                                Manager generates the appropriate keytab path and host name.
                            </p>
</li>

                    </ul>
</li>

                <li class="li">On the <span class="keyword wintitle">Kafka</span> tab, add the
                        <span class="ph uicontrol">security.protocol</span> Kafka configuration property, and
                    set it to <span class="ph uicontrol">SASL_PLAINTEXT</span>.</li>

                <li class="li">Then, add the
                        <span class="ph uicontrol">sasl.kerberos.service.name</span> configuration property,
                    and set it to <span class="ph uicontrol">kafka</span>. </li>

            </ol>
</div>

        <p class="p">For example, the following Kafka properties enable connecting to Kafka with Kerberos:</p>

        <p class="p"><img class="image" id="concept_w4j_3vb_t5__d56e165" src="../../../reusable-content/datacollector/reusable-topics/../../../datacollector/UserGuide/Graphics/Kafka-Kerberos.png" height="95" width="639" /></p>

 </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title10" id="concept_qzq_jrk_55">
 <h3 class="title topictitle3" id="ariaid-title10">Enabling SSL/TLS and Kerberos</h3>

 <div class="body conbody">
        <p class="p">You can enable the Kafka Multitopic Consumer origin
            to use SSL/TLS and Kerberos to connect to Kafka. </p>

        <div class="p"><span class="ph">To use SSL/TLS and Kerberos, combine the required
                steps to enable each and set the security.protocol property as follows:</span><ol class="ol" id="concept_qzq_jrk_55__ol_grw_v14_gbb">
                <li class="li">Make sure Kafka is configured to use SSL/TLS and
                    Kerberos (SASL) as described in the following Kafka documentation:<ul class="ul" id="concept_qzq_jrk_55__d55e37">
                        <li class="li"><a class="xref" href="http://kafka.apache.org/documentation.html#security_ssl" target="_blank">http://kafka.apache.org/documentation.html#security_ssl</a></li>

                        <li class="li"><a class="xref" href="http://kafka.apache.org/documentation.html#security_sasl" target="_blank">http://kafka.apache.org/documentation.html#security_sasl</a></li>

                    </ul>
</li>

                <li class="li">Make sure that Kerberos authentication is enabled for <span class="ph">Data Collector</span>, as described
                    in <a class="xref" href="../Configuration/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Kerberos Authentication</a>.</li>

                    <li class="li">Add the Java Authentication and Authorization
                    Service (JAAS) configuration properties required for Kafka clients based on your
                    installation and authentication type:<ul class="ul" id="concept_qzq_jrk_55__d56e56">
                        <li class="li"><span class="ph uicontrol">RPM, tarball, or Cloudera Manager installation without LDAP
                                authentication</span> - If <span class="ph">Data Collector</span> does
                            not use LDAP authentication, create a separate JAAS configuration file
                            on the <span class="ph">Data Collector</span>
                            machine. Add the following <code class="ph codeph">KafkaClient</code> login section to
                            the
                                file:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</code></pre><div class="p">For
                                example:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</code></pre></div>
<div class="p">Then
                                modify the SDC_JAVA_OPTS environment variable to include the
                                following option that defines the path to the JAAS configuration
                                file:<pre class="pre codeblock"><code>-Djava.security.auth.login.config=&lt;JAAS config path&gt;</code></pre></div>
<p class="p"><a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_zhl_rb3_qcb">Modify environment variables</a> using the method required by your installation
                  type.</p>
</li>

                        <li class="li"><span class="ph uicontrol">RPM or tarball installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in an
                            RPM or tarball installation, add the properties to the JAAS
                            configuration file used by <span class="ph">Data Collector</span> - the
                                <code class="ph codeph">$SDC_CONF/ldap-login.conf</code> file. Add the following
                                <code class="ph codeph">KafkaClient</code> login section to the end of the
                                <code class="ph codeph">ldap-login.conf</code>
                                file:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="&lt;keytab path&gt;"
    principal="&lt;principal name&gt;/&lt;host name&gt;@&lt;realm&gt;";
};</code></pre><div class="p">For
                                example:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="/etc/security/keytabs/sdc.keytab"
    principal="sdc/sdc-01.streamsets.net@EXAMPLE.COM";
};</code></pre></div>
</li>

                        <li class="li"><span class="ph uicontrol">Cloudera Manager installation with LDAP
                                authentication</span> - If LDAP authentication is enabled in a
                            Cloudera Manager installation, enable the LDAP Config File Substitutions
                            (ldap.login.file.allow.substitutions) property for the StreamSets
                            service in Cloudera Manager.<p class="p">If the Use Safety Valve to Edit LDAP
                                Information (use.ldap.login.file) property is enabled and LDAP
                                authentication is configured in the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for ldap-login.conf field, then
                                add the JAAS configuration properties to the same ldap-login.conf
                                safety valve.</p>
<p class="p">If LDAP authentication is configured through the
                                LDAP properties rather than the ldap-login.conf safety value, add
                                the JAAS configuration properties to the Data Collector Advanced
                                Configuration Snippet (Safety Valve) for
                                generated-ldap-login-append.conf field.</p>
<p class="p">Add the following
                                    <code class="ph codeph">KafkaClient</code> login section to the appropriate
                                field as
                                follows:</p>
<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="&lt;principal name&gt;/_HOST@&lt;realm&gt;";
};</code></pre><div class="p">For
                                example:<pre class="pre codeblock"><code>KafkaClient {
    com.sun.security.auth.module.Krb5LoginModule required
    useKeyTab=true
    keyTab="_KEYTAB_PATH"
    principal="sdc/_HOST@EXAMPLE.COM";
};</code></pre></div>
<p class="p">Cloudera
                                Manager generates the appropriate keytab path and host name.
                            </p>
</li>

                    </ul>
</li>

                <li class="li">On the <span class="keyword wintitle">Kafka</span> tab, add the
                        <span class="ph uicontrol">security.protocol</span> property and set it to
                        <span class="ph uicontrol">SASL_SSL</span>.</li>

                    <li class="li">Then, add the
                        <span class="ph uicontrol">sasl.kerberos.service.name</span> configuration property,
                    and set it to <span class="ph uicontrol">kafka</span>. </li>

                    <li class="li">Then add and configure the following SSL Kafka
                        properties:<ul class="ul" id="concept_qzq_jrk_55__d59e58">
                        <li class="li">ssl.truststore.location</li>

                        <li class="li">ssl.truststore.password</li>

                    </ul>
<div class="p">When the Kafka broker requires client authentication - when the
                        ssl.client.auth broker property is set to "required" - add and configure the
                        following properties: <ul class="ul" id="concept_qzq_jrk_55__d59e68">
                            <li class="li">ssl.keystore.location</li>

                            <li class="li">ssl.keystore.password</li>

                            <li class="li">ssl.key.password</li>

                        </ul>
</div>
<div class="p">Some brokers might require adding the following properties as
                            well:<ul class="ul" id="concept_qzq_jrk_55__d59e81">
                            <li class="li">ssl.enabled.protocols</li>

                            <li class="li">ssl.truststore.type</li>

                            <li class="li">ssl.keystore.type</li>

                        </ul>
</div>
<p class="p">For details about these properties, see the Kafka
                        documentation.</p>
</li>

            </ol>
</div>

 </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title11" id="concept_xgs_nlc_wr">
 <h2 class="title topictitle2" id="ariaid-title11">Data Formats</h2>

 <div class="body conbody">
  <p class="p">The Kafka Multitopic Consumer origin processes data
      differently based on the data format. Kafka Multitopic Consumer can process the following
      types of data:</p>

  <dl class="dl">
      
                              <dt class="dt dlterm">Avro</dt>

                              <dd class="dd">Generates a record for every message. Includes a "precision" and
                                    "scale" field attribute for each Decimal field. For more
                                    information about field attributes, see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a>.</dd>

                              <dd class="dd ddexpand">The origin writes the Avro schema to an avroSchema record header
                                    attribute. For more information about record header attributes,
                                    see <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz">Record Header Attributes</a>. </dd>

                              <dd class="dd ddexpand">You can use one of the following methods to specify the location
                                    of the Avro schema definition:<ul class="ul" id="concept_xgs_nlc_wr__d11e1005">
                                          <li class="li"><span class="ph uicontrol">Message/Data Includes Schema</span> -
                                                Use the schema in the message.</li>

                                          <li class="li"><span class="ph uicontrol">In Pipeline Configuration</span> - Use
                                                the schema that you provide in the stage
                                                configuration.</li>

                                          <li class="li"><span class="ph uicontrol">Confluent Schema Registry</span> -
                                                Retrieve the schema from Confluent Schema Registry.
                                                The Confluent Schema Registry is a distributed
                                                storage layer for Avro schemas. You can configure
                                                the origin to look up the schema in the Confluent
                                                Schema Registry by the schema ID embedded in the
                                                message or by the schema ID or subject specified in
                                                the stage configuration.<p class="p">You must specify the
                                                  method that the origin uses to deserialize the
                                                  message. If the Avro schema ID is embedded in each
                                                  message, set the key and value deserializers to
                                                  Confluent on the <span class="ph uicontrol">Kafka</span>
                                                  tab.</p>
</li>

                                    </ul>
</dd>

                              <dd class="dd ddexpand">Using a schema in the stage configuration or retrieving a schema
                                    from the Confluent Schema Registry overrides any schema that
                                    might be included in the message and can improve
                                    performance.</dd>

                        
      
                              <dt class="dt dlterm">Binary</dt>

                              <dd class="dd">Generates a record with a single byte array field at the root of
                                    the record. </dd>

                              <dd class="dd ddexpand">When the data exceeds the user-defined maximum data size, the
                                    origin cannot process the data. Because the record is not
                                    created, the origin cannot pass the record to the pipeline to be
                                    written as an error record. Instead, the origin generates a
                                    stage error. </dd>

                        
      
                              <dt class="dt dlterm">Datagram</dt>

                              <dd class="dd">Generates a record for every message. The origin <span class="ph">can process <a class="xref" href="https://collectd.org/" target="_blank">collectd</a> messages, <span class="ph" id="concept_xgs_nlc_wr__d11e2668">NetFlow 5 and NetFlow 9 messages</span>, and the
                        following types of syslog messages:</span><ul class="ul" id="concept_xgs_nlc_wr__ul_fj2_3q4_4x">
                        <li class="li" id="concept_xgs_nlc_wr__d11e2673"><a class="xref" href="https://tools.ietf.org/html/rfc5424" target="_blank">RFC 5424</a></li>

                        <li class="li" id="concept_xgs_nlc_wr__d11e2677"><a class="xref" href="https://tools.ietf.org/html/rfc3164" target="_blank">RFC 3164</a></li>

                        <li class="li">Non-standard common messages, such as RFC 3339 dates with no version
                              digit</li>

                  </ul>
</dd>

                              <dd class="dd ddexpand"><span class="ph">When processing NetFlow messages, the stage generates
                        different records based on the NetFlow version. When processing NetFlow 9,
                        the records are generated based on the NetFlow 9 configuration properties.
                        For more information, see <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_thl_nnr_hbb">NetFlow Data Processing</a>.</span></dd>

                        
      
                              <dt class="dt dlterm">Delimited</dt>

                              <dd class="dd">Generates a record for each delimited line. You can use the
                                    following delimited format types:<ul class="ul" id="concept_xgs_nlc_wr__ul_vyp_ksl_mcb">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                  </ul>
</dd>

                              <dd class="dd ddexpand">You can use a list or list-map root field type for delimited data,
                                    optionally including the header information when available. For
                                    more information about the root field types, see <a class="xref" href="../Data_Formats/DelimitedDataRootFieldTypes.html#concept_zcg_bm4_fs">Delimited Data Root Field Type</a>.</dd>

                              <dd class="dd ddexpand">When using a header line, you can allow processing records with
                                    additional columns. The additional columns are named using a
                                    custom prefix and integers in sequential increasing order, such
                                    as _extra_1, _extra_2. When you disallow additional columns when
                                    using a header line, records that include additional columns are
                                    sent to error.</dd>

                              <dd class="dd ddexpand">You can also replace a string constant with null values.</dd>

                              <dd class="dd ddexpand">When a record exceeds the maximum record length defined for the
                                    origin, the origin processes the object based on the error
                                    handling configured for the stage.</dd>

                        
      
                              <dt class="dt dlterm">JSON</dt>

                              <dd class="dd">Generates a record for each JSON object. You can process JSON
                                    files that include multiple JSON objects or a single JSON
                                    array.</dd>

                              <dd class="dd ddexpand">When an object exceeds the maximum object length defined for the
                                    origin, the origin processes the object based on the error
                                    handling configured for the stage. </dd>

                        
      
                              <dt class="dt dlterm">Log</dt>

                              <dd class="dd">Generates a record for every log line. </dd>

                              <dd class="dd ddexpand">When a line exceeds the user-defined maximum line length, the
                                    origin truncates longer lines. </dd>

                              <dd class="dd ddexpand">You can include the processed log line as a field in the record.
                                    If the log line is truncated, and you request the log line in
                                    the record, the origin includes the truncated line.</dd>

                              <dd class="dd ddexpand">You can define the <a class="xref" href="../Data_Formats/LogFormats.html#concept_tr1_spd_sr" title="When you use an origin to read log data, you define the format of the log files to be read.">log format</a> or type to be read.</dd>

                        
      
                              <dt class="dt dlterm">Protobuf</dt>

                              <dd class="dd">Generates a record for every protobuf message. By default, the
                                    origin assumes messages contain multiple protobuf messages.</dd>

                              <dd class="dd ddexpand">Protobuf messages must match the specified message type and be
                                    described in the descriptor file. </dd>

                              <dd class="dd ddexpand">When the data for a record exceeds 1 MB, the origin cannot
                                    continue processing data in the message. The origin handles the
                                    message based on the stage error handling property and continues
                                    reading the next message. </dd>

                              <dd class="dd ddexpand">For information about generating the descriptor file, see <a class="xref" href="../Data_Formats/Protobuf-Prerequisites.html" title="Perform the following prerequisites before reading or writing protobuf data.">Protobuf Data Format Prerequisites</a>.</dd>

                        
      
                              <dt class="dt dlterm">SDC Record</dt>

                              <dd class="dd">Generates a record for every record. Use to process records
                                    generated by a <span class="ph">Data Collector</span>
                                    pipeline using the SDC Record data format.</dd>

                              <dd class="dd ddexpand">For error records, the origin provides the original record as read
                                    from the origin in the original pipeline, as well as error
                                    information that you can use to correct the record. </dd>

                              <dd class="dd ddexpand">When processing error records, the origin expects the error file
                                    names and contents as generated by the original pipeline.</dd>

                        
      
                              <dt class="dt dlterm">Text</dt>

                              <dd class="dd">Generates a record for each line of text or for each section of
                                    text based on a custom delimiter.</dd>

                              <dd class="dd ddexpand">When a line or section exceeds the maximum line length defined for
                                    the origin, the origin truncates it. The origin adds a boolean
                                    field named Truncated to indicate if the line was
                                    truncated.</dd>

                              <dd class="dd ddexpand">For more information about processing text with a custom
                                    delimiter, see <a class="xref" href="../Data_Formats/TextCDelim.html#concept_lg2_gcg_jx">Text Data Format with Custom Delimiters</a>.</dd>

                        
      
                              <dt class="dt dlterm">XML</dt>

                              <dd class="dd">Generates records based on a user-defined delimiter element. Use
                                    an XML element directly under the root element or define a
                                    simplified XPath expression. If you do not define a delimiter
                                    element, the origin treats the XML file as a single record.</dd>

                              <dd class="dd ddexpand">Generated records include XML attributes and namespace
                                    declarations as fields in the record by default. You can
                                    configure the stage to include them in the record as field
                                    attributes. </dd>

                              <dd class="dd ddexpand">You can include XPath information for each parsed XML element and
                                    XML attribute in field attributes. This also places each
                                    namespace in an xmlns record header attribute. <div class="note note"><span class="notetitle">Note:</span> <span class="ph">Field attributes and record header attributes are
                        written to destination systems automatically only when you use the SDC RPC
                        data format in destinations. For more information about working with field
                        attributes and record header attributes, and how to include them in records,
                        see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a> and <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz">Record Header Attributes</a>.</span></div>
</dd>

                              <dd class="dd ddexpand">When a record exceeds the user-defined maximum record length, the
                                    origin skips the record and continues processing with the next
                                    record. It sends the skipped record to the pipeline for error
                                    handling. </dd>

                              <dd class="dd ddexpand">Use the XML data format to process valid XML documents. For more
                                    information about XML processing, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_lty_42b_dy">Reading and Processing XML Data</a>.</dd>

                              <dd class="dd ddexpand">
                                    <div class="note tip"><span class="tiptitle">Tip:</span> <span class="ph">If you want to process invalid XML
                                                documents, you can try using the text data format
                                                with custom delimiters. For more information, see
                                                  <a class="xref" href="../Data_Formats/TextCDelim.html#concept_okt_kmg_jx">Processing XML Data with Custom Delimiters</a>.</span>
                                    </div>

                              </dd>

                        
    </dl>

 </div>

</article>
<article class="topic task nested1" aria-labelledby="ariaid-title12" id="task_ost_3n4_x1b">
    <h2 class="title topictitle2" id="ariaid-title12">Configuring a Kafka Multitopic Consumer</h2>

    <div class="body taskbody">
        <section class="section context">Configure a Kafka Multitopic
            Consumer to use multiple threads to read data from multiple topics in a Kafka cluster. </section>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__d66e861" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e1380">General Property</th>

                                    <th class="entry cellrowborder" id="d301069e1383">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1380 ">Name</td>

                                    <td class="entry cellrowborder" headers="d301069e1383 ">Stage name.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1380 ">Description</td>

                                    <td class="entry cellrowborder" headers="d301069e1383 ">Optional description.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1380 ">Stage Library</td>

                                    <td class="entry cellrowborder" headers="d301069e1383 ">Library version that you want to use. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1380 ">On Record Error <a class="xref" href="../Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r">
                                            <img class="image" id="task_ost_3n4_x1b__d66e916" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d301069e1383 ">Error record handling for the stage: <ul class="ul" id="task_ost_3n4_x1b__d66e920">
                                            <li class="li">Discard - Discards the record.</li>

                                            <li class="li">Send to Error - Sends the record to the pipeline for
                                                error handling.</li>

                                            <li class="li">Stop Pipeline - Stops the pipeline. Not valid for
                                                cluster pipelines.</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Connection</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_v4j_qhw_yq" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:27.77777777777778%" /><col style="width:72.22222222222221%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e1468">Kafka Property</th>

                                    <th class="entry cellrowborder" id="d301069e1471">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1468 ">Broker URI</td>

                                    <td class="entry cellrowborder" headers="d301069e1471 ">Connection string for the Kafka broker. Use the following
                                        format: <code class="ph codeph">&lt;host&gt;:&lt;port&gt;</code>. <p class="p">To ensure a
                                            connection, enter a comma-separated list of additional
                                            broker URIs.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1468 ">Consumer Group</td>

                                    <td class="entry cellrowborder" headers="d301069e1471 ">Kafka consumer group that the <span class="ph">Data Collector</span> belongs to.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1468 ">Topic List</td>

                                    <td class="entry cellrowborder" headers="d301069e1471 ">The Kafka topics to read. Click
                                            <span class="ph uicontrol">Add</span> to add additional topics. <div class="p">
                                            <div class="note tip"><span class="tiptitle">Tip:</span> You can use <a class="xref" href="Origins_overview.html#task_jp5_ql1_tq" title="Some origins allow you to preview raw source data. Preview raw source data when reviewing the data might help with origin configuration.">Raw Preview</a> to generate a list of topics
                                                associated with a broker. The list displays in a
                                                format that you can use to list the topics in <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">bulk edit mode</a>. </div>

                                        </div>
</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e1468 ">Produce Single Record</td>

       <td class="entry cellrowborder" headers="d301069e1471 ">For each partition, generates a single record for records that include multiple
        objects. <p class="p">When not selected, the origin generates multiple records when a record includes
         multiple objects.</p>
</td>

      </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1468 ">Number of Threads </td>

                                    <td class="entry cellrowborder" headers="d301069e1471 ">The number of threads the origin generates and uses for
                                        multithreaded processing. The origin uses threads as defined
                                        by the Kafka partition assignment strategy. For more
                                        information, see <a class="xref" href="KafkaMultiConsumer.html#concept_ifs_wtm_3z">Multithreaded Processing</a>.</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e1468 ">Max Batch Size (records)</td>

       <td class="entry cellrowborder" headers="d301069e1471 ">Maximum number of records processed at one time. Honors values up to the <span class="ph">Data Collector</span> maximum batch size. <p class="p">Default is
         1000. The <span class="ph">Data Collector</span> default is
         1000.</p>
</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e1468 ">Batch Wait Time (ms) <a class="xref" href="Origins_overview.html#concept_ypd_vgr_5q">
         <img class="image" id="task_ost_3n4_x1b__d42e897" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d301069e1471 ">Number of milliseconds to wait before sending a partial or empty batch. </td>

      </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1468 ">Configuration Properties <a class="xref" href="KafkaMultiConsumer.html#concept_d5f_n2g_vq" title="You can add custom Kafka configuration properties to the Kafka Multitopic Consumer.">
                                            <img class="image" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a>
                                    </td>

                                    <td class="entry cellrowborder" headers="d301069e1471 ">
                                        <p class="p">Additional Kafka configuration
                                            properties to use. Using <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a>, click the
                                                <span class="ph uicontrol">Add</span> icon to add properties.
                                            Define the Kafka property name and value.</p>

                                        <p class="p">Use the property names and values as
                                            expected by Kafka.</p>

                                        <p class="p" id="task_ost_3n4_x1b__p-KafkaConfig3">For information about enabling secure
                                            connections to Kafka, see <a class="xref" href="KafkaMultiConsumer.html#concept_yg3_k31_t5">Enabling Security</a>.</p>

                                    </td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Data Format</span> tab, configure the following
                    property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_hvy_pt3_vx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e1651">Data Format Property</th>

                                    <th class="entry cellrowborder" id="d301069e1654">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1651 ">Data Format <a class="xref" href="KafkaMultiConsumer.html#concept_xgs_nlc_wr">
                                            <img class="image" id="task_ost_3n4_x1b__image_bmy_h5q_ds" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d301069e1654 ">Type of data to be read. Use one of the following
                                            options:<ul class="ul" id="task_ost_3n4_x1b__ul_l1j_hnf_qw">
                        <li class="li">Avro</li>

                        <li class="li">Binary</li>

                        <li class="li">Datagram</li>

                        <li class="li">Delimited</li>

                        <li class="li">JSON</li>

                        <li class="li">Log</li>

                        <li class="li">Protobuf</li>

                        <li class="li">SDC Record <a class="xref" href="../Pipeline_Design/SDCRecordFormat.html#concept_qkk_mwk_br" title="SDC Record is a proprietary data format that Data Collector uses to generate error records. Data Collector can also use the data format to read and write data.">
                                    <img class="image" id="task_ost_3n4_x1b__d11e914" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="14" width="14" /></a></li>

                        <li class="li">Text</li>

                        <li class="li">XML</li>

                  </ul>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand" id="task_ost_3n4_x1b__O-AVRO-Mess">
                <span class="ph cmd">For Avro data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_acd_2qd_3t" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e1747">Avro Property</th>

                                    <th class="entry cellrowborder" id="d301069e1750">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1747 ">Avro Schema Location</td>

                                    <td class="entry cellrowborder" headers="d301069e1750 ">Location of the Avro schema definition to use when
                                        processing data:<ul class="ul" id="task_ost_3n4_x1b__d66e1126">
                                            <li class="li">Message/Data Includes Schema - Use the schema in the
                                                message.</li>

                                            <li class="li">In Pipeline Configuration - Use the schema provided
                                                in the stage configuration.</li>

                                            <li class="li">Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry.</li>

                                        </ul>
<p class="p">Using a schema in the stage configuration or in the
                                            Confluent Schema Registry can improve
                                        performance.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1747 ">Avro Schema</td>

                                    <td class="entry cellrowborder" headers="d301069e1750 ">Avro schema definition used to process the data.
                                        Overrides any existing schema definitions associated with
                                        the data. <p class="p">You can optionally use the runtime:loadResource
                                            function to use a schema definition stored in a runtime
                                            resource file. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1747 ">Schema Registry URLs</td>

                                    <td class="entry cellrowborder" headers="d301069e1750 ">Confluent Schema Registry URLs used to look up the
                                        schema. To add a URL, click <span class="ph uicontrol">Add</span>. Use
                                        the following format to enter the
                                        URL:<pre class="pre codeblock"><code>http://&lt;host name&gt;:&lt;port number&gt;</code></pre></td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1747 ">Lookup Schema By</td>

                                    <td class="entry cellrowborder" headers="d301069e1750 ">Method used to look up the schema in the Confluent Schema
                                            Registry:<ul class="ul" id="task_ost_3n4_x1b__d66e1173">
                                            <li class="li">Subject - Look up the specified Avro schema
                                                subject.</li>

                                            <li class="li">Schema ID - Look up the specified Avro schema ID. </li>

                                            <li class="li">Embedded Schema ID - Look up the Avro schema ID
                                                embedded in each message.</li>

                                        </ul>
Overrides any existing schema definitions associated
                                        with the message. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1747 ">Schema Subject</td>

                                    <td class="entry cellrowborder" headers="d301069e1750 ">Avro schema subject to look up in the Confluent Schema
                                            Registry.<p class="p">If the specified subject has multiple schema
                                            versions, the origin uses the latest schema version for
                                            that subject. To use an older version, find the
                                            corresponding schema ID, and then set the
                                                <span class="ph uicontrol">Look Up Schema By</span> property to
                                            Schema ID.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1747 ">Schema ID</td>

                                    <td class="entry cellrowborder" headers="d301069e1750 ">Avro schema ID to look up in the Confluent Schema
                                        Registry.</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand" id="task_ost_3n4_x1b__O-Binary">
                <span class="ph cmd">For binary data, on the <span class="keyword wintitle">Data Format</span> tab and configure the
                    following property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_dpx_kdm_35" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e1876">Binary Property</th>

                                    <th class="entry cellrowborder" id="d301069e1879">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1876 ">Max Data Size (bytes)</td>

                                    <td class="entry cellrowborder" headers="d301069e1879 ">Maximum number of bytes in the message. Larger messages
                                        cannot be processed or written to error. </td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For datagram data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__d66e1473" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e1923">Datagram Properties</th>

                                    <th class="entry cellrowborder" id="d301069e1926">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 ">Datagram Packet Format</td>

                                    <td class="entry cellrowborder" headers="d301069e1926 ">Packet format of the data: <ul class="ul" id="task_ost_3n4_x1b__ul_q1q_yp4_4x">
                                            <li class="li">collectd</li>

                                            <li class="li">NetFlow</li>

                                            <li class="li">syslog </li>

                                            <li class="li">Raw/separated data </li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 ">TypesDB File Path</td>

                                    <td class="entry cellrowborder" headers="d301069e1926 "><span class="ph">Path to a user-provided types.db
                                            file. Overrides the default types.db file.</span><p class="p">For collectd data only.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 ">Convert Hi-Res Time &amp;
                                        Interval</td>

                                    <td class="entry cellrowborder" headers="d301069e1926 "><span class="ph">Converts the collectd high
                                            resolution time format interval and timestamp to UNIX
                                            time, in milliseconds.</span><p class="p">For collectd data only.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 ">Exclude Interval</td>

                                    <td class="entry cellrowborder" headers="d301069e1926 "><span class="ph">Excludes the interval field from
                                            output record.</span><p class="p">For collectd data only.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 ">Auth File</td>

                                    <td class="entry cellrowborder" headers="d301069e1926 "><span class="ph">Path to an optional authentication
                                            file. Use an authentication file to accept signed and
                                            encrypted data.</span><p class="p">For collectd data only.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 "><span class="ph">Record Generation Mode <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_jdh_hxk_3bb">
                                                <img class="image" id="task_ost_3n4_x1b__d66e5433" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></span>
                                    </td>

                                    <td class="entry cellrowborder" headers="d301069e1926 "><span class="ph">Determines the type of
                                            values to include in the record. Select one of the
                                            following options:</span><ul class="ul" id="task_ost_3n4_x1b__ul_zgh_m4l_3bb">
                                            <li class="li">Raw Only</li>

                                            <li class="li">Interpreted Only</li>

                                            <li class="li">Both Raw and Interpreted</li>

                                        </ul>
<p class="p">For NetFlow 9 data only.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 "><span class="ph">Max Templates in
                                            Cache</span></td>

                                    <td class="entry cellrowborder" headers="d301069e1926 "><span class="ph">The maximum number of
                                            templates to store in the template cache. For more
                                            information about templates, see <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_ivr_j1l_3bb">Caching NetFlow 9 Templates</a>.</span><p class="p"><span class="ph">Default is -1
                                                for an unlimited cache size.</span></p>
<p class="p">For NetFlow 9 data only.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e1923 "><span class="ph">Template Cache
                                            Timeout (ms)</span></td>

                                    <td class="entry cellrowborder" headers="d301069e1926 "><span class="ph">The maximum number
                                            of milliseconds to cache an idle template. Templates
                                            unused for more than the specified time are evicted from
                                            the cache. For more information about templates, see
                                                <a class="xref" href="../Data_Formats/NetFlow_Overview.html#concept_ivr_j1l_3bb">Caching NetFlow 9 Templates</a>.</span><p class="p"><span class="ph">Default is -1 for caching templates
                                                indefinitely.</span></p>
<p class="p">For NetFlow 9 data only.</p>
</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e1923 ">Charset</td>

       <td class="entry cellrowborder" headers="d301069e1926 ">Character encoding of the messages to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e1923 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_ost_3n4_x1b__d42e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d301069e1926 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For delimited data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_wbk_jvs_wx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e2126">Delimited Property</th>

                                    <th class="entry cellrowborder" id="d301069e2129">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Delimiter Format Type</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Delimiter format type. Use one of the following options:
                                            <ul class="ul" id="task_ost_3n4_x1b__ul_s5z_b3z_3r">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                  </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Header Line</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Indicates whether a file contains a header line, and
                                        whether to use the header line.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Allow Extra Columns</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">When processing data with a header line, allows
                                        processing records with more columns than exist in the
                                        header line.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Extra Column Prefix</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Prefix to use for any additional columns. Extra columns
                                        are named using the prefix and sequential increasing
                                        integers as follows:
                                            <code class="ph codeph">&lt;prefix&gt;&lt;integer&gt;</code>. <p class="p">For
                                            example, _extra_1. Default is _extra_.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Max Record Length (chars)</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Maximum length of a record in characters. Longer records
                                        are not read. <p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Delimiter Character</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Delimiter character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                            character.<p class="p">You can enter a Unicode control character
                                            using the format \u<em class="ph i">NNNN</em>, where ​<em class="ph i">N</em> is a
                                            hexadecimal digit from the numbers 0-9 or the letters
                                            A-F. For example, enter \u0000 to use the null character
                                            as the delimiter or \u2028 to use a line separator as
                                            the delimiter.</p>
<p class="p">Default is the pipe character ( |
                                            ).</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Escape Character</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Escape character for a custom file type.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Quote Character</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Quote character for a custom file type.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Root Field Type <a class="xref" href="../Data_Formats/DelimitedDataRootFieldTypes.html">
                                            <img class="image" id="task_ost_3n4_x1b__d66e1760" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Root field type to use:<ul class="ul" id="task_ost_3n4_x1b__d66e1764">
                                            <li class="li">List-Map - Generates an indexed list of data.
                                                Enables you to use standard functions to process
                                                data. Use for new pipelines.</li>

                                            <li class="li">List - Generates a record with an indexed list with
                                                a map for header and value. Requires the use of
                                                delimited data functions to process data. Use only
                                                to maintain pipelines created before 1.1.0.</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Lines to Skip</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Lines to skip before reading data. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">Parse NULLs</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">Replaces the specified string constant with null
                                        values.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2126 ">NULL Constant</td>

                                    <td class="entry cellrowborder" headers="d301069e2129 ">String constant to replace with null values.</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2126 ">Charset</td>

       <td class="entry cellrowborder" headers="d301069e2129 ">Character encoding of the files to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2126 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_ost_3n4_x1b__d42e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d301069e2129 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For JSON data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_c1h_wls_wx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e2378">JSON Property</th>

                                    <th class="entry cellrowborder" id="d301069e2381">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2378 ">JSON Content</td>

                                    <td class="entry cellrowborder" headers="d301069e2381 ">Type of JSON content. Use one of the following options: <div class="p">
                                            <ul class="ul" id="task_ost_3n4_x1b__d66e1938">
                                                <li class="li">Array of Objects </li>

                                                <li class="li">Multiple Objects</li>

                                            </ul>

                                        </div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2378 ">Maximum Object Length (chars)</td>

                                    <td class="entry cellrowborder" headers="d301069e2381 ">Maximum number of characters in a JSON object. <p class="p">Longer
                                            objects are diverted to the pipeline for error handling.
                                                </p>
<p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2378 ">Charset</td>

       <td class="entry cellrowborder" headers="d301069e2381 ">Character encoding of the files to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2378 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_ost_3n4_x1b__d42e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d301069e2381 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For log data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_mgz_ydm_wx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e2481">Log Property</th>

                                    <th class="entry cellrowborder" id="d301069e2484">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2481 ">Log Format <a class="xref" href="../Data_Formats/LogFormats.html" title="When you use an origin to read log data, you define the format of the log files to be read.">
                                            <img class="image" id="task_ost_3n4_x1b__d66e2046" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d301069e2484 ">Format of the log files. Use one of the following
                                            options:<ul class="ul" id="task_ost_3n4_x1b__d66e2050">
                                            <li class="li">Common Log Format</li>

                                            <li class="li">Combined Log Format</li>

                                            <li class="li">Apache Error Log Format</li>

                                            <li class="li">Apache Access Log Custom Format</li>

                                            <li class="li">Regular Expression</li>

                                            <li class="li">Grok Pattern</li>

                                            <li class="li">Log4j</li>

                                            <li class="li">Common Event Format (CEF)</li>

                                            <li class="li">Log Event Extended Format (LEEF)</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2481 ">Max Line Length</td>

                                    <td class="entry cellrowborder" headers="d301069e2484 ">Maximum length of a log line. The origin truncates longer
                                        lines. <p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2481 ">Retain Original Line</td>

                                    <td class="entry cellrowborder" headers="d301069e2484 ">Determines how to treat the original log line. Select to
                                        include the original log line as a field in the resulting
                                            record.<p class="p">By default, the original line is
                                            discarded.</p>
</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2481 ">Charset</td>

       <td class="entry cellrowborder" headers="d301069e2484 ">Character encoding of the files to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2481 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_ost_3n4_x1b__d42e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d301069e2484 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                    <ul class="ul" id="task_ost_3n4_x1b__ul_hx5_k2m_wx">
                        <li class="li">When you select <span class="ph uicontrol">Apache Access Log Custom Format</span>,
                            use Apache log format strings to define the <span class="ph uicontrol">Custom Log
                                Format</span>.</li>

                        <li class="li">When you select <span class="ph uicontrol">Regular Expression</span>, enter the
                            regular expression that describes the log format, and then map the
                            fields that you want to include to each regular expression group.</li>

                        <li class="li">When you select <span class="ph uicontrol">Grok Pattern</span>, you can use the
                                <span class="ph uicontrol">Grok Pattern Definition</span> field to define
                            custom grok patterns. You can define a pattern on each line. <p class="p">In the
                                    <span class="ph uicontrol">Grok Pattern</span> field, enter the pattern to
                                use to parse the log. You can use a predefined grok patterns or
                                create a custom grok pattern using patterns defined in
                                    <span class="ph uicontrol">Grok Pattern Definition</span>.</p>
<p class="p">For more
                                information about defining grok patterns and supported grok
                                patterns, see <a class="xref" href="../Apx-GrokPatterns/GrokPatterns_title.html#concept_vdk_xjb_wr" title="You can use the grok patterns in this appendix to define the structure of log data.">Defining Grok Patterns</a>.</p>
</li>

                        <li class="li">When you select <span class="ph uicontrol">Log4j</span>, define the following properties:<div class="p">
                                
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__d66e2163" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:22.22222222222222%" /><col style="width:77.77777777777779%" /></colgroup><thead class="thead" style="text-align:left;">
                                            <tr>
                                                <th class="entry cellrowborder" id="d301069e2657">Log4j Property</th>

                                                <th class="entry cellrowborder" id="d301069e2660">Description</th>

                                            </tr>

                                        </thead>
<tbody class="tbody">
                                            <tr>
                                                <td class="entry cellrowborder" headers="d301069e2657 ">On Parse Error</td>

                                                <td class="entry cellrowborder" headers="d301069e2660 ">Determines how to handle information that
                                                  cannot be parsed:<ul class="ul" id="task_ost_3n4_x1b__d66e2192">
                                                  <li class="li">Skip and Log Error - Skips reading the line
                                                  and logs a stage error.</li>

                                                  <li class="li">Skip, No Error - Skips reading the line and
                                                  does not log an error.</li>

                                                  <li class="li">Include as Stack Trace - Includes information
                                                  that cannot be parsed as a stack trace to the
                                                  previously-read log line. The information is added
                                                  to the message field for the last valid log
                                                  line.</li>

                                                  </ul>
</td>

                                            </tr>

                                            <tr>
                                                <td class="entry cellrowborder" headers="d301069e2657 ">Use Custom Log Format</td>

                                                <td class="entry cellrowborder" headers="d301069e2660 ">Allows you to define a custom log
                                                  format.</td>

                                            </tr>

                                            <tr>
                                                <td class="entry cellrowborder" headers="d301069e2657 ">Custom Format</td>

                                                <td class="entry cellrowborder" headers="d301069e2660 ">Use log4j variables to define a custom log
                                                  format. </td>

                                            </tr>

                                        </tbody>
</table>
</div>

                            </div>
</li>

                    </ul>

                </div>
            </li>
<li class="li step stepexpand" id="task_ost_3n4_x1b__O-PROTO-Mess">
                <span class="ph cmd">For protobuf data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_s3c_mz4_45" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e2734">Protobuf Property</th>

                                    <th class="entry cellrowborder" id="d301069e2737">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2734 ">Protobuf Descriptor File </td>

                                    <td class="entry cellrowborder" headers="d301069e2737 ">Descriptor file (.desc) to use. The descriptor file must
                                        be in the <span class="ph">Data Collector</span> resources directory,
                                            <code class="ph codeph">$SDC_RESOURCES</code>.<p class="p">For information about
                                            generating the descriptor file, see <a class="xref" href="../Data_Formats/Protobuf-Prerequisites.html" title="Perform the following prerequisites before reading or writing protobuf data.">Protobuf Data Format Prerequisites</a>. <span class="ph">For more information about environment variables, see
                              <a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_rng_qym_qr">Data Collector Environment Configuration</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2734 ">Message Type</td>

                                    <td class="entry cellrowborder" headers="d301069e2737 ">The fully-qualified name for the message type to use when
                                        reading data.<p class="p">Use the following format:
                                                <code class="ph codeph">&lt;package name&gt;.&lt;message
                                            type&gt;</code>. </p>
Use a message type defined in the
                                        descriptor file.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2734 ">Delimited Messages</td>

                                    <td class="entry cellrowborder" headers="d301069e2737 ">Indicates if a message might include more than one
                                        protobuf message.</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand" id="task_ost_3n4_x1b__Text">
                <span class="ph cmd">For text data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_ngy_vcc_fv" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e2825">Text Property</th>

                                    <th class="entry cellrowborder" id="d301069e2828">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2825 ">Max Line Length</td>

                                    <td class="entry cellrowborder" headers="d301069e2828 ">Maximum number of characters allowed for a line. Longer
                                        lines are truncated.<p class="p">Adds a boolean field to the record to
                                            indicate if it was truncated. The field name is
                                            Truncated. </p>
<p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2825 ">Use Custom Delimiter <a class="xref" href="../Data_Formats/TextCDelim.html#concept_lg2_gcg_jx">
                                            <img class="image" id="task_ost_3n4_x1b__d66e2665" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d301069e2828 ">Uses custom delimiters to define records instead of line
                                        breaks. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2825 ">Custom Delimiter</td>

                                    <td class="entry cellrowborder" headers="d301069e2828 ">One or more characters to use to define records. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2825 ">Include Custom Delimiter</td>

                                    <td class="entry cellrowborder" headers="d301069e2828 ">Includes delimiter characters in the record.</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2825 ">Charset</td>

       <td class="entry cellrowborder" headers="d301069e2828 ">Character encoding of the files to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2825 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_ost_3n4_x1b__d42e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d301069e2828 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand" id="task_ost_3n4_x1b__XMLprops">
                <span class="ph cmd">For XML data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_ost_3n4_x1b__table_pmz_mcj_45" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d301069e2941">XML Property</th>

                                    <th class="entry cellrowborder" id="d301069e2944">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2941 ">Delimiter Element <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_tmc_4bc_dy">
                                            <img class="image" id="task_ost_3n4_x1b__d66e2915" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d301069e2944 ">
                                        <div class="p">Delimiter to use to generate records. Omit a delimiter to
                                            treat the entire XML document as one record. Use one of
                                            the following:<ul class="ul" id="task_ost_3n4_x1b__d66e2921">
                                                <li class="li">An XML element directly under the root element.
                                                  <p class="p">Use the XML element name without surrounding
                                                  angle brackets ( &lt; &gt; ) . For example, msg
                                                  instead of &lt;msg&gt;. </p>
</li>

                                                <li class="li">A simplified XPath expression that specifies the
                                                  data to use.<p class="p">Use a simplified XPath expression
                                                  to access data deeper in the XML document or data
                                                  that requires a more complex access
                                                  method.</p>
<p class="p">For more information about valid
                                                  syntax, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_tmc_4bc_dy">Simplified XPath Syntax</a>.</p>
</li>

                                            </ul>
</div>

                                    </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2941 ">Include Field XPaths <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_w3k_1ch_qz">
                                            <img class="image" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d301069e2944 ">Includes the XPath to each parsed XML element and XML
                                        attribute in field attributes. Also includes each namespace
                                        in an xmlns record header attribute. <p class="p">When not selected,
                                            this information is not included in the record. By
                                            default, the property is not selected.</p>
<div class="p">
                                            <div class="note note"><span class="notetitle">Note:</span> <span class="ph">Field attributes and record header attributes are
                        written to destination systems automatically only when you use the SDC RPC
                        data format in destinations. For more information about working with field
                        attributes and record header attributes, and how to include them in records,
                        see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a> and <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_wn2_jcz_dz">Record Header Attributes</a>.</span></div>

                                        </div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2941 ">Namespaces </td>

                                    <td class="entry cellrowborder" headers="d301069e2944 ">Namespace prefix and URI to use when parsing the XML
                                        document. Define namespaces when the XML element being used
                                        includes a namespace prefix or when the XPath expression
                                        includes namespaces.<p class="p">For information about using
                                            namespaces with an XML element, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_ilc_r3g_2y">Using XML Elements with Namespaces</a>.</p>
<p class="p">For information about using namespaces with
                                            XPath expressions, see <a class="xref" href="../Data_Formats/XMLDFormat.html#concept_mkk_3zj_dy">Using XPath Expressions with Namespaces</a>.</p>
<p class="p">Using <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a>, click the
                                                <span class="ph uicontrol">Add</span> icon to add additional
                                            namespaces.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2941 ">Output Field Attributes</td>

                                    <td class="entry cellrowborder" headers="d301069e2944 ">Includes XML attributes and namespace declarations in the
                                        record as field attributes. When not selected, XML
                                        attributes and namespace declarations are included in the
                                        record as fields.<div class="note note"><span class="notetitle">Note:</span> <span class="ph">Field attributes are automatically included in
                        records written to destination systems only when you use the SDC RPC data
                        format in the destination.</span> For more information about working with field
                                            attributes, see <a class="xref" href="../Pipeline_Design/FieldAttributes.html#concept_xfm_wtp_1z" title="Field attributes are attributes that provide additional information about each field that you can use in pipeline logic, as needed.">Field Attributes</a>.</div>
<p class="p">By default, the property is not
                                            selected.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d301069e2941 ">Max Record Length (chars) </td>

                                    <td class="entry cellrowborder" headers="d301069e2944 ">
                                        <p class="p">The maximum number of characters in a record. Longer
                                            records are diverted to the pipeline for error handling. </p>

                                        <p class="p"><span class="ph">This property can be limited by the <span class="ph">Data Collector</span> parser
                        buffer size. For more information, see <a class="xref" href="Origins_overview.html#concept_svg_2zl_d1b">Maximum Record Size</a>.</span></p>

                                    </td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2941 ">Charset</td>

       <td class="entry cellrowborder" headers="d301069e2944 ">Character encoding of the files to be processed.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d301069e2941 ">Ignore Ctrl Characters <a class="xref" href="../Pipeline_Design/ControlCharacters.html" title="You can use several stages to remove control characters - such as escape or end-of-transmission characters - from data. Remove control characters to avoid creating invalid records.">
         <img class="image" id="task_ost_3n4_x1b__d42e733" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d301069e2944 ">Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
</ol>

    </div>

</article>
</article>
</article></main></div>
                        
                        
                        
                    </div>
                    
                </div>
            </div>
        </div> <nav class="navbar navbar-default wh_footer">
  <div class=" footer-container text-center ">
    <!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script>
  </div>
</nav>

        
        <div id="go2top">
            <span class="glyphicon glyphicon-chevron-up"></span>
        </div>
        
        <!-- The modal container for images -->
        <div id="modal_img_large" class="modal">
            <span class="close glyphicon glyphicon-remove"></span>
            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="modal-img" />
            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>
        
        <script src="../../../oxygen-webhelp/lib/bootstrap/js/bootstrap.min.js" type="text/javascript"></script>
        © Apache License, Version 2.0.
    </body>
</html>