
<!DOCTYPE html
  PUBLIC "" "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:whc="http://www.oxygenxml.com/webhelp/components" xml:lang="en-us" lang="en-us">
    <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="shortcut icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><link rel="icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link>        
      <meta name="copyright" content="(C) Copyright 2018" /><meta name="DC.rights.owner" content="(C) Copyright 2018" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Pipeline Statistics" /><meta name="abstract" content="A Control Hub job defines the pipeline to run and the Data Collectors that run the pipeline. When you start a job, Control Hub remotely runs the pipeline on the group of Data Collectors. To monitor the job statistics and metrics within Control Hub, you must configure the pipeline to write statistics to Control Hub or to another system." /><meta name="description" content="A Control Hub job defines the pipeline to run and the Data Collectors that run the pipeline. When you start a job, Control Hub remotely runs the pipeline on the group of Data Collectors. To monitor the job statistics and metrics within Control Hub, you must configure the pipeline to write statistics to Control Hub or to another system." /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/DPM/DPM_title.html" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/DPM/RegisterSDCwithDPM.html#concept_kc4_xyf_xw" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/DPM/PipelineManagement.html#concept_eq5_qjd_fx" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="DC.Date.Created" content="2014-10-31" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_h2q_mb5_xw" /><title>Pipeline Statistics</title><!--  Generated with Oxygen version 20.0-SNAPSHOT, build number 2018042310.  --><meta name="wh-path2root" content="../../../" /><meta name="wh-toc-id" content="concept_h2q_mb5_xw-d46e99939" />         
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- Latest compiled and minified Bootstrap CSS -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap.min.css" />

        <!-- Bootstrap Optional theme -->
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap-theme.min.css" />
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/jquery-ui/jquery-ui.min.css" />

        <!-- Template default styles  -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/app/topic-page.css?buildId=2018042310" />
        

        <script type="text/javascript" src="../../../oxygen-webhelp/lib/jquery/jquery-3.1.1.min.js"><!----></script>

        <script data-main="../../../oxygen-webhelp/app/topic-page.js" src="../../../oxygen-webhelp/lib/requirejs/require.js"></script>
        
        <!-- Skin resources -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/template/light.css?buildId=2018042310" />
        <!-- EXM-36950 - Expand the args.hdf parameter here -->
        
        
    <link rel="stylesheet" type="text/css" href="../../../skin.css" /></head>

    <body class="wh_topic_page frmBody">
        <!-- EXM-36950 - Expand the args.hdr parameter here -->
        
        
        
<nav class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div class="wh_header_flex_container">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <!--
                            This component will be generated when the next parameters are specified in the transformation scenario:
                            'webhelp.logo.image' and 'webhelp.logo.image.target.url'.
                            See: http://oxygenxml.com/doc/versions/17.1/ug-editor/#topics/dita_webhelp_output.html.
                    -->
                    <a href="../../../index.html" class=" wh_logo hidden-xs "></a>
                    <div class=" wh_publication_title "><a href="../../../index.html"><span class="booktitle">  <span class="ph mainbooktitle"><span class="ph">Data Collector</span> User Guide</span>  </span></a></div>
                    
                </div>
                
                <!-- The menu button for mobile devices is copied in the output only when the 'webhelp.show.top.menu' parameter is set to 'yes' -->
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse">
                
                
                <div class=" wh_indexterms_link "><a href="../../../indexTerms.html" title="Index"><span>Index</span></a></div>
                
            </div>
        </div>
    </div>
</nav>

        <div class=" wh_search_input "><form id="searchForm" method="get" action="../../../search.html"><div><input type="search" placeholder="Search " class="wh_search_textfield" id="textToSearch" name="searchQuery" /><button type="submit" class="wh_search_button"><span>Search</span></button></div><script><!--
                                    $(document).ready(function () {
                                        $('#searchForm').submit(function (e) {
                                            if ($('.wh_search_textfield').val().length < 1) {
                                                e.preventDefault();
                                            }
                                        });
                                    });
                                --></script></form></div>
        
        <div class="container-fluid">
            <div class="row">

                <nav class="wh_tools hidden-print">
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol xmlns:html="http://www.w3.org/1999/xhtml" class="hidden-print"><li><span class="home"><a href="../../../index.html"><span>Home</span></a></span></li>
   <li><span class="topicref" data-id="concept_ugp_kwf_xw"><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM_title.html">StreamSets Control Hub</a></span></span></li>
   <li class="active"><span class="topicref" data-id="concept_h2q_mb5_xw"><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_h2q_mb5_xw">Pipeline Statistics</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">A <span class="ph">Control Hub</span>         job defines the pipeline to run and the <span class="ph">Data Collector</span>s that         run the pipeline. When you start a job, <span class="ph">Control Hub</span>         remotely runs the pipeline on the group of <span class="ph">Data Collector</span>s. To         monitor the job statistics and metrics within <span class="ph">Control Hub</span>, you         must configure the pipeline to write statistics to <span class="ph">Control Hub</span> or to         another system.
                  
               </p>
               </span></span></span></li>
</ol></div>

                    <div class="wh_right_tools hidden-sm hidden-xs">
                        <div class=" wh_navigation_links "><span id="topic_navigation_links" class="navheader">
  
<span class="navprev"><a class="link" href="../../../datacollector/UserGuide/DPM/RegisterSDCwithDPM.html#concept_kc4_xyf_xw" title="Register Data Collector with Control Hub"></a></span>  
<span class="navnext"><a class="link" href="../../../datacollector/UserGuide/DPM/PipelineManagement.html#concept_eq5_qjd_fx" title="Pipeline Management with Control Hub"></a></span>  </span></div>
                        <button class="wh_hide_highlight" title="Toggle search highlights"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" title="Collapse sections"></button>
                        <div class=" wh_print_link print "><a href="javascript:window.print();" title="Print this page"></a></div>
                    </div>
                </nav>
            </div>

            <div class="wh_content_area">
                <div class="row">
                    
                        <nav role="navigation" id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-3 hidden-xs navbar hidden-print">
                            <div class=" wh_publication_toc " data-tooltip-position="right"><ul>
   <li><span data-tocid="concept_htw_ghg_jq-d46e54" class="topicref" data-id="concept_htw_ghg_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Getting_Started/GettingStarted_Title.html#concept_htw_ghg_jq">Getting Started</a></span></span></li>
   <li><span data-tocid="concept_hz3_5fk_fy-d46e557" class="topicref" data-id="concept_hz3_5fk_fy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/WhatsNew/WhatsNew_Title.html#concept_hz3_5fk_fy">What's New</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_l4q_flb_kr-d46e4414" class="topicref" data-id="concept_l4q_flb_kr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Installation/Install_title.html">Installation</a></span></span></li>
   <li><span data-tocid="concept_ylh_yyz_ky-d46e6481" class="topicref" data-id="concept_ylh_yyz_ky" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Configuration/Config_title.html">Configuration</a></span></span></li>
   <li><span data-tocid="concept_ejk_f1f_5v-d46e13895" class="topicref" data-id="concept_ejk_f1f_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Upgrade/Upgrade_title.html">Upgrade</a></span></span></li>
   <li><span data-tocid="concept_qsw_cjy_bt-d46e18499" class="topicref" data-id="concept_qsw_cjy_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Design/PipelineDesign_title.html">Pipeline Concepts and Design</a></span></span></li>
   <li><span data-tocid="concept_qn1_wn4_kq-d46e20154" class="topicref" data-id="concept_qn1_wn4_kq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Configuration/PipelineConfiguration_title.html">Pipeline Configuration</a></span></span></li>
   <li><span data-tocid="concept_hdr_gyw_41b-d46e22651" class="topicref" data-id="concept_hdr_gyw_41b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Formats/DataFormats-Title.html">Data Formats</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e24466" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e64169" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Processors/Processors_title.html">Processors</a></span></span></li>
   <li><span data-tocid="concept_agj_cfj_br-d46e77391" class="topicref" data-id="concept_agj_cfj_br" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations-title.html">Destinations</a></span></span></li>
   <li><span data-tocid="concept_umc_1lk_fx-d46e92871" class="topicref" data-id="concept_umc_1lk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-title.html">Executors</a></span></span></li>
   <li><span data-tocid="concept_ugp_kwf_xw-d46e98772" class="topicref" data-id="concept_ugp_kwf_xw" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM_title.html">StreamSets Control Hub</a></span></span><ul class="nav nav-list">
         <li><span data-tocid="concept_l45_qwf_xw-d46e98794" class="topicref" data-id="concept_l45_qwf_xw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM.html#concept_l45_qwf_xw">Meet <span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">StreamSets Control Hub</span></a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"><span class="ph">StreamSets Control Hub</span><sup class="ph sup">TM</sup> is a central point of control for all of your dataflow pipelines. <span class="ph">Control Hub</span> allows         teams to build and execute large numbers of complex dataflows at scale. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_evb_3bs_bx-d46e99215" class="topicref" data-id="concept_evb_3bs_bx" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/WorkingWithDPM.html#concept_evb_3bs_bx">Working with <span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">Control Hub</span></a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_lry_34g_xw-d46e99241" class="topicref" data-id="concept_lry_34g_xw" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/OrgUserAccount.html#concept_lry_34g_xw">Request a <span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">Control Hub</span> Organization and User Account
                     </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kc4_xyf_xw-d46e99268" class="topicref" data-id="concept_kc4_xyf_xw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/RegisterSDCwithDPM.html#concept_kc4_xyf_xw">Register Data Collector with <span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">Control Hub</span></a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">You must register a <span class="ph">Data Collector</span> to         work with <span class="ph">StreamSets Control Hub</span>.         When you register a <span class="ph">Data Collector</span>, <span class="ph">Data Collector</span>         generates an authentication token that it uses to issue authenticated requests to <span class="ph">Control Hub</span>.
                        
                     </p>
                     </span></span></span></li>
         <li class="active"><span data-tocid="concept_h2q_mb5_xw-d46e99939" class="topicref" data-id="concept_h2q_mb5_xw" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_h2q_mb5_xw">Pipeline Statistics</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">A <span class="ph">Control Hub</span>         job defines the pipeline to run and the <span class="ph">Data Collector</span>s that         run the pipeline. When you start a job, <span class="ph">Control Hub</span>         remotely runs the pipeline on the group of <span class="ph">Data Collector</span>s. To         monitor the job statistics and metrics within <span class="ph">Control Hub</span>, you         must configure the pipeline to write statistics to <span class="ph">Control Hub</span> or to         another system.
                        
                     </p>
                     </span></span></span><ul class="nav nav-list">
               <li><span data-tocid="concept_pyb_2fc_jcb-d46e100124" class="topicref" data-id="concept_pyb_2fc_jcb" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_pyb_2fc_jcb">Pipeline Execution Mode</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">Pipelines can run in standalone, cluster, or edge execution mode. Some pipeline         execution modes do not support all
                              statistics aggregator options.
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_abc_1w1_c1b-d46e100149" class="topicref" data-id="concept_abc_1w1_c1b" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_abc_1w1_c1b">Write Statistics Directly to <span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">Control Hub</span></a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">When you write statistics directly to <span class="ph">Control Hub</span>, <span class="ph">Control Hub</span> does         not generate a system pipeline for the job. Instead, the <span class="ph">Data Collector</span>         directly sends the statistics to <span class="ph">Control Hub</span>.
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_c53_pzp_yy-d46e100198" class="topicref" data-id="concept_c53_pzp_yy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_c53_pzp_yy">Write Statistics to SDC RPC</a></span></span></li>
               <li><span data-tocid="concept_wmv_cbb_fx-d46e100292" class="topicref" data-id="concept_wmv_cbb_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_wmv_cbb_fx">Write Statistics to Kafka</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">When you write statistics to a Kafka cluster, <span class="ph">Data Collector</span>         effectively adds a Kafka Producer destination to the pipeline that you are configuring. <span class="ph">Control Hub</span>         automatically generates and runs a system pipeline for the job. The system pipeline reads         the statistics
                              from Kafka, and then aggregates and sends the statistics to <span class="ph">Control Hub</span>. 
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_em4_2bb_fx-d46e100525" class="topicref" data-id="concept_em4_2bb_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_em4_2bb_fx">Write Statistics to Kinesis Streams</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"> When you write statistics to Amazon Kinesis Streams, <span class="ph">Data Collector</span>         effectively adds a Kinesis Producer destination to the pipeline that you are configuring.             <span class="ph">Control Hub</span>         automatically generates and runs a system pipeline for the job. The system pipeline reads         the statistics
                              from Kinesis Streams, and then aggregates and sends the statistics to <span class="ph">Control Hub</span>. 
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_qh5_v5t_mbb-d46e100849" class="topicref" data-id="concept_qh5_v5t_mbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#concept_qh5_v5t_mbb">Write Statistics to MapR Streams</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">When you write statistics to MapR Streams, <span class="ph">Data Collector</span>         effectively adds a MapR Streams Producer destination to the pipeline that you are         configuring. <span class="ph">Control Hub</span>         automatically generates and runs a system pipeline for the job. The system pipeline reads         the statistics
                              from MapR Streams, and then aggregates and sends the statistics to <span class="ph">Control Hub</span>. 
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="task_lcd_ng5_xw-d46e101263" class="topicref" data-id="task_lcd_ng5_xw" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/AggregatedStatistics.html#task_lcd_ng5_xw">Configuring a Pipeline to Write Statistics</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">You can configure a pipeline to write statistics<span class="ph"> after the <span class="ph">Data Collector</span>             has been registered with <span class="ph">Control Hub</span></span>.
                              
                           </p>
                           </span></span></span></li>
            </ul>
         </li>
         <li><span data-tocid="concept_eq5_qjd_fx-d46e101427" class="topicref" data-id="concept_eq5_qjd_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/PipelineManagement.html#concept_eq5_qjd_fx">Pipeline Management with <span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">Control Hub</span></a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">After you register a <span class="ph">Data Collector</span> with             <span class="ph">StreamSets Control Hub</span>,         you can manage how the pipelines work with <span class="ph">Control Hub</span>.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hrn_zz3_fx-d46e101932" class="topicref" data-id="concept_hrn_zz3_fx" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPMConfiguration.html#concept_hrn_zz3_fx"><span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">Control Hub</span> Configuration File
                     </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ldb_sr5_cx-d46e101958" class="topicref" data-id="concept_ldb_sr5_cx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/UnregisterSDCwithDPM.html#concept_ldb_sr5_cx">Unregister Data Collector from <span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">Control Hub</span></a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">You can unregister a <span class="ph">Data Collector</span> from             <span class="ph">StreamSets Control Hub</span>         when you no longer want to use that <span class="ph">Data Collector</span>         installation with <span class="ph">Control Hub</span>. 
                        
                     </p>
                     </span></span></span></li>
      </ul>
   </li>
   <li><span data-tocid="concept_xxd_f5r_kx-d46e102096" class="topicref" data-id="concept_xxd_f5r_kx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Event_Handling/EventFramework-Title.html#concept_xxd_f5r_kx">Dataflow Triggers</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fjj_zcf_2w-d46e106011" class="topicref" data-id="concept_fjj_zcf_2w" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w">Drift Synchronization Solution for Hive</a></span></span></li>
   <li><span data-tocid="concept_kgt_pnr_4cb-d46e108837" class="topicref" data-id="concept_kgt_pnr_4cb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/JDBC_DriftSolution/JDBC_DriftSyncSolution_title.html#concept_kgt_pnr_4cb">Drift Synchronization Solution for PostgreSQL</a></span></span></li>
   <li><span data-tocid="concept_wwq_gxc_py-d46e109636" class="topicref" data-id="concept_wwq_gxc_py" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wwq_gxc_py">Multithreaded Pipelines</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fyf_gkq_4bb-d46e110218" class="topicref" data-id="concept_fyf_gkq_4bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Edge_Mode/EdgePipelines_title.html">Edge Pipelines</a></span></span></li>
   <li><span data-tocid="concept_wr1_ktz_bt-d46e111818" class="topicref" data-id="concept_wr1_ktz_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/RPC_Pipelines/SDC_RPCpipelines_title.html#concept_wr1_ktz_bt">SDC RPC Pipelines</a></span></span></li>
   <li><span data-tocid="concept_fpz_5r4_vs-d46e112299" class="topicref" data-id="concept_fpz_5r4_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Cluster_Mode/ClusterPipelines_title.html">Cluster Pipelines</a></span></span></li>
   <li><span data-tocid="concept_jjk_23z_sq-d46e113641" class="topicref" data-id="concept_jjk_23z_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Preview/DataPreview_Title.html#concept_jjk_23z_sq">Data Preview</a></span></span></li>
   <li><span data-tocid="concept_pgk_brx_rr-d46e114610" class="topicref" data-id="concept_pgk_brx_rr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Alerts/RulesAlerts_title.html#concept_pgk_brx_rr">Rules and Alerts</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_asx_fdz_sq-d46e117238" class="topicref" data-id="concept_asx_fdz_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Monitoring/PipelineMonitoring_title.html#concept_asx_fdz_sq">Pipeline Monitoring</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_o3l_dtr_5q-d46e118495" class="topicref" data-id="concept_o3l_dtr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Maintenance/PipelineMaintenance_title.html#concept_o3l_dtr_5q">Pipeline Maintenance</a></span></span></li>
   <li><span data-tocid="concept_yms_ftm_sq-d46e120286" class="topicref" data-id="concept_yms_ftm_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Administration/Administration_title.html#concept_yms_ftm_sq">Administration</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_nls_w1r_ks-d46e124782" class="topicref" data-id="concept_nls_w1r_ks" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Tutorial/Tutorial-title.html">Tutorial</a></span></span></li>
   <li><span data-tocid="concept_sh3_frm_tq-d46e125996" class="topicref" data-id="concept_sh3_frm_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Troubleshooting/Troubleshooting_title.html#concept_sh3_frm_tq">Troubleshooting</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_xbx_rs1_tq-d46e129904" class="topicref" data-id="concept_xbx_rs1_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Glossary/Glossary_title.html#concept_xbx_rs1_tq">Glossary</a></span></span></li>
   <li><span data-tocid="concept_jn1_nzb_kv-d46e129959" class="topicref" data-id="concept_jn1_nzb_kv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-DataFormats/DataFormat_Title.html#concept_jn1_nzb_kv">Data Formats by Stage</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_pvm_yt3_wq-d46e130119" class="topicref" data-id="concept_pvm_yt3_wq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Expression_Language/ExpressionLanguage_title.html">Expression Language</a></span></span></li>
   <li><span data-tocid="concept_vcj_1ws_js-d46e131600" class="topicref" data-id="concept_vcj_1ws_js" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-RegEx/RegEx-Title.html#concept_vcj_1ws_js">Regular Expressions</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_chv_vmj_wr-d46e131822" class="topicref" data-id="concept_chv_vmj_wr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-GrokPatterns/GrokPatterns_title.html#concept_chv_vmj_wr">Grok Patterns</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
</ul></div>
                        </nav>
                    
                    
                    <div class="col-lg-9 col-md-9 col-sm-9 col-xs-12" id="wh_topic_body">
                        <div class=" wh_topic_content body "><main role="main"><article role="article" aria-labelledby="ariaid-title1"><article class="nested0" aria-labelledby="ariaid-title1" id="concept_h2q_mb5_xw">
 <h1 class="title topictitle1" id="ariaid-title1">Pipeline Statistics</h1>

 
 <div class="body conbody"><p class="shortdesc">A <span class="ph">Control Hub</span>
        job defines the pipeline to run and the <span class="ph">Data Collector</span>s that
        run the pipeline. When you start a job, <span class="ph">Control Hub</span>
        remotely runs the pipeline on the group of <span class="ph">Data Collector</span>s. To
        monitor the job statistics and metrics within <span class="ph">Control Hub</span>, you
        must configure the pipeline to write statistics to <span class="ph">Control Hub</span> or to
        another system.</p>

  <p class="p">When a job runs on a
            single <span class="ph">Data Collector</span>,
            you can simply configure the pipeline to write the statistics directly to <span class="ph">Control Hub</span>. By
            default, pipelines are configured to write statistics directly to <span class="ph">Control Hub</span>.</p>

        <p class="p">When a job runs on multiple <span class="ph">Data Collector</span>s,
            a remote pipeline instance runs on each of the <span class="ph">Data Collector</span>s.
            To view aggregated statistics for the job within <span class="ph">Control Hub</span>,
            you must configure the pipeline to write the statistics to one of the following
            systems:</p>

        <ul class="ul" id="concept_h2q_mb5_xw__ul_e23_pxp_yy">
            <li class="li">SDC RPC</li>

            <li class="li">Kafka cluster</li>

            <li class="li">Amazon Kinesis Streams</li>

            <li class="li">MapR Streams</li>

        </ul>

        <p class="p">When you start a job that includes a pipeline configured to write to Kafka, Kinesis, MapR
            Streams, or SDC RPC, <span class="ph">Control Hub</span>
            automatically generates and runs a system pipeline for the job. The system pipeline
            reads the statistics written by each running pipeline instance to Kafka, Kinesis, MapR
            Streams, or SDC RPC. Then, the system pipeline aggregates and sends the statistics to
                <span class="ph">Control Hub</span>. </p>

        <div class="note important"><span class="importanttitle">Important:</span> For a production environment, use a Kafka
                  cluster, Amazon Kinesis Streams, or MapR Streams to aggregate statistics. Using
                  SDC RPC to aggregate statistics is not highly available and might cause the loss
                  of some data. It should be used for development purposes only.</div>

        <p class="p">When a <span class="ph">Control Hub</span> job includes a pipeline that is configured to write statistics, you can view the
            statistics and metrics when you monitor the job in <span class="ph">Control Hub</span>:</p>

        <p class="p"><img class="image" id="concept_h2q_mb5_xw__image_h2w_wxs_gx" src="../Graphics/DPM_MonitorJob.png" height="320" width="719" /></p>

        <p class="p">When a <span class="ph">Control Hub</span> job includes a pipeline that is configured to discard statistics, <span class="ph">Control Hub</span>
            cannot display statistics and metrics for the job. Instead, <span class="ph">Control Hub</span>
            displays the following warning message when you monitor the job:</p>

        <pre class="pre codeblock"><code>Aggregated metrics for the job are not available as individual pipeline metrics are discarded.</code></pre>
 </div>

<article class="topic concept nested1" aria-labelledby="ariaid-title2" id="concept_pyb_2fc_jcb">
    <h2 class="title topictitle2" id="ariaid-title2">Pipeline Execution Mode</h2>

    
    <div class="body conbody"><p class="shortdesc">Pipelines can run in standalone, cluster, or edge execution mode. Some pipeline
        execution modes do not support all statistics aggregator options.</p>

        <div class="p">The following table lists each pipeline execution mode and the statistics aggregator
            options that it supports:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_pyb_2fc_jcb__table_ihb_ggc_jcb" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                        <tr>
                            <th class="entry cellrowborder" id="d48560e367">Pipeline Execution Mode</th>

                            <th class="entry cellrowborder" id="d48560e370">Supported Statistics Aggregator Options</th>

                        </tr>

                    </thead>
<tbody class="tbody">
                        <tr>
                            <td class="entry cellrowborder" headers="d48560e367 ">Standalone</td>

                            <td class="entry cellrowborder" headers="d48560e370 ">All options are supported.</td>

                        </tr>

                        <tr>
                            <td class="entry cellrowborder" headers="d48560e367 "><a class="xref" href="../Cluster_Mode/ClusterPipelines.html#concept_hmh_kfn_1s" title="A cluster pipeline is a pipeline that runs in cluster execution mode. You can run a pipeline in standalone execution mode or cluster execution mode.">Cluster</a></td>

                            <td class="entry cellrowborder" headers="d48560e370 ">
                                <ul class="ul" id="concept_pyb_2fc_jcb__ul_dcj_vgc_jcb">
                                    <li class="li">Write to SDC RPC</li>

                                    <li class="li">Write to Kafka</li>

                                    <li class="li">Write to Kinesis Streams</li>

                                    <li class="li">Write to MapR Streams</li>

                                </ul>

                            </td>

                        </tr>

                        <tr>
                            <td class="entry cellrowborder" headers="d48560e367 "><a class="xref" href="../Edge_Mode/EdgePipelines_Overview.html#concept_d4h_kkq_4bb" title="An edge pipeline is a pipeline that runs on an edge device with limited resources. Use edge pipelines to read data from the edge device or to receive data from another pipeline and then act on that data to control the edge device.">Edge</a></td>

                            <td class="entry cellrowborder" headers="d48560e370 ">
                                <ul class="ul" id="concept_pyb_2fc_jcb__ul_ubg_3gc_jcb">
                                    <li class="li">Write to SCH Directly</li>

                                </ul>

                            </td>

                        </tr>

                    </tbody>
</table>
</div>
</div>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title3" id="concept_abc_1w1_c1b">
 <h2 class="title topictitle2" id="ariaid-title3">Write Statistics Directly to <span class="ph">Control Hub</span></h2>

 
 <div class="body conbody"><p class="shortdesc">When you write statistics directly to <span class="ph">Control Hub</span>, <span class="ph">Control Hub</span> does
        not generate a system pipeline for the job. Instead, the <span class="ph">Data Collector</span>
        directly sends the statistics to <span class="ph">Control Hub</span>.</p>

  <p class="p">Write statistics directly to <span class="ph">Control Hub</span>
            when the job runs on a single <span class="ph">Data Collector</span>.
            If the job runs on multiple <span class="ph">Data Collector</span>s,
                <span class="ph">Control Hub</span>
            can display the pipeline statistics for each individual <span class="ph">Data Collector</span>.
            However, <span class="ph">Control Hub</span>
            cannot display an aggregated view of the statistics across all running pipeline
            instances.</p>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title4" id="concept_c53_pzp_yy">
 <h2 class="title topictitle2" id="ariaid-title4">Write Statistics to SDC RPC</h2>

 <div class="body conbody">
        <p class="p">When you write statistics to SDC RPC, <span class="ph">Data Collector</span>
            effectively adds an SDC RPC destination to the pipeline that you are configuring. <span class="ph">Control Hub</span>
            automatically generates and runs a system pipeline for the job. The system pipeline is a
            pipeline with a Dev SDC RPC with Buffering origin that reads the statistics passed from
            the SDC RPC destination, and then aggregates and sends the statistics to <span class="ph">Control Hub</span>. </p>

        <p class="p">Write statistics to SDC RPC when the job runs on multiple <span class="ph">Data Collector</span>s.</p>

        <div class="p">When you configure a pipeline to write statistics to an SDC RPC destination, you specify
            the following information: <ul class="ul" id="concept_c53_pzp_yy__ul_dzy_wm3_1z">
                <li class="li">SDC RPC connection - The host and port number of the <span class="ph">Data Collector</span> machine where <span class="ph">Control Hub</span> starts the system pipeline. The host must be a <span class="ph">Data Collector</span> machine registered with <span class="ph">Control Hub</span> that can run a pipeline for the job. A <span class="ph">Data Collector</span> can run the pipeline when it has all labels associated with the job. <p class="p">For
                        example, if you associate the job with the WestCoast label, then the host
                        specified in the RPC connection must be a machine with a registered <span class="ph">Data Collector</span> that also has the WestCoast label.</p>
</li>

                <li class="li">SDC RPC ID - A user-defined identifier that allows SDC RPC stages to recognize
                    each other. To avoid mixing statistics from different jobs, use a unique ID for
                    each job.</li>

            </ul>
</div>

        <p class="p">You can optionally enable encryption to pass data securely and define retry and timeout
            properties.</p>

  <div class="p">
            <div class="note important"><span class="importanttitle">Important:</span> For a production environment, use a Kafka
                  cluster, Amazon Kinesis Streams, or MapR Streams to aggregate statistics. Using
                  SDC RPC to aggregate statistics is not highly available and might cause the loss
                  of some data. It should be used for development purposes only.</div>

        </div>

        <p class="p">For more information about SDC RPC pipelines, see <a class="xref" href="../RPC_Pipelines/SDC_RPCpipelines_title.html#concept_lnh_z3z_bt" title="Data Collector Remote Protocol Call pipelines, a.k.a. SDC RPC pipelines, are a set of StreamSets pipelines that pass data from one pipeline to another without writing to an intermediary system.">SDC RPC Pipeline Overview</a>.</p>

 </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title5" id="concept_e1d_nzr_yy">
 <h3 class="title topictitle3" id="ariaid-title5">Best Practices for SDC RPC</h3>

 <div class="body conbody">
  <div class="p">Consider the following best
            practices when you configure a pipeline to write statistics to an SDC RPC destination:
                <ul class="ul" id="concept_e1d_nzr_yy__ul_irc_szr_yy">
                <li class="li">To avoid mixing statistics from different jobs, use a unique SDC RPC ID for each
                    job. </li>

                <li class="li">Monitor the disk space where the Dev SDC RPC with Buffering origin in the system
                    pipeline temporarily buffers the records to disk before passing the records to
                    the next stage in the pipeline.<p class="p">The Dev SDC RPC with Buffering origin in the
                        system pipeline temporarily buffers the statistics to a queue on disk. If
                        the system pipeline slows, the temporary location on disk might become full.
                        The temporary statistics are written to the location specified in the
                            <code class="ph codeph">java.io.tmpdir</code> system property, to a file with the
                        following
                    name:</p>
<pre class="pre codeblock"><code>sdc-fragments&lt;file ID&gt;.queueFile</code></pre></li>

            </ul>
</div>

 </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title6" id="concept_wmv_cbb_fx">
 <h2 class="title topictitle2" id="ariaid-title6">Write Statistics to Kafka</h2>

 
 <div class="body conbody"><p class="shortdesc">When you write statistics to a Kafka cluster, <span class="ph">Data Collector</span>
        effectively adds a Kafka Producer destination to the pipeline that you are configuring. <span class="ph">Control Hub</span>
        automatically generates and runs a system pipeline for the job. The system pipeline reads
        the statistics from Kafka, and then aggregates and sends the statistics to <span class="ph">Control Hub</span>. </p>

        <p class="p">Write statistics to a Kafka cluster when the
            job runs on multiple <span class="ph">Data Collector</span>s.</p>

        <p class="p">When you write statistics to a Kafka cluster, you define connection information and the
            topic to write to. </p>

        <p class="p">You also configure the partition strategy. The pipeline passes data to partitions in the
            Kafka topic based on the partition strategy that you choose. You can add additional
            Kafka configuration properties as needed. </p>

        <div class="note note"><span class="notetitle">Note:</span> At this time, you cannot configure the pipeline to connect securely through SSL/TLS or
            Kerberos when using Kafka.</div>

    </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title7" id="concept_wph_j2b_fx">
 <h3 class="title topictitle3" id="ariaid-title7">Partition Strategy</h3>

 
 <div class="body conbody"><p class="shortdesc">The partition strategy determines how to write statistics to Kafka partitions. You can
        use a partition strategy to balance the work load or to write data semantically.</p>

        <p class="p">The pipeline can use one of the following partition strategies:</p>

        <p class="p">
            
        </p>

     <dl class="dl">
         
             <dt class="dt dlterm">Round-Robin</dt>

             <dd class="dd">Writes statistics to a different partition using a cyclical order. Use for load
                    balancing. </dd>

         
         
             <dt class="dt dlterm">Random</dt>

             <dd class="dd">Writes statistics to a different partition using a random order. Use for load
                    balancing.</dd>

         
         
                <dt class="dt dlterm">Expression</dt>

                <dd class="dd">Writes statistics to a partition based on the results of the partition
                    expression. Use to perform semantic partitioning. </dd>

                <dd class="dd ddexpand">When you configure the partition expression, define the expression to evaluate
                    to the partition where you want statistics written. </dd>

            
            
                <dt class="dt dlterm">Default</dt>

                <dd class="dd">Writes statistics using the default partition strategy that Kafka provides.</dd>

            
     </dl>

    </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title8" id="concept_bmq_ff5_xw">
 <h3 class="title topictitle3" id="ariaid-title8">Best Practices for a Kafka Cluster</h3>

 <div class="body conbody">
  <p class="p">Consider the following best
            practices when you configure a pipeline to write statistics to a Kafka cluster: </p>

        <ul class="ul" id="concept_bmq_ff5_xw__ul_vlq_jg5_xw">
            <li class="li">To avoid mixing statistics from different jobs, use a unique topic name for each
                job. </li>

            <li class="li">Consider the Kafka retention policy. <p class="p">Each running pipeline instance writes
                    statistics to Kafka, and then the system pipeline consumes the statistics from
                    Kafka. If the system pipeline unexpectedly shuts down, Kafka retains the
                    statistics for the amount of time determined by the Kafka retention policy. If
                    the system pipeline is down for longer than Kafka retains data, the statistics
                    are lost.</p>
</li>

        </ul>

 </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title9" id="concept_em4_2bb_fx">
 <h2 class="title topictitle2" id="ariaid-title9">Write Statistics to Kinesis Streams</h2>

 
 <div class="body conbody"><p class="shortdesc"> When you write statistics to Amazon Kinesis Streams, <span class="ph">Data Collector</span>
        effectively adds a Kinesis Producer destination to the pipeline that you are configuring.
            <span class="ph">Control Hub</span>
        automatically generates and runs a system pipeline for the job. The system pipeline reads
        the statistics from Kinesis Streams, and then aggregates and sends the statistics to <span class="ph">Control Hub</span>. </p>

        <p class="p">Write statistics to Kinesis Streams when the job runs on multiple <span class="ph">Data Collector</span>s.</p>

        <p class="p">When you write statistics to Kinesis Streams, you define connection information and the
            stream to write to.</p>

        <p class="p">You also configure the partition strategy. The pipeline passes data to partitions in
            Kinesis shards based on the partition strategy that you choose. You can add additional
            Kinesis configuration properties as needed. </p>

 </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title10" id="concept_m3j_2kb_fx">
 <h3 class="title topictitle3" id="ariaid-title10">AWS Credentials</h3>

 
 <div class="body conbody"><p class="shortdesc">When the pipeline writes aggregated statistics to Amazon Kinesis Streams, it must pass
        credentials to Amazon Web Services. </p>

  <p class="p">Use one of the following methods to pass AWS
                credentials:</p>

     <dl class="dl">
         
             <dt class="dt dlterm">IAM roles</dt>

             <dd class="dd">When <span class="ph">Data Collector</span> runs on an Amazon EC2 instance, you can use the AWS Management
                 Console to configure an IAM role for the EC2 instance. <span class="ph">Data Collector</span> uses the IAM instance profile credentials to automatically connect
                 to AWS. </dd>

             <dd class="dd ddexpand">When you use IAM roles, you do not need to specify the Access Key ID and Secret
                    Access Key properties when you configure statistics for the pipeline. </dd>

             <dd class="dd ddexpand">For more information about assigning an IAM role to an EC2 instance, see
                 the Amazon EC2 documentation.</dd>

         
         
             <dt class="dt dlterm">AWS access key pairs</dt>

             <dd class="dd">
                 <p class="p">When <span class="ph">Data Collector</span> does not run on an Amazon EC2 instance or when the EC2 instance doesn’t
                        have an IAM role, you must specify the <span class="ph uicontrol">Access Key ID</span>
                        and <span class="ph uicontrol">Secret Access Key</span> properties when you configure
                        statistics for the pipeline.</p>

             </dd>

         
     </dl>

 </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title11" id="concept_fdy_5f5_xw">
 <h3 class="title topictitle3" id="ariaid-title11">Best Practices for Kinesis Streams</h3>

 <div class="body conbody">
  <p class="p">Consider the following best
            practices when you configure a pipeline to write statistics to Amazon Kinesis Streams: </p>

        <ul class="ul" id="concept_fdy_5f5_xw__ul_w44_3g5_xw">
            <li class="li">To avoid mixing statistics from different jobs, use a unique stream name for each
                job. </li>

            <li class="li">Consider the Kinesis Streams retention policy. <p class="p">Each running pipeline instance
                    writes statistics to Kinesis Streams, and then the system pipeline reads the
                    statistics from Kinesis Streams. If the system pipeline unexpectedly shuts down,
                    Kinesis Streams retains the statistics for the amount of time determined by the
                    Kinesis Streams retention policy. If the system pipeline is down for longer than
                    Kinesis Streams retains data, the statistics are lost.</p>
</li>

        </ul>

 </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title12" id="concept_qh5_v5t_mbb">
 <h2 class="title topictitle2" id="ariaid-title12">Write Statistics to MapR Streams</h2>

 
 <div class="body conbody"><p class="shortdesc">When you write statistics to MapR Streams, <span class="ph">Data Collector</span>
        effectively adds a MapR Streams Producer destination to the pipeline that you are
        configuring. <span class="ph">Control Hub</span>
        automatically generates and runs a system pipeline for the job. The system pipeline reads
        the statistics from MapR Streams, and then aggregates and sends the statistics to <span class="ph">Control Hub</span>. </p>

        <p class="p">Write statistics to MapR Streams when the job
            runs on multiple <span class="ph">Data Collector</span>s.</p>

        <p class="p">When you write statistics to MapR Streams, you define the topic to write to. You also
            configure the partition strategy. The pipeline passes data to partitions in the MapR
            Streams topic based on the partition strategy that you choose. You can add additional
            MapR Streams configuration properties as needed. </p>

     <p class="p">Before you can write statistics to MapR Streams, you must
                  perform additional steps to enable <span class="ph">Data Collector</span> to process MapR
                  data. <span class="ph">For more information, see <a class="xref" href="../Installation/MapR-Prerequisites.html#concept_jgs_qpg_2v" title="Due to licensing restrictions, StreamSets cannot distribute MapR libraries with Data Collector. As a result, you must perform additional steps to enable the Data Collector machine to connect to MapR. Data Collector does not display MapR origins and destinations in stage library lists nor the MapR Streams statistics aggregator in the pipeline properties until you perform these prerequisites.">MapR Prerequisites</a>.</span></p>

 </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title13" id="concept_xsq_1wt_mbb">
 <h3 class="title topictitle3" id="ariaid-title13">Partition Strategy</h3>

 
 <div class="body conbody"><p class="shortdesc">The partition strategy determines how to write statistics to MapR Streams partitions.
        You can use a partition strategy to balance the work load or to write data
        semantically.</p>

        <p class="p">The pipeline can use one of the following partition strategies:</p>

        <p class="p">
            
        </p>

        <div class="p">
            <dl class="dl">
                
                    <dt class="dt dlterm">Round-Robin</dt>

                    <dd class="dd">Writes each record to a different partition using a cyclical order. Use for
                        load balancing.</dd>

                
                
                    <dt class="dt dlterm">Random</dt>

                    <dd class="dd">Writes each record to a different partition using a random order. Use for
                        load balancing.</dd>

                
                
                    <dt class="dt dlterm">Expression</dt>

                    <dd class="dd">Writes each record to a partition based on the results of the partition
                        expression. Use to perform semantic partitioning. </dd>

                    <dd class="dd ddexpand">When you configure the partition expression, define the expression to
                        evaluate to the partition where you want each record written. The expression
                        must return a numeric value. </dd>

                
                
                    <dt class="dt dlterm">Default</dt>

                    <dd class="dd">Writes each record using the default partition strategy that MapR Streams
                        provides.</dd>

                
            </dl>

        </div>

 </div>

</article>
<article class="topic concept nested2" aria-labelledby="ariaid-title14" id="concept_owb_vxt_mbb">
 <h3 class="title topictitle3" id="ariaid-title14">Best Practices for MapR Streams</h3>

 <div class="body conbody">
        <p class="p">Consider the following best
            practices when you configure a pipeline to write statistics to MapR Streams: </p>

        <ul class="ul" id="concept_owb_vxt_mbb__ul_vlq_jg5_xw">
            <li class="li">To avoid mixing statistics from different jobs, use a unique topic name for each
                job. </li>

            <li class="li">Consider the MapR Streams retention policy. <p class="p">Each running pipeline instance writes
                    statistics to MapR Streams, and then the system pipeline consumes the statistics
                    from MapR Streams. If the system pipeline unexpectedly shuts down, MapR Streams
                    retains the statistics for the amount of time determined by the MapR Streams
                    retention policy. If the system pipeline is down for longer than MapR Streams
                    retains data, the statistics are lost.</p>
</li>

        </ul>

 </div>

</article>
</article>
<article class="topic task nested1" aria-labelledby="ariaid-title15" id="task_lcd_ng5_xw">
    <h2 class="title topictitle2" id="ariaid-title15">Configuring a Pipeline to Write Statistics</h2>

    
    <div class="body taskbody"><p class="shortdesc">You can configure a pipeline to write statistics<span class="ph"> after the <span class="ph">Data Collector</span>
            has been registered with <span class="ph">Control Hub</span></span>.</p>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">Open the pipeline. </span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Statistics</span> tab, select one of the following
                    options for the statistics aggregator:</span>
                <div class="itemgroup info">
                    <ul class="ul" id="task_lcd_ng5_xw__ul_ljj_brd_dx">
                        <li class="li">Discard - Discard the pipeline statistics. <span class="ph">Control Hub</span> cannot display statistics and metrics for the job.</li>

                        <li class="li">Write to <span class="ph">Control Hub</span> Directly - Write the pipeline statistics directly to <span class="ph">Control Hub</span>. Use when the job runs on a single <span class="ph">Data Collector</span>.</li>

                        <li class="li">Write to SDC RPC - Write the pipeline statistics to an SDC RPC
                            destination. Use when the job runs on multiple <span class="ph">Data Collector</span>s and for development purposes only.</li>

                        <li class="li">Write to Kafka - Write the pipeline statistics to a Kafka cluster. Use
                            when the job runs on multiple <span class="ph">Data Collector</span>s.</li>

                        <li class="li">Write to Kinesis - Write the pipeline statistics to Amazon Kinesis
                            Streams. Use when the job runs on multiple <span class="ph">Data Collector</span>s.</li>

                        <li class="li">Write to MapR Streams - Write the pipeline statistics to MapR Streams.
                            Use when the job runs on multiple <span class="ph">Data Collector</span>s.</li>

                    </ul>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To write statistics to an SDC RPC destination, on the <span class="ph uicontrol">Stats
                        Aggregator - Write to SDC RPC</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_lcd_ng5_xw__table_jxy_4sq_yy" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d48560e1208">SDC RPC Properties</th>

                                    <th class="entry cellrowborder" id="d48560e1211">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">SDC RPC Connection</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Host and port where the system pipeline runs. The host
                                        must be a machine with a registered <span class="ph">Data Collector</span> that runs a pipeline instance for the job. <p class="p">Use the
                                            following format: <code class="ph codeph">&lt;host&gt;:&lt;port&gt;</code>.
                                        </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Retries per Batch</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Number of times the SDC RPC destination tries to write a
                                        batch to the Dev SDC RPC with Buffering origin in the system
                                        pipeline. <p class="p">When the SDC RPC destination cannot write the
                                            batch within the configured number of retries, it fails
                                            the batch.</p>
<p class="p">Default is 3.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Back off Period</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Milliseconds to wait before retrying writing a batch to
                                        the Dev SDC RPC with Buffering origin in the system
                                            pipeline.<p class="p">The value that you enter increases
                                            exponentially after each retry. For example, if you set
                                            the back off period to 10, the SDC RPC destination
                                            attempts the first retry after waiting 10 milliseconds,
                                            attempts the second retry after waiting 100
                                            milliseconds, and attempts the third retry after waiting
                                            1,000 milliseconds. Set to 0 to retry
                                            immediately.</p>
<p class="p">Default is 0.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">SDC RPC ID</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">User-defined ID to allow the SDC RPC destination to pass
                                        statistics to the system pipeline. To avoid mixing
                                        statistics from different jobs, use a unique ID for each
                                            job.<p class="p">You cannot define an expression that evaluates to
                                            the ID. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Connection Timeout (ms)</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Milliseconds to establish a connection to the system
                                        pipeline. <p class="p">The SDC RPC destination retries the connection
                                            based on the Retries Per Batch property.</p>
<p class="p">Default
                                            is 5000 milliseconds.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">TLS Enabled</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Enables the secure transfer of data using TLS. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Truststore File</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Truststore file for TLS. Required if the keystore file is
                                        a self-signed certificate.<p class="p">Must be stored in the <span class="ph">Data Collector</span> resources directory,
                                                <span class="ph filepath">$SDC_RESOURCES</span>, on each <span class="ph">Data Collector</span> machine that runs a pipeline instance for the job.
                                        </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Truststore Password</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Password for the truststore file.<div class="note tip"><span class="tiptitle">Tip:</span> <span class="ph" id="task_lcd_ng5_xw__d127e4830">To
                        secure sensitive information such as usernames and passwords, you can use
                              <a class="xref" href="../Pipeline_Configuration/RuntimeValues.html#concept_bs4_5nm_2s" title="Similar to runtime properties, runtime resources are values that you define in a file local to the Data Collector and call from within a pipeline. But with runtime resources, you can restrict the permissions for the files to secure sensitive information. Use runtime resources to load sensitive information from files at runtime.">runtime resources</a> or <span class="ph"><a class="xref" href="../Configuration/CredentialStores.html#concept_bt1_bpj_r1b" title="Data Collector pipeline stages communicate with external systems to read and write data. Many of these external systems require credentials - user names or passwords - to access the data. When you configure pipeline stages for these external systems, you define the credentials that the stage uses to connect to the system.">credential stores.</a></span></span></div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Read Timeout (ms)</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Milliseconds to wait for the Dev SDC RPC with Buffering
                                        origin in the system pipeline to read data from a batch.
                                            <p class="p">The SDC RPC destination retries the write based on
                                            the Retries Per Batch property.</p>
<p class="p">Default is 2000
                                            milliseconds.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Use Compression</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Enables the SDC RPC destination to use compression to
                                        pass data to the Dev SDC RPC with Buffering origin in the
                                        system pipeline. Enabled by default. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1208 ">Verify Host in Server Certificate</td>

                                    <td class="entry cellrowborder" headers="d48560e1211 ">Verifies the host in the keystore file on the <span class="ph">Data Collector</span> machine that runs the system pipeline. </td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To write statistics to Kafka, on the <span class="ph uicontrol">Stats Aggregator - Write to
                        Kafka</span> tab, configure the following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_lcd_ng5_xw__table_i2g_jwd_dx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d48560e1407">Kafka Properties</th>

                                    <th class="entry cellrowborder" id="d48560e1410">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                        <td class="entry cellrowborder" headers="d48560e1407 ">Broker URI</td>

                                        <td class="entry cellrowborder" headers="d48560e1410 ">Connection string for the Kafka broker. Use the
                                            following format:
                                                <code class="ph codeph">&lt;host&gt;:&lt;port&gt;</code>.<p class="p">To ensure a
                                                connection, enter a comma-separated list of
                                                additional broker URI.</p>
</td>

                                    </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1407 ">Runtime Topic Resolution </td>

                                    <td class="entry cellrowborder" headers="d48560e1410 ">Do not use at this time. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1407 ">Topic</td>

                                    <td class="entry cellrowborder" headers="d48560e1410 ">Topic to use. To avoid mixing statistics from different
                                        jobs, use a unique topic name for each job.<p class="p">You cannot
                                            define an expression that evaluates to the topic name.
                                        </p>
</td>

                                </tr>

                                <tr>
                                        <td class="entry cellrowborder" headers="d48560e1407 ">Partition Strategy <a class="xref" href="../Destinations/KProducer.html#concept_qpm_xp4_4r" title="The partition strategy determines how to write data to Kafka partitions. You can use a partition strategy to balance the work load or to write data semantically.">
                                                <img class="image" id="task_lcd_ng5_xw__d1326e9749" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                        <td class="entry cellrowborder" headers="d48560e1410 ">Strategy to use to write to partitions:<ul class="ul" id="task_lcd_ng5_xw__d1326e9753">
                                                <li class="li">Round Robin - Takes turns writing to different
                                                  partitions.</li>

                                                <li class="li">Random - Writes to partitions randomly.</li>

                                                <li class="li">Expression - Uses an expression to write data to
                                                  different partitions. Writes records to the
                                                  partitions specified by the results of the
                                                  expression.</li>

                                                <li class="li">Default - Uses an expression to extract a
                                                  partition key from the record. Writes records to
                                                  partitions based on a hash of the partition key.
                                                </li>

                                            </ul>
</td>

                                    </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1407 ">Partition Expression </td>

                                    <td class="entry cellrowborder" headers="d48560e1410 ">Expression to use when using the expression partition
                                            strategy.<p class="p">Define the expression to evaluate to the
                                            partition where you want statistics written. Partition
                                            numbers start with 0.</p>
<p class="p">Optionally, click
                                                <span class="ph uicontrol">Ctrl + Space Bar</span> for help
                                            with creating the expression.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1407 ">Kafka Configuration</td>

                                    <td class="entry cellrowborder" headers="d48560e1410 ">Additional Kafka properties to use. Using <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a>, click the
                                            <span class="ph uicontrol">Add</span> icon and define the Kafka
                                        property name and value.<p class="p">Use the property names and values
                                            as expected by Kafka. Do not use the broker.list
                                            property.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1407 ">ZooKeeper URI</td>

                                    <td class="entry cellrowborder" headers="d48560e1410 ">Connection string for the ZooKeeper of the Kafka cluster.
                                        Use the following format:
                                            <code class="ph codeph">&lt;host&gt;:&lt;port&gt;</code>. <p class="p">To use a
                                            ZooKeeper quorum, enter a comma-separated list.
                                            </p>
<div class="p">To use a ZooKeeper chroot path, add the path at
                                            the end of the list as
                                            follows:<pre class="pre codeblock"><code>&lt;host&gt;:&lt;port&gt;, &lt;host2&gt;:&lt;port2&gt;, .../&lt;chroot_path&gt;</code></pre></div>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To write statistics to Amazon Kinesis Streams, on the <span class="ph uicontrol">Stats
                        Aggregator - Write to Kinesis</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_lcd_ng5_xw__table_kh3_kls_dx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d48560e1561">Kinesis Properties</th>

                                    <th class="entry cellrowborder" id="d48560e1564">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1561 ">Access Key ID <a class="xref" href="AggregatedStatistics.html#concept_m3j_2kb_fx" title="When the pipeline writes aggregated statistics to Amazon Kinesis Streams, it must pass credentials to Amazon Web Services."><img class="image" id="task_lcd_ng5_xw__image_ekt_x9g_cs" src="../Graphics/icon_moreInfo.png" height="12" width="12" />
                                        </a></td>

                                    <td class="entry cellrowborder" headers="d48560e1564 ">
        <p class="p">AWS access key ID.</p>

        <p class="p">Required when not using IAM roles with IAM instance profile credentials.</p>

       </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1561 ">Secret Access Key <a class="xref" href="AggregatedStatistics.html#concept_m3j_2kb_fx" title="When the pipeline writes aggregated statistics to Amazon Kinesis Streams, it must pass credentials to Amazon Web Services."><img class="image" id="task_lcd_ng5_xw__image_ekt_x6g_cs" src="../Graphics/icon_moreInfo.png" height="12" width="12" />
                                        </a></td>

                                    <td class="entry cellrowborder" headers="d48560e1564 ">
        <p class="p">AWS secret access key. </p>

        <p class="p">Required when not using IAM roles with IAM instance profile credentials. </p>

       </td>

                                </tr>

                                <tr>
      <td class="entry cellrowborder" headers="d48560e1561 ">Region</td>

      <td class="entry cellrowborder" headers="d48560e1564 ">Amazon Web Services region that hosts the Kinesis cluster.</td>

     </tr>

                                <tr>
      <td class="entry cellrowborder" headers="d48560e1561 ">Endpoint</td>

      <td class="entry cellrowborder" headers="d48560e1564 ">Endpoint to connect to when you select Other for the region. Enter the endpoint
       name.</td>

     </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1561 ">Stream Name</td>

                                    <td class="entry cellrowborder" headers="d48560e1564 ">Kinesis stream name. To avoid mixing statistics from
                                        different jobs, use a unique stream name for each job.<p class="p">You
                                            cannot define an expression that evaluates to the stream
                                            name. </p>
</td>

                                </tr>

                                <tr>
      <td class="entry cellrowborder" headers="d48560e1561 ">Partitioning Strategy</td>

      <td class="entry cellrowborder" headers="d48560e1564 ">Strategy to write data to Kinesis shards:<ul class="ul" id="task_lcd_ng5_xw__d1327e1458">
        <li class="li">Random - Generates a random partition key.</li>

        <li class="li">
         <p class="p">Expression - Uses the result of an expression as the partition key.</p>

        </li>

       </ul>
</td>

     </tr>

                                <tr>
      <td class="entry cellrowborder" headers="d48560e1561 ">Partition Expression</td>

      <td class="entry cellrowborder" headers="d48560e1564 ">Expression to generate the partition key used to pass data to different shards. <p class="p">Use
        for the expression partition strategy. </p>
</td>

     </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1561 ">Kinesis Producer Configuration</td>

                                    <td class="entry cellrowborder" headers="d48560e1564 ">Additional Kinesis properties.<p class="p">When you add a
                                            configuration property, enter the exact property name
                                            and the value. The pipeline does not validate the
                                            property names or values.</p>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To write statistics to MapR Streams, on the <span class="ph uicontrol">Stats Aggregator - Write
                        to MapR Streams</span> tab, configure the following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_lcd_ng5_xw__table_z2j_315_mbb" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d48560e1715">MapR Streams Properties</th>

                                    <th class="entry cellrowborder" id="d48560e1718">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1715 ">Runtime Topic Resolution </td>

                                    <td class="entry cellrowborder" headers="d48560e1718 ">Do not use at this time. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1715 ">Topic</td>

                                    <td class="entry cellrowborder" headers="d48560e1718 ">Topic to use. To avoid mixing statistics from different
                                        jobs, use a unique topic name for each job.<p class="p">You cannot
                                            define an expression that evaluates to the topic name.
                                        </p>
</td>

                                </tr>

                                <tr>
                                        <td class="entry cellrowborder" headers="d48560e1715 ">Partition Strategy <a class="xref" href="../Destinations/KProducer.html#concept_qpm_xp4_4r" title="The partition strategy determines how to write data to Kafka partitions. You can use a partition strategy to balance the work load or to write data semantically.">
                                                <img class="image" id="task_lcd_ng5_xw__d1326e9749" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                        <td class="entry cellrowborder" headers="d48560e1718 ">Strategy to use to write to partitions:<ul class="ul" id="task_lcd_ng5_xw__d1326e9753">
                                                <li class="li">Round Robin - Takes turns writing to different
                                                  partitions.</li>

                                                <li class="li">Random - Writes to partitions randomly.</li>

                                                <li class="li">Expression - Uses an expression to write data to
                                                  different partitions. Writes records to the
                                                  partitions specified by the results of the
                                                  expression.</li>

                                                <li class="li">Default - Uses an expression to extract a
                                                  partition key from the record. Writes records to
                                                  partitions based on a hash of the partition key.
                                                </li>

                                            </ul>
</td>

                                    </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1715 ">Partition Expression </td>

                                    <td class="entry cellrowborder" headers="d48560e1718 ">Expression to use when using the expression partition
                                            strategy.<p class="p">Define the expression to evaluate to the
                                            partition where you want statistics written. Partition
                                            numbers start with 0.</p>
<p class="p">Optionally, click
                                                <span class="ph uicontrol">Ctrl + Space Bar</span> for help
                                            with creating the expression.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d48560e1715 ">MapR Streams Configuration</td>

                                    <td class="entry cellrowborder" headers="d48560e1718 ">Additional configuration properties to use. Using <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a>, click the
                                            <span class="ph uicontrol">Add</span> icon and define the MapR
                                        Streams property name and value.<p class="p">Use the property names
                                            and values as expected by MapR Streams. You can use MapR
                                            Streams properties and the set of Kafka properties
                                            supported by MapR Streams. </p>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
</ol>

    </div>

</article>
</article>
</article></main></div>
                        
                        
                        
                    </div>
                    
                </div>
            </div>
        </div> <nav class="navbar navbar-default wh_footer">
  <div class=" footer-container text-center ">
    <!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script>
  </div>
</nav>

        
        <div id="go2top">
            <span class="glyphicon glyphicon-chevron-up"></span>
        </div>
        
        <!-- The modal container for images -->
        <div id="modal_img_large" class="modal">
            <span class="close glyphicon glyphicon-remove"></span>
            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="modal-img" />
            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>
        
        <script src="../../../oxygen-webhelp/lib/bootstrap/js/bootstrap.min.js" type="text/javascript"></script>
        © Apache License, Version 2.0.
    </body>
</html>