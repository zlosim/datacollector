
<!DOCTYPE html
  PUBLIC "" "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:whc="http://www.oxygenxml.com/webhelp/components" xml:lang="en-us" lang="en-us">
    <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><link rel="shortcut icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><link rel="icon" href="../../../oxygen-webhelp/template/images/favicon.png"><!----></link><meta name="description" content="The Hadoop FS destination writes data to the Hadoop Distributed File System (HDFS). You can write the data to HDFS as flat files or Hadoop sequence files. You can also use the whole file data format ..." /><meta name="copyright" content="(C) Copyright 2018" /><meta name="DC.rights.owner" content="(C) Copyright 2018" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Hadoop FS" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Destinations/Destinations-title.html" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Destinations/PubSubPublisher.html#concept_qsj_hk1_v1b" /><meta name="DC.Relation" scheme="URI" content="../../../datacollector/UserGuide/Destinations/HBase.html#concept_wsz_5t5_vr" /><meta name="DC.Relation" scheme="URI" content="../Hive_Drift_Solution/HiveDriftSolution_title.html#concept_phk_bdf_2w" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="prodname" content="Data Collector" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="version" content="1" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="release" content="0" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="modification" content="0 Beta 2" /><meta name="DC.Date.Created" content="2014-10-31" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_awl_4km_zq" /><title>Hadoop FS</title><!--  Generated with Oxygen version 20.0-SNAPSHOT, build number 2018042310.  --><meta name="wh-path2root" content="../../../" /><meta name="wh-toc-id" content="concept_awl_4km_zq-d46e87248" />         
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <!-- Latest compiled and minified Bootstrap CSS -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap.min.css" />

        <!-- Bootstrap Optional theme -->
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/bootstrap/css/bootstrap-theme.min.css" />
        <link rel="stylesheet" href="../../../oxygen-webhelp/lib/jquery-ui/jquery-ui.min.css" />

        <!-- Template default styles  -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/app/topic-page.css?buildId=2018042310" />
        

        <script type="text/javascript" src="../../../oxygen-webhelp/lib/jquery/jquery-3.1.1.min.js"><!----></script>

        <script data-main="../../../oxygen-webhelp/app/topic-page.js" src="../../../oxygen-webhelp/lib/requirejs/require.js"></script>
        
        <!-- Skin resources -->
        <link rel="stylesheet" type="text/css" href="../../../oxygen-webhelp/template/light.css?buildId=2018042310" />
        <!-- EXM-36950 - Expand the args.hdf parameter here -->
        
        
    <link rel="stylesheet" type="text/css" href="../../../skin.css" /></head>

    <body class="wh_topic_page frmBody">
        <!-- EXM-36950 - Expand the args.hdr parameter here -->
        
        
        
<nav class="navbar navbar-default wh_header">
    <div class="container-fluid">
        <div class="wh_header_flex_container">
            <div class="wh_logo_and_publication_title_container">
                <div class="wh_logo_and_publication_title">
                    
                    <!--
                            This component will be generated when the next parameters are specified in the transformation scenario:
                            'webhelp.logo.image' and 'webhelp.logo.image.target.url'.
                            See: http://oxygenxml.com/doc/versions/17.1/ug-editor/#topics/dita_webhelp_output.html.
                    -->
                    <a href="../../../index.html" class=" wh_logo hidden-xs "></a>
                    <div class=" wh_publication_title "><a href="../../../index.html"><span class="booktitle">  <span class="ph mainbooktitle"><span class="ph">Data Collector</span> User Guide</span>  </span></a></div>
                    
                </div>
                
                <!-- The menu button for mobile devices is copied in the output only when the 'webhelp.show.top.menu' parameter is set to 'yes' -->
                
            </div>

            <div class="wh_top_menu_and_indexterms_link collapse navbar-collapse">
                
                
                <div class=" wh_indexterms_link "><a href="../../../indexTerms.html" title="Index"><span>Index</span></a></div>
                
            </div>
        </div>
    </div>
</nav>

        <div class=" wh_search_input "><form id="searchForm" method="get" action="../../../search.html"><div><input type="search" placeholder="Search " class="wh_search_textfield" id="textToSearch" name="searchQuery" /><button type="submit" class="wh_search_button"><span>Search</span></button></div><script><!--
                                    $(document).ready(function () {
                                        $('#searchForm').submit(function (e) {
                                            if ($('.wh_search_textfield').val().length < 1) {
                                                e.preventDefault();
                                            }
                                        });
                                    });
                                --></script></form></div>
        
        <div class="container-fluid">
            <div class="row">

                <nav class="wh_tools hidden-print">
                    <div data-tooltip-position="bottom" class=" wh_breadcrumb "><ol xmlns:html="http://www.w3.org/1999/xhtml" class="hidden-print"><li><span class="home"><a href="../../../index.html"><span>Home</span></a></span></li>
   <li><span class="topicref" data-id="concept_agj_cfj_br"><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations-title.html">Destinations</a></span></span></li>
   <li class="active"><span class="topicref" data-id="concept_awl_4km_zq"><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_awl_4km_zq">Hadoop FS</a></span></span></li>
</ol></div>

                    <div class="wh_right_tools hidden-sm hidden-xs">
                        <div class=" wh_navigation_links "><span id="topic_navigation_links" class="navheader">
  
<span class="navprev"><a class="link" href="../../../datacollector/UserGuide/Destinations/PubSubPublisher.html#concept_qsj_hk1_v1b" title="Google Pub/Sub Publisher"></a></span>  
<span class="navnext"><a class="link" href="../../../datacollector/UserGuide/Destinations/HBase.html#concept_wsz_5t5_vr" title="HBase"></a></span>  </span></div>
                        <button class="wh_hide_highlight" title="Toggle search highlights"></button>
                        <button class="webhelp_expand_collapse_sections" data-next-state="collapsed" title="Collapse sections"></button>
                        <div class=" wh_print_link print "><a href="javascript:window.print();" title="Print this page"></a></div>
                    </div>
                </nav>
            </div>

            <div class="wh_content_area">
                <div class="row">
                    
                        <nav role="navigation" id="wh_publication_toc" class="col-lg-3 col-md-3 col-sm-3 hidden-xs navbar hidden-print">
                            <div class=" wh_publication_toc " data-tooltip-position="right"><ul>
   <li><span data-tocid="concept_htw_ghg_jq-d46e54" class="topicref" data-id="concept_htw_ghg_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Getting_Started/GettingStarted_Title.html#concept_htw_ghg_jq">Getting Started</a></span></span></li>
   <li><span data-tocid="concept_hz3_5fk_fy-d46e804" class="topicref" data-id="concept_hz3_5fk_fy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/WhatsNew/WhatsNew_Title.html#concept_hz3_5fk_fy">What's New</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_l4q_flb_kr-d46e4946" class="topicref" data-id="concept_l4q_flb_kr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Installation/Install_title.html">Installation</a></span></span></li>
   <li><span data-tocid="concept_ylh_yyz_ky-d46e7013" class="topicref" data-id="concept_ylh_yyz_ky" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Configuration/Config_title.html">Configuration</a></span></span></li>
   <li><span data-tocid="concept_ejk_f1f_5v-d46e15233" class="topicref" data-id="concept_ejk_f1f_5v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Upgrade/Upgrade_title.html">Upgrade</a></span></span></li>
   <li><span data-tocid="concept_qsw_cjy_bt-d46e20068" class="topicref" data-id="concept_qsw_cjy_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Design/PipelineDesign_title.html">Pipeline Concepts and Design</a></span></span></li>
   <li><span data-tocid="concept_qn1_wn4_kq-d46e21748" class="topicref" data-id="concept_qn1_wn4_kq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Configuration/PipelineConfiguration_title.html">Pipeline Configuration</a></span></span></li>
   <li><span data-tocid="concept_hdr_gyw_41b-d46e24245" class="topicref" data-id="concept_hdr_gyw_41b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Formats/DataFormats-Title.html">Data Formats</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e26060" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Origins/Origins_title.html">Origins</a></span></span></li>
   <li><span data-tocid="concept_yjl_nc5_jq-d46e66858" class="topicref" data-id="concept_yjl_nc5_jq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Processors/Processors_title.html">Processors</a></span></span></li>
   <li><span data-tocid="concept_agj_cfj_br-d46e81955" class="topicref" data-id="concept_agj_cfj_br" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations-title.html">Destinations</a></span></span><ul class="nav nav-list">
         <li><span data-tocid="concept_hpr_twm_jq-d46e81977" class="topicref" data-id="concept_hpr_twm_jq" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Destinations_overview.html#concept_hpr_twm_jq">Destinations</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_gyq_rpr_4cb-d46e82001" class="topicref" data-id="concept_gyq_rpr_4cb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Aerospike.html#concept_gyq_rpr_4cb">Aerospike</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Aerospike destination writes data to Aerospike.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_avx_bnq_rt-d46e82058" class="topicref" data-id="concept_avx_bnq_rt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/AmazonS3.html#concept_avx_bnq_rt">Amazon S3</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Amazon S3 destination writes data to Amazon S3. To write data to an Amazon Kinesis         Firehose delivery system, use
                        the Kinesis Firehose destination. To write data to Amazon         Kinesis Streams, use the Kinesis Producer destination.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_jzm_kf4_zx-d46e82997" class="topicref" data-id="concept_jzm_kf4_zx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/DataLakeStore.html#concept_jzm_kf4_zx">Azure Data Lake Store</a></span></span></li>
         <li><span data-tocid="concept_xq5_d5q_1bb-d46e83930" class="topicref" data-id="concept_xq5_d5q_1bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/AzureEventHubProducer.html#concept_xq5_d5q_1bb">Azure Event Hub Producer</a></span></span></li>
         <li><span data-tocid="concept_pnd_jkq_1bb-d46e84026" class="topicref" data-id="concept_pnd_jkq_1bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/AzureIoTHub.html#concept_pnd_jkq_1bb">Azure IoT Hub Producer</a></span></span></li>
         <li><span data-tocid="concept_hfy_mfd_sr-d46e84182" class="topicref" data-id="concept_hfy_mfd_sr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Cassandra.html#concept_hfy_mfd_sr">Cassandra</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Cassandra destination writes data to a Cassandra cluster.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hw5_s3n_sz-d46e84396" class="topicref" data-id="concept_hw5_s3n_sz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/CoAPClient.html#concept_hw5_s3n_sz">CoAP Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">Constrained Application Protocol (CoAP) is a web transfer protocol designed for         machine-to-machine devices. The CoAP
                        Client destination writes data to a CoAP endpoint. Use         the destination to send requests to a CoAP resource URL.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ahq_1wq_h2b-d46e84495" class="topicref" data-id="concept_ahq_1wq_h2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Couchbase.html#concept_ahq_1wq_h2b">Couchbase</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Couchbase destination writes data to Couchbase Server. Couchbase Server is a         distributed NoSQL document-oriented
                        database.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_u5t_vpv_4r-d46e84552" class="topicref" data-id="concept_u5t_vpv_4r" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Elasticsearch.html#concept_u5t_vpv_4r">Elasticsearch</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Elasticsearch destination writes data to an Elasticsearch cluster, including Elastic         Cloud clusters (formerly
                        Found clusters). The destination uses the Elasticsearch HTTP API to         write each record to Elasticsearch as a document.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hlx_r53_rx-d46e84773" class="topicref" data-id="concept_hlx_r53_rx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/WaveAnalytics.html#concept_hlx_r53_rx">Einstein Analytics</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Einstein Analytics destination writes data to Salesforce Einstein Analytics. The         destination connects to Einstein
                        Analytics to upload external data to a dataset.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_pzn_hl4_yr-d46e85062" class="topicref" data-id="concept_pzn_hl4_yr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Flume.html#concept_pzn_hl4_yr">Flume</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Flume destination writes data to a Flume source. When you write data to Flume, you     pass data to a Flume client. The
                        Flume client passes data to hosts based on client configuration     properties. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hj4_brk_dbb-d46e85161" class="topicref" data-id="concept_hj4_brk_dbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/BigQuery.html#concept_hj4_brk_dbb">Google BigQuery</a></span></span></li>
         <li><span data-tocid="concept_pl5_tmq_tx-d46e85452" class="topicref" data-id="concept_pl5_tmq_tx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Bigtable.html#concept_pl5_tmq_tx">Google Bigtable</a></span></span></li>
         <li><span data-tocid="concept_p4n_jrl_nbb-d46e86033" class="topicref" data-id="concept_p4n_jrl_nbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/GCS.html#concept_p4n_jrl_nbb">Google Cloud Storage</a></span></span></li>
         <li><span data-tocid="concept_qsj_hk1_v1b-d46e86963" class="topicref" data-id="concept_qsj_hk1_v1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/PubSubPublisher.html#concept_qsj_hk1_v1b">Google Pub/Sub Publisher</a></span></span></li>
         <li class="active"><span data-tocid="concept_awl_4km_zq-d46e87248" class="topicref" data-id="concept_awl_4km_zq" data-state="expanded"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_awl_4km_zq">Hadoop FS</a></span></span><ul class="nav nav-list">
               <li><span data-tocid="concept_cvc_skd_br-d46e87401" class="topicref" data-id="concept_cvc_skd_br" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_cvc_skd_br">Directory Templates</a></span></span></li>
               <li><span data-tocid="concept_gkz_smd_br-d46e87423" class="topicref" data-id="concept_gkz_smd_br" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_gkz_smd_br">Time Basis</a></span></span></li>
               <li><span data-tocid="concept_xgm_g4d_br-d46e87455" class="topicref" data-id="concept_xgm_g4d_br" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_xgm_g4d_br">Late Records and Late Record Handling </a></span></span></li>
               <li><span data-tocid="concept_qjs_dw3_tv-d46e87497" class="topicref" data-id="concept_qjs_dw3_tv" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_qjs_dw3_tv">Timeout to Close Idle Files</a></span></span></li>
               <li><span data-tocid="concept_uv2_vfb_vy-d46e87549" class="topicref" data-id="concept_uv2_vfb_vy" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_uv2_vfb_vy">Recovery</a></span></span></li>
               <li><span data-tocid="concept_lww_3b3_kr-d46e87611" class="topicref" data-id="concept_lww_3b3_kr" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_lww_3b3_kr">Data Formats</a></span></span></li>
               <li><span data-tocid="concept_n42_z2f_sw-d46e87683" class="topicref" data-id="concept_n42_z2f_sw" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_n42_z2f_sw">Writing to Azure HDInsight</a><span class="wh-tooltip">
                           
                           <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">You can use the HDP stage libraries to write to Azure Blob storage using the WASB         protocol. This enables the Hadoop
                              FS destination to write directly to Azure HDInsight. 
                              
                           </p>
                           </span></span></span></li>
               <li><span data-tocid="concept_bvb_rxj_px-d46e87769" class="topicref" data-id="concept_bvb_rxj_px" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_bvb_rxj_px">Event Generation</a></span></span></li>
               <li><span data-tocid="concept_xy5_4tm_vs-d46e87965" class="topicref" data-id="concept_xy5_4tm_vs" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_xy5_4tm_vs">Kerberos Authentication</a></span></span></li>
               <li><span data-tocid="concept_u4h_lwt_ls-d46e88078" class="topicref" data-id="concept_u4h_lwt_ls" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_u4h_lwt_ls">Using an HDFS User</a></span></span></li>
               <li><span data-tocid="concept_xh5_y4d_br-d46e88202" class="topicref" data-id="concept_xh5_y4d_br" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#concept_xh5_y4d_br">HDFS Properties and Configuration Files</a></span></span></li>
               <li><span data-tocid="task_m2m_skm_zq-d46e88335" class="topicref" data-id="task_m2m_skm_zq" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HadoopFS-destination.html#task_m2m_skm_zq">Configuring a Hadoop FS Destination</a></span></span></li>
            </ul>
         </li>
         <li><span data-tocid="concept_wsz_5t5_vr-d46e88478" class="topicref" data-id="concept_wsz_5t5_vr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HBase.html#concept_wsz_5t5_vr">HBase</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The HBase destination writes data to an HBase cluster. The destination can write data       to HBase as text, binary data,
                        or JSON strings. You can define the data format for each column       written to HBase.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_gcr_z2t_zv-d46e88861" class="topicref" data-id="concept_gcr_z2t_zv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HiveMetastore.html#concept_gcr_z2t_zv">Hive Metastore</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hive Metastore destination works with the Hive Metadata processor and the Hadoop FS         or MapR FS destination as
                        part of the Drift Synchronization Solution for Hive. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kvs_3hh_ht-d46e89456" class="topicref" data-id="concept_kvs_3hh_ht" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Hive.html#concept_kvs_3hh_ht">Hive Streaming</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Hive Streaming destination writes data to Hive tables stored in the ORC (Optimized   Row Columnar) file format.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_khl_sg5_lz-d46e89555" class="topicref" data-id="concept_khl_sg5_lz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/HTTPClient.html#concept_khl_sg5_lz">HTTP Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The HTTP Client destination writes data to an HTTP endpoint. The destination sends         requests to an HTTP resource URL.
                        Use the HTTP Client destination to perform a range of         standard requests or use an expression to determine the request
                        for each record.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_inf_db_sr-d46e90381" class="topicref" data-id="concept_inf_db_sr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/InfluxDB.html#concept_inf_db_sr">InfluxDB</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The InfluxDB destination writes data to an InfluxDB database.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_kvs_3hh_ht-d46e90438" class="topicref" data-id="concept_kvs_3hh_ht" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/JDBCProducer.html#concept_kvs_3hh_ht">JDBC Producer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The JDBC Producer destination uses a JDBC connection to write data to a database         table. You can also use the JDBC
                        Producer to write change capture data from a Microsoft SQL         Server change log. 
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_sfz_ww5_n1b-d46e90655" class="topicref" data-id="concept_sfz_ww5_n1b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/JMSProducer.html#concept_sfz_ww5_n1b">JMS Producer</a></span></span></li>
         <li><span data-tocid="concept_oq2_5jl_zq-d46e91023" class="topicref" data-id="concept_oq2_5jl_zq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/KProducer.html#concept_oq2_5jl_zq">Kafka Producer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Kafka Producer destination writes data to a Kafka cluster. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_bjv_dpk_kv-d46e91829" class="topicref" data-id="concept_bjv_dpk_kv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/KinFirehose.html#concept_bjv_dpk_kv">Kinesis Firehose</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Kinesis Firehose destination writes data to an Amazon Kinesis Firehose delivery         stream. Firehose automatically
                        delivers the data to the Amazon S3 bucket or Amazon Redshift         table that you specify in the delivery stream.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_swk_h1j_yr-d46e92052" class="topicref" data-id="concept_swk_h1j_yr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/KinProducer.html#concept_swk_h1j_yr">Kinesis Producer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Kinesis Producer destination writes data to Amazon Kinesis Streams. To write data to         an Amazon Kinesis Firehose
                        delivery system, use the Kinesis Firehose destination. To write         data to Amazon S3, use the Amazon S3 destination.
                        
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_hxh_5xg_qbb-d46e92209" class="topicref" data-id="concept_hxh_5xg_qbb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/KineticaDB.html#concept_hxh_5xg_qbb">KineticaDB</a></span></span></li>
         <li><span data-tocid="concept_chy_xxg_4v-d46e92357" class="topicref" data-id="concept_chy_xxg_4v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Kudu.html#concept_chy_xxg_4v">Kudu </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Kudu destination writes data to a Kudu cluster.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_zvc_bv5_1r-d46e92508" class="topicref" data-id="concept_zvc_bv5_1r" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/LocalFS.html#concept_zvc_bv5_1r">Local FS</a></span></span></li>
         <li><span data-tocid="concept_vxg_w2z_yv-d46e93182" class="topicref" data-id="concept_vxg_w2z_yv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/MapRDB.html#concept_vxg_w2z_yv">MapR DB</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR DB destination writes data to MapR DB binary tables. The destination can write         data to MapR DB as text, binary
                        data, or JSON strings. You can define the data format for         each column written to MapR DB.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_i4h_2kj_dy-d46e93565" class="topicref" data-id="concept_i4h_2kj_dy" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/MapRDBJSON.html#concept_i4h_2kj_dy">MapR DB JSON</a></span></span></li>
         <li><span data-tocid="concept_spv_xlc_fv-d46e93937" class="topicref" data-id="concept_spv_xlc_fv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/MapRFS.html#concept_spv_xlc_fv">MapR FS </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR FS destination writes files to MapR FS. You can write the data to MapR as flat         files or Hadoop sequence files.
                        
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_cfj_qbn_2v-d46e95023" class="topicref" data-id="concept_cfj_qbn_2v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/MapRStreamsProd.html#concept_cfj_qbn_2v">MapR Streams Producer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MapR Streams Producer destination writes messages to MapR Streams.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_eth_k5n_4v-d46e95322" class="topicref" data-id="concept_eth_k5n_4v" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/MongoDB.html#concept_eth_k5n_4v">MongoDB</a></span></span></li>
         <li><span data-tocid="concept_odz_txt_lz-d46e95604" class="topicref" data-id="concept_odz_txt_lz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/MQTTPublisher.html#concept_odz_txt_lz">MQTT Publisher</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The MQTT Publisher destination publishes messages to a topic on an MQTT broker. The         destination functions as an MQTT
                        client that publishes messages, writing each record as a         message.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_pl5_tdg_gcb-d46e95758" class="topicref" data-id="concept_pl5_tdg_gcb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/NamedPipe.html#concept_pl5_tdg_gcb">Named Pipe</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Named Pipe destination writes data to a UNIX named pipe. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_fq3_kpc_r2b-d46e96144" class="topicref" data-id="concept_fq3_kpc_r2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/PulsarProducer.html#concept_fq3_kpc_r2b">Pulsar Producer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Pulsar Producer destination writes data to topics in an Apache Pulsar         cluster.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_pxj_rvy_dv-d46e96298" class="topicref" data-id="concept_pxj_rvy_dv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/RabbitMQ.html#concept_pxj_rvy_dv">RabbitMQ Producer</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">RabbitMQ Producer writes AMQP messages to a single RabbitMQ queue. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ktc_gw2_gw-d46e96397" class="topicref" data-id="concept_ktc_gw2_gw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Redis.html#concept_ktc_gw2_gw">Redis</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Redis destination writes data to Redis. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_rlb_rt3_rx-d46e96683" class="topicref" data-id="concept_rlb_rt3_rx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Salesforce.html#concept_rlb_rt3_rx">Salesforce</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Salesforce destination writes data to Salesforce objects.</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_lfk_hx2_ct-d46e96900" class="topicref" data-id="concept_lfk_hx2_ct" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/SDC_RPCdest.html#concept_lfk_hx2_ct">SDC RPC</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The SDC RPC destination enables connectivity between two SDC RPC pipelines. The SDC RPC     destination passes data to one
                        or more SDC RPC origins. Use the SDC RPC destination as part of     an SDC RPC origin pipeline.
                        
                     </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_eyd_zx4_q2b-d46e97057" class="topicref" data-id="concept_eyd_zx4_q2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/SendResponse.html#concept_eyd_zx4_q2b">Send Response to Origin</a></span></span></li>
         <li><span data-tocid="concept_z2g_q1r_wr-d46e97112" class="topicref" data-id="concept_z2g_q1r_wr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Solr.html#concept_z2g_q1r_wr">Solr</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Solr destination writes data to a Solr node or cluster. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_zzr_pqn_xdb-d46e97272" class="topicref" data-id="concept_zzr_pqn_xdb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Splunk.html#concept_zzr_pqn_xdb">Splunk</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Splunk destination writes data to Splunk using the Splunk HTTP Event Collector         (HEC).</p>
                     </span></span></span></li>
         <li><span data-tocid="concept_idr_ct5_w2b-d46e97495" class="topicref" data-id="concept_idr_ct5_w2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Syslog.html#concept_idr_ct5_w2b">Syslog</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The Syslog destination writes syslog messages to a Syslog server. </p>
                     </span></span></span></li>
         <li><span data-tocid="concept_ryn_v3z_lr-d46e97784" class="topicref" data-id="concept_ryn_v3z_lr" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/ToError.html">To Error </a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_htf_ydj_wq-d46e97808" class="topicref" data-id="concept_htf_ydj_wq" data-state="leaf"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/Trash.html#concept_htf_ydj_wq">Trash</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
                     </span></span></span></li>
         <li><span data-tocid="concept_l4d_mjn_lz-d46e97832" class="topicref" data-id="concept_l4d_mjn_lz" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Destinations/WebSocketClient.html#concept_l4d_mjn_lz">WebSocket Client</a><span class="wh-tooltip">
                     
                     <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc">The WebSocket Client destination writes data to a WebSocket endpoint. Use the         destination to send data to a WebSocket
                        resource URL. 
                        
                     </p>
                     </span></span></span></li>
      </ul>
   </li>
   <li><span data-tocid="concept_umc_1lk_fx-d46e97932" class="topicref" data-id="concept_umc_1lk_fx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Executors/Executors-title.html">Executors</a></span></span></li>
   <li><span data-tocid="concept_fyf_gkq_4bb-d46e103694" class="topicref" data-id="concept_fyf_gkq_4bb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Edge_Mode/EdgePipelines_title.html"><span xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="ph">StreamSets Data Collector Edge</span></a></span></span></li>
   <li><span data-tocid="concept_ugp_kwf_xw-d46e105613" class="topicref" data-id="concept_ugp_kwf_xw" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/DPM/DPM_title.html">StreamSets Control Hub</a></span></span></li>
   <li><span data-tocid="concept_xxd_f5r_kx-d46e109014" class="topicref" data-id="concept_xxd_f5r_kx" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Event_Handling/EventFramework-Title.html#concept_xxd_f5r_kx">Dataflow Triggers</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_fjj_zcf_2w-d46e112928" class="topicref" data-id="concept_fjj_zcf_2w" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Hive_Drift_Solution/HiveDriftSolution_title.html#concept_fjj_zcf_2w">Drift Synchronization Solution for Hive</a></span></span></li>
   <li><span data-tocid="concept_kgt_pnr_4cb-d46e115754" class="topicref" data-id="concept_kgt_pnr_4cb" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/JDBC_DriftSolution/JDBC_DriftSyncSolution_title.html#concept_kgt_pnr_4cb">Drift Synchronization Solution for PostgreSQL</a></span></span></li>
   <li><span data-tocid="concept_wwq_gxc_py-d46e116553" class="topicref" data-id="concept_wwq_gxc_py" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Multithreaded_Pipelines/MultithreadedPipelines.html#concept_wwq_gxc_py">Multithreaded Pipelines</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_gzw_tdm_p2b-d46e117135" class="topicref" data-id="concept_gzw_tdm_p2b" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Microservice/Microservice_Title.html#concept_gzw_tdm_p2b">Microservice Pipelines</a></span></span></li>
   <li><span data-tocid="concept_wr1_ktz_bt-d46e117357" class="topicref" data-id="concept_wr1_ktz_bt" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/RPC_Pipelines/SDC_RPCpipelines_title.html#concept_wr1_ktz_bt">SDC RPC Pipelines</a></span></span></li>
   <li><span data-tocid="concept_fpz_5r4_vs-d46e117839" class="topicref" data-id="concept_fpz_5r4_vs" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Cluster_Mode/ClusterPipelines_title.html">Cluster Pipelines</a></span></span></li>
   <li><span data-tocid="concept_jjk_23z_sq-d46e119186" class="topicref" data-id="concept_jjk_23z_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Data_Preview/DataPreview_Title.html#concept_jjk_23z_sq">Data Preview</a></span></span></li>
   <li><span data-tocid="concept_pgk_brx_rr-d46e120155" class="topicref" data-id="concept_pgk_brx_rr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Alerts/RulesAlerts_title.html#concept_pgk_brx_rr">Rules and Alerts</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_asx_fdz_sq-d46e122783" class="topicref" data-id="concept_asx_fdz_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Monitoring/PipelineMonitoring_title.html#concept_asx_fdz_sq">Pipeline Monitoring</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_o3l_dtr_5q-d46e124040" class="topicref" data-id="concept_o3l_dtr_5q" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Pipeline_Maintenance/PipelineMaintenance_title.html#concept_o3l_dtr_5q">Pipeline Maintenance</a></span></span></li>
   <li><span data-tocid="concept_yms_ftm_sq-d46e125831" class="topicref" data-id="concept_yms_ftm_sq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Administration/Administration_title.html#concept_yms_ftm_sq">Administration</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_nls_w1r_ks-d46e130328" class="topicref" data-id="concept_nls_w1r_ks" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Tutorial/Tutorial-title.html">Tutorial</a></span></span></li>
   <li><span data-tocid="concept_sh3_frm_tq-d46e131541" class="topicref" data-id="concept_sh3_frm_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Troubleshooting/Troubleshooting_title.html#concept_sh3_frm_tq">Troubleshooting</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_xbx_rs1_tq-d46e136033" class="topicref" data-id="concept_xbx_rs1_tq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Glossary/Glossary_title.html#concept_xbx_rs1_tq">Glossary</a></span></span></li>
   <li><span data-tocid="concept_jn1_nzb_kv-d46e136088" class="topicref" data-id="concept_jn1_nzb_kv" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-DataFormats/DataFormat_Title.html#concept_jn1_nzb_kv">Data Formats by Stage</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_pvm_yt3_wq-d46e136248" class="topicref" data-id="concept_pvm_yt3_wq" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Expression_Language/ExpressionLanguage_title.html">Expression Language</a></span></span></li>
   <li><span data-tocid="concept_vcj_1ws_js-d46e137892" class="topicref" data-id="concept_vcj_1ws_js" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-RegEx/RegEx-Title.html#concept_vcj_1ws_js">Regular Expressions</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
   <li><span data-tocid="concept_chv_vmj_wr-d46e138115" class="topicref" data-id="concept_chv_vmj_wr" data-state="not-ready"><span class="wh-expand-btn"></span><span class="title"><a href="../../../datacollector/UserGuide/Apx-GrokPatterns/GrokPatterns_title.html#concept_chv_vmj_wr">Grok Patterns</a><span class="wh-tooltip">
               
               <p xmlns:toc="http://www.oxygenxml.com/ns/webhelp/toc" xmlns:xhtml="http://www.w3.org/1999/xhtml" class="shortdesc"></p>
               </span></span></span></li>
</ul></div>
                        </nav>
                    
                    
                    <div class="col-lg-9 col-md-9 col-sm-9 col-xs-12" id="wh_topic_body">
                        <div class=" wh_topic_content body "><main role="main"><article role="article" aria-labelledby="ariaid-title1"><article class="nested0" aria-labelledby="ariaid-title1" id="concept_awl_4km_zq">
 <h1 class="title topictitle1" id="ariaid-title1">Hadoop FS</h1>

 <div class="body conbody">
        <p class="p">The Hadoop FS destination writes data to the Hadoop
            Distributed File System (HDFS). You can write the data to HDFS as flat files or Hadoop
            sequence files. You can also use the whole file data format to write whole files to
            HDFS.</p>

        <p class="p">When you configure a Hadoop FS destination, <span class="ph">you can define a directory template and time basis to
                        determine the output directories that the destination creates and the files
                        where records are written. </span></p>

        <p class="p">As part of the Drift Synchronization Solution for
                  Hive, you can alternatively use record header attributes to perform record-based
                  writes. You can write records to the specified directory, use the defined Avro
                  schema, and roll files based on record header attributes. For more information,
                  see <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_lmn_gdc_1w">Record Header Attributes for Record-Based Writes</a>.</p>

        <p class="p">You can define a file prefix and suffix, the data time zone, and
                  properties that define when the destination closes a file. You can specify the
                  amount of time that a record can be written to its associated directory and what
                  happens to late records.</p>

        <p class="p">You can configure the Hadoop FS destination to write to Azure HDInsight.</p>

        <p class="p"><span class="ph">The destination can generate events for an event stream. For
                        more information about the event framework, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">Dataflow Triggers Overview</a>.</span></p>

        <p class="p">When necessary, you can enable Kerberos authentication and
                  specify a Hadoop user. You can also use Hadoop configuration files and add other
                  Hadoop configuration properties as needed. </p>

        <p class="p">You can use Gzip, Bzip2, Snappy, LZ4, and other compression
                  formats to write output files. </p>

        
    </div>

    
<article class="topic concept nested1" aria-labelledby="ariaid-title2" id="concept_cvc_skd_br">
 <h2 class="title topictitle2" id="ariaid-title2">Directory Templates</h2>

 <div class="body conbody">
  <p class="p">By default, the Hadoop FS destination uses directory templates
      to create output and late record directories. Hadoop FS writes records to the directories
      based on the configured time basis. </p>

    <p class="p">You can alternatively write records to directories based
                  on the targetDirectory record header attribute. Using the targetDirectory
                  attribute disables the ability to define directory templates.</p>

  <p class="p">When you define a directory template, you can use a mix
                  of constants, field values, and datetime variables. You can use the
                        <code class="ph codeph">every</code> function to create new directories at regular
                  intervals based on hours, minutes, or seconds, starting on the hour. You can also
                  use the <code class="ph codeph">record:valueOrDefault</code> function to use field values or a
                  default in the directory template. </p>

  <div class="p">For example, the following directory template creates
                  output directories for event data based on the state and timestamp of a record
                  with hours as the smallest unit of measure, creating a new directory every
                  hour:<pre class="pre codeblock"><code> /outputfiles/${record:valueOrDefault("/State", "unknown")}/${YY()}-${MM()}-${DD()}-${hh()}</code></pre></div>

  <div class="p">You can use the following elements in a directory template:<dl class="dl">
                        
                              <dt class="dt dlterm">Constants</dt>

                              <dd class="dd">You can use any constant, such as "output".</dd>

                        
                        
                              <dt class="dt dlterm">Datetime Variables</dt>

                              <dd class="dd">You can use datetime variables, such as <code class="ph codeph">${YYYY()}</code>
                                    or <code class="ph codeph">${DD()}</code>. The destination creates directories
                                    as needed, based on the smallest datetime variable that you use.
                                    For example, if the smallest variable is hours, then the
                                    directories are created for every hour of the day that receives
                                    output records.</dd>

                              <dd class="dd ddexpand">When you use datetime variables in an expression, use all of the
                                    datetime variables between one of the year variables and the
                                    smallest variable that you want to use. For example, to create
                                    directories on a daily basis for a Hadoop FS destination, use a
                                    year variable, a month variable, and then a day variable. You
                                    might use one of the following datetime variable progressions: </dd>

                              <dd class="dd ddexpand">
                                    <pre class="pre codeblock"><code>${YYYY()}-${MM()}-${DD()}
${YY()}_${MM()}_${DD()}</code></pre>
                              </dd>

                              <dd class="dd ddexpand">For details about datetime variables, see <a class="xref" href="../Expression_Language/DateTimeVariables.html#concept_gh4_qd2_sv" title="The expression language provides datetime variables for use in expressions.">Datetime Variables</a>.</dd>

                        
                        
                              <dt class="dt dlterm"><code class="ph codeph">every</code> function</dt>

                              <dd class="dd">You can use the <code class="ph codeph">every</code> function in a directory
                                    template to create directories at regular intervals based on
                                    hours, minutes, or seconds, beginning on the hour. The intervals
                                    should be a submultiple or integer factor of 60. For example,
                                    you can create directories every 15 minutes or 30 seconds. </dd>

                              <dd class="dd ddexpand">Use the <code class="ph codeph">every</code> function to replace the smallest
                                    datetime variable used in the template.</dd>

                              <dd class="dd ddexpand">For example, the following directory template creates directories
                                    every 5 minutes, starting on the
                                    hour:<pre class="pre codeblock"><code>/HDFS_output/${YYYY()}-${MM()}-${DD()}-${hh()}-${every(5,mm())}</code></pre></dd>

                              <dd class="dd ddexpand">For details about the <code class="ph codeph">every</code> function, see <a class="xref" href="../Expression_Language/Functions.html#concept_ddw_ld1_1s">Miscellaneous Functions</a>.</dd>

                        
                        
                              <dt class="dt dlterm"><code class="ph codeph">record:valueOrDefault</code> function</dt>

                              <dd class="dd">You can use the following expression to use the value of a field
                                    and the specified default value if the field does not exist or
                                    if the field is null:
                                    <pre class="pre codeblock"><code>${record:valueOrDefault(&lt;field path&gt;, &lt;default value&gt;)}</code></pre></dd>

                              <dd class="dd ddexpand">For example, the following directory template creates a directory
                                    based on the product field every day, and if the product field
                                    is empty or null, uses Misc in the directory path:
                                    <pre class="pre codeblock"><code>/${record:valueOrDefault("/Product", "Misc")}/${YY()}-${MM()}-${DD()}</code></pre></dd>

                              <dd class="dd ddexpand">This template might create the following
                                    paths:<pre class="pre codeblock"><code>/Shirts/2015-07-31 
/Misc/2015-07-31</code></pre></dd>

                        
                  </dl>
</div>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title3" id="concept_gkz_smd_br">
 <h2 class="title topictitle2" id="ariaid-title3">Time Basis</h2>

 <div class="body conbody">
  <p class="p">When using directory templates, the time basis
   helps determine when directories are created. It also determines the directory Hadoop FS uses
   when writing a record, and whether a record is late.</p>

  <p class="p"><span class="ph">When using the targetDirectory record header attribute
                        to write records, the time basis determines only whether a record is
                        late.</span></p>

  <p class="p">You can use the following times as the time basis: </p>

  <dl class="dl">
                  
                        <dt class="dt dlterm">Processing Time</dt>

                        <dd class="dd">When you use processing time as the time basis, the destination creates
                              directories based on the processing time and the directory template,
                              and writes records to the directories based on when they are
                              processed.</dd>

                        <dd class="dd ddexpand">For example, say a directory template creates directories every minute
                              and the time basis is the time of processing. Then, directories are
                              created for every minute that the destination writes output records.
                              And the output records are written to the directory for that minute of
                              processing. </dd>

                        <dd class="dd ddexpand">To use the processing time as the time basis, use the following
                              expression: <code class="ph codeph">${time:now()}</code>. This is the default time
                              basis. </dd>

                  
                  
                        <dt class="dt dlterm">Record Time</dt>

                        <dd class="dd">When you use the time associated with a record as the time basis, you
                              specify a Date field in the record. The destination creates
                              directories based on the datetimes associated with the records and
                              writes the records to the appropriate directories. </dd>

                        <dd class="dd ddexpand">For example, say a directory template creates directories every hour and
                              the time basis is based on the record. Then, directories are created
                              for every hour associated with output records and the destination
                              writes the records to the related output directory. </dd>

                        <dd class="dd ddexpand">To use a time associated with the record, use an expression that calls a
                              field and resolves to a datetime value, such as
                                    <code class="ph codeph">${record:value("/Timestamp")}</code>. </dd>

                  
            </dl>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title4" id="concept_xgm_g4d_br">
 <h2 class="title topictitle2" id="ariaid-title4">Late Records and Late Record Handling </h2>

 <div class="body conbody">
        <p class="p"></p>

        <p class="p">When you use a record time as the time basis, you can define
                  a time limit for records to be written to their associated output file. When the
                  destination creates a new output file in a new directory, the previous output file
                  is kept open for the specified late record time limit. When records that belong in
                  that file arrive within the time limit, the destination writes the records to the
                  open output file. When the late record time limit is reached, the output file is
                  closed and any record that arrives past this limit is considered late.</p>

        <div class="note tip"><span class="tiptitle">Tip:</span> The late records properties are not applicable if
                  you use processing time as the time basis. If you use processing time, set the
                  late record time limit to one second.</div>

     <p class="p">You can send late records to a late records file or to the
                  stage for error handling. When you send records to a late records file, you define
                  a late records directory template. </p>

        <div class="p">For example, you use a record time as the time basis,
                  configure a one hour late record time limit, configure late records to be sent to
                  the stage for error handling, and use the default directory template value:
                  <pre class="pre codeblock"><code>/tmp/out/${YYYY()}-${MM()}-${DD()}-${hh()} </code></pre></div>

        <p class="p">The first records that arrive have a datetime between the
                  hours of 02:00 and 02:59, and so are written to an output file in the 02
                  directory. When records with a datetime between the hours of 03:00 and 03:59
                  arrive, the destination creates a new file in an 03 directory. The destination
                  keeps the file in the 02 directory open for another hour. </p>

        <p class="p">If a record with a datetime between the hours of 02:00 and
                  02:59 arrives before the hour time limit, the destination writes the record to the
                  open file in the 02 directory. After one hour, the destination closes the output
                  file in the 02 directory. Any records with a datetime between the hours of 02:00
                  and 02:59 that arrive after the one hour time limit are considered late. The late
                  records are sent to the stage for error handling.</p>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title5" id="concept_qjs_dw3_tv">
 <h2 class="title topictitle2" id="ariaid-title5">Timeout to Close Idle Files</h2>

 <div class="body conbody">
        <p class="p">You can configure the maximum time that an open output
            file can remain idle. After no records are written to an output file for the specified
            amount of time, the Hadoop FS destination closes the file. </p>

        <p class="p">You might want to configure an idle timeout when output
                  files remain open and idle for too long, thus delaying another system from
                  processing the files.</p>

        <div class="p">Output files might remain idle for too long for the following
                  reasons: <ul class="ul" id="concept_qjs_dw3_tv__d24e4172">
                        <li class="li">You configured the maximum number of records to be written to output
                              files or the maximum size of output files, but records have stopped
                              arriving. An output file that has not reached the maximum number of
                              records or the maximum file size stays open until more records
                              arrive.</li>

                        <li class="li">You configured a date field in the record as the time basis and have
                              configured a late record time limit, but records arrive in
                              chronological order. When a new directory is created, the output file
                              in the previous directory remains open for the configured late record
                              time limit. However, no records are ever written to the open file in
                              the previous directory.<p class="p">For example, when a record with a datetime
                                    of 03:00 arrives, the destination creates a new file in a new 03
                                    directory. The previous file in the 02 directory is kept open
                                    for the late record time limit, which is an hour by default.
                                    However, when records arrive in chronological order, no records
                                    that belong in the 02 directory arrive after the 03 directory is
                                    created. </p>
</li>

                  </ul>
</div>

        <p class="p">In either situation, configure an idle timeout so that other
                  systems can process the files sooner, instead of waiting for the configured
                  maximum records, maximum file size, or late records conditions to occur. </p>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title6" id="concept_uv2_vfb_vy">
 <h2 class="title topictitle2" id="ariaid-title6">Recovery</h2>

 <div class="body conbody">
  <p class="p">The Hadoop FS destination supports recovery after an
            unexpected stop of the pipeline by renaming temporary files when the pipeline
            restarts.</p>

        <div class="p">The destination names temporary open output files using the
                  following format:<pre class="pre codeblock"><code>_tmp_&lt;prefix&gt;_&lt;runnerId&gt;</code></pre>Where
                        <code class="ph codeph">&lt;prefix&gt;</code> is the file prefix defined for the destination
                  and <code class="ph codeph">&lt;runnerId&gt;</code> is the ID of the pipeline runner performing the
                  pipeline processing. For example, when the destination prefix is defined as
                        <code class="ph codeph">sdc</code> and the destination runs from a single-threaded
                  pipeline, the temporary file is named like so: <code class="ph codeph">_tmp_sdc_0</code>. </div>
<div class="p">When the destination closes the file, either after it is fully
                  written, after the idle timeout expires, or when you deliberately stop the
                  pipeline, it renames the file to remove the <code class="ph codeph">_tmp_</code> string and to
                  replace the pipeline runner ID with a random unique identifier like
                  so:<pre class="pre codeblock"><code>&lt;prefix&gt;_e7ce67c5-013d-47a7-9496-8c882ddb28a0</code></pre></div>
<p class="p">However, when the pipeline stops unexpectedly, the temporary
                  files remain. When the pipeline restarts, the destination scans all subdirectories
                  of the defined directory template to rename any temporary files that match the
                  defined prefix for the destination. After the destination renames the temporary
                  files, it continues writing to new output files.</p>
<div class="note note"><span class="notetitle">Note:</span> The destination renames all temporary files that match the
                  defined prefix in all subdirectories of the defined directory template, even if
                  those files were not written by that pipeline. So if you happen to have another
                  file whose name begins with the same pattern - <code class="ph codeph">_tmp_&lt;prefix&gt;</code> -
                  the destination renames that file also.</div>
<div class="p">The destination might not rename all temporary files in the
                  following situations:<dl class="dl">
                        
                              <dt class="dt dlterm">The directory template includes an expression with the
                                    record:value or record:valueOrDefault function.</dt>

                              <dd class="dd">If the record:value or record:valueOrDefault function evaluates to
                                    an empty string or to a subdirectory, the destination cannot
                                    determine those locations when the pipeline restarts. As a
                                    result, the destination cannot rename any temporary files
                                    written to those locations.</dd>

                              <dd class="dd ddexpand">For example, let’s assume that the directory template is defined
                                    as
                                    follows:<pre class="pre codeblock"><code>/tmp/out/${YY()}-${MM()}-${DD()}/${sdc:hostname()}/${record:value('/a')}/${record:value('/b')}</code></pre></dd>

                              <dd class="dd ddexpand">If the expression <code class="ph codeph">${record:value('/b')}</code> evaluates
                                    to an empty string or to a subdirectory such as
                                          <code class="ph codeph">/folder1/folder2</code>, then the destination
                                    cannot determine those locations when the pipeline restarts.
                              </dd>

                        
                        
                              <dt class="dt dlterm">The directory is defined in the targetDirectory record header
                                    attribute.</dt>

                              <dd class="dd">When the directory is defined in the targetDirectory record header
                                    attribute, the destination cannot determine where to look for
                                    temporary files when the pipeline restarts. As a result, it
                                    cannot rename the temporary files.</dd>

                        
                  </dl>
</div>
<p class="p">In either of these situations, you must manually rename the
                  temporary files.</p>
<p class="p">File recovery can slow down the pipeline as it restarts. If
                  needed, you can configure the destination to skip file recovery.</p>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title7" id="concept_lww_3b3_kr">
 <h2 class="title topictitle2" id="ariaid-title7">Data Formats</h2>

 <div class="body conbody">
  <div class="p">Hadoop FS writes data to
      HDFS based on the data format that you select. You can use the following data formats: <dl class="dl">
        
                              <dt class="dt dlterm">Avro</dt>

                              <dd class="dd">The destination writes records based on the Avro schema. You can
                                    use one of the following methods to specify the location of the
                                    Avro schema definition:</dd>

                              <dd class="dd ddexpand">
                                    <ul class="ul" id="concept_lww_3b3_kr__d24e3182">
                                          <li class="li"><span class="ph uicontrol">In Pipeline Configuration</span> - Use
                                                the schema that you provide in the stage
                                                configuration.</li>

                                          <li class="li"><span class="ph uicontrol">In Record Header</span> - Use the
                                                schema included in the avroSchema record header
                                                attribute.</li>

                                          <li class="li"><span class="ph uicontrol">Confluent Schema Registry</span> -
                                                Retrieve the schema from Confluent Schema Registry.
                                                The Confluent Schema Registry is a distributed
                                                storage layer for Avro schemas. You can configure
                                                the destination to look up the schema in the
                                                Confluent Schema Registry by the schema ID or
                                                subject. <p class="p">If using the Avro schema in the stage or
                                                  in the record header attribute, you can optionally
                                                  configure the destination to register the Avro
                                                  schema with the Confluent Schema
                                                Registry.</p>
</li>

                                    </ul>

                              </dd>

                              <dd class="dd ddexpand">The destination includes the schema definition in each file.</dd>

                              <dd class="dd ddexpand">You can compress data with an Avro-supported compression codec.
                                    When using Avro compression, avoid using other compression
                                    properties in the destination. </dd>

                        
        
                              <dt class="dt dlterm">Binary</dt>

                              <dd class="dd">The destination writes binary data from a single field in the
                                    record. </dd>

                        
        
                              <dt class="dt dlterm">Delimited</dt>

                              <dd class="dd">The destination writes records as delimited data. When you use
                                    this data format, the root field must be list or list-map.</dd>

                              <dd class="dd ddexpand">
                                    <div class="p">You can use the following delimited format types: <ul class="ul" id="concept_lww_3b3_kr__ul_jtv_5sl_mcb">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                  </ul>
</div>

                              </dd>

                        
        
                              <dt class="dt dlterm">JSON</dt>

                              <dd class="dd">The destination writes records as JSON data. You can use one of
                                    the following formats:<ul class="ul" id="concept_lww_3b3_kr__d24e3344">
                                          <li class="li">Array - Each file includes a single array. In the
                                                array, each element is a JSON representation of each
                                                record.</li>

                                          <li class="li">Multiple objects - Each file includes multiple JSON
                                                objects. Each object is a JSON representation of a
                                                record. </li>

                                    </ul>
</dd>

                        
        
                        <dt class="dt dlterm">Protobuf</dt>

                        <dd class="dd">Writes a batch of messages in each file. </dd>

                        <dd class="dd ddexpand">Uses the user-defined message type and the definition of the message
                              type in the descriptor file to generate the messages in the file. </dd>

                        <dd class="dd ddexpand">For information about generating the descriptor file, see <a class="xref" href="../Data_Formats/Protobuf-Prerequisites.html" title="Perform the following prerequisites before reading or writing protobuf data.">Protobuf Data Format Prerequisites</a>.</dd>

                  
        
                        <dt class="dt dlterm">SDC Record</dt>

                        <dd class="dd">The destination writes records in the SDC Record data format. </dd>

                  
        
                        <dt class="dt dlterm">Text</dt>

                        <dd class="dd">The destination writes data from a single text field to the destination
                              system. When you configure the stage, you select the field to use.
                              When necessary, merge record data into the field earlier in the
                              pipeline. </dd>

                        <dd class="dd ddexpand">You can configure the characters to use as record separators. By
                              default, the destination uses a UNIX-style line ending (\n) to
                              separate records.</dd>

                        <dd class="dd ddexpand">When a record does not contain the selected text field, you can
                              configure the destination to report the missing field as an error or
                              to ignore the missing field. By default, the destination reports an
                              error.</dd>

                        <dd class="dd ddexpand">When configured to ignore a missing text field, you can configure the
                              destination to discard the record or to write the record separator
                              characters to create an empty line for the record. By default, the
                              destination discards the record.</dd>

                  
        
                        <dt class="dt dlterm">Whole File</dt>

                        <dd class="dd">Streams whole files to the destination system. The destination writes
                              the data to the file and location defined in the stage. If a file of
                              the same name already exists, you can configure the destination to
                              overwrite the existing file or send the current file to error.</dd>

                        <dd class="dd ddexpand">By default, written files use the default access permissions for the
                              destination system. You can specify an expression that defines access
                              permissions. </dd>

                        <dd class="dd ddexpand">You can configure the destination to generate a checksum for the written
                              file and pass checksum information to the destination system in an
                              event record. </dd>

                        <dd class="dd ddexpand">Using this data format requires setting the <span class="keyword wintitle">File
                                    Type</span> property to <span class="ph uicontrol">Whole
                              File</span>.</dd>

                        <dd class="dd ddexpand">For more information about the whole file data format, see <a class="xref" href="../Data_Formats/WholeFile.html#concept_nfc_qkh_xw" title="You can use the whole file data format to transfer entire files from an origin system to a destination system. With the whole file data format, you can transfer any type of file.">Whole File Data Format</a>.</dd>

                  
      </dl>
</div>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title8" id="concept_n42_z2f_sw">
    <h2 class="title topictitle2" id="ariaid-title8">Writing to Azure HDInsight</h2>

    
    <div class="body conbody"><p class="shortdesc">You can use the HDP stage libraries to write to Azure Blob storage using the WASB
        protocol. This enables the Hadoop FS destination to write directly to Azure HDInsight. </p>

        <p class="p">To write to an Azure HDInsight
            cluster, <span class="ph">Data Collector</span> can
            be installed anywhere. It can be installed on a node in the HDInsight cluster or outside
            of the cluster entirely. </p>

        <div class="p">To write to HDInsight, configure the Hadoop FS destination as follows: <ol class="ol" id="concept_n42_z2f_sw__ol_kvn_mnf_sw">
                <li class="li">On the <span class="keyword wintitle">General</span> tab of the Hadoop FS destination, for the
                        <span class="ph uicontrol">Stage Library</span> property, select the HDP stage library
                    version 2.4 or later. </li>

                <li class="li">Configure Azure credentials in one of the following ways:<ul class="ul" id="concept_n42_z2f_sw__ul_hzr_q2g_sw">
                        <li class="li">If the Azure credentials are defined in the HDFS configuration file
                                <code class="ph codeph">core-site.xml</code>, configure the destination to access
                            the file.<ol class="ol" type="a" id="concept_n42_z2f_sw__ol_sjt_rmd_rx">
                                <li class="li">On the <span class="ph uicontrol">Hadoop FS</span> tab, configure the
                                        <span class="ph uicontrol">Hadoop FS Configuration Directory</span>
                                    property to point to the directory that includes the file. </li>

                            </ol>
</li>

                        <li class="li">If the credentials are not defined in the <code class="ph codeph">core-site.xml</code>
                            file, use a Hadoop FS configuration property to pass the Azure
                                credentials:<ol class="ol" type="a" id="concept_n42_z2f_sw__ol_yxb_1ht_px">
                                <li class="li">In the destination, on the <span class="keyword wintitle">Hadoop FS</span> tab,
                                    click the <span class="ph uicontrol">Add</span> icon to add a new Hadoop FS
                                    configuration property. <p class="p">You can use <a class="xref" href="../Pipeline_Configuration/SimpleBulkEdit.html#concept_alb_b3y_cbb">simple or bulk edit mode</a> to add configuration
                                        properties.</p>
</li>

                                <li class="li">Enter the following property name, using the Azure storage
                                    account name for &lt;storage account
                                    name&gt;:<pre class="pre codeblock"><code>fs.azure.account.key.&lt;storage account name&gt;.blob.core.windows.net</code></pre>For
                                    example, if the storage account name is "sdchd", then enter the
                                    following name for the property:
                                        <pre class="pre codeblock"><code>fs.azure.account.key.sdchd.blob.core.windows.net</code></pre><div class="note tip"><span class="tiptitle">Tip:</span> You can find the Azure storage account name on
                                        the <span class="keyword wintitle">Access Keys</span> page in the Microsoft
                                        Azure portal. To view the page in the Microsoft Azure
                                        portal, click <span class="ph menucascade"><span class="ph uicontrol">All Resources</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Storage Account</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Access Keys</span></span>. A page like the following appears, with the
                                        storage account name and access keys:</div>
<p class="p"><img class="image" id="concept_n42_z2f_sw__image_v3c_j3t_px" src="../Graphics/Azure-AccessKeys.png" height="425" width="602" /></p>
</li>

                                <li class="li">For the value of the Hadoop FS Configuration property, enter an
                                    access key value for the Azure storage account. You can use any
                                    valid key.<div class="p">
                                        <div class="note tip"><span class="tiptitle">Tip:</span> The account key value also displays on the
                                                <span class="keyword wintitle">Access Keys</span> page. For example,
                                            on the image above, you could use either the key1 or
                                            key2 value. </div>

                                    </div>
</li>

                            </ol>
</li>

                    </ul>
</li>

                <li class="li">In the destination, on the <span class="keyword wintitle">Hadoop FS</span> tab, configure the
                        <span class="ph uicontrol">Hadoop FS URI</span> property using the following
                        structure:<pre class="pre codeblock"><code>&lt;wasb[s]&gt;://&lt;container name&gt;@&lt;storage account name&gt;.blob.core.windows.net/&lt;path to files&gt;</code></pre><p class="p">In
                        the URI, &lt;container name&gt; is the Azure container name. And &lt;storage
                        account name&gt; is the same Azure storage account name that you used for the
                        Hadoop FS configuration property. </p>
<div class="p">For example, for a
                            <code class="ph codeph">sdc-hd</code> container in a storage account named
                            <code class="ph codeph">sdchd</code>, with all files in a "files" directory, you would
                        define the Hadoop FS URI as
                        follows:<pre class="pre codeblock"><code>wasbs://sdc-hd@sdchd.blob.core.windows.net/files</code></pre></div>
<div class="p">
                        <div class="note tip"><span class="tiptitle">Tip:</span> You can find the container name and storage account name on
                            the <span class="keyword wintitle">Essentials</span> page in the Microsoft Azure portal.
                            For a standard storage account, in the Microsoft Azure portal, click <span class="ph menucascade"><span class="ph uicontrol">All Resources</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Storage Account</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Overview</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Blobs</span></span>. For a blob storage account, click <span class="ph menucascade"><span class="ph uicontrol">All Resources</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Storage Account</span><abbr title="and then"> &gt; </abbr><span class="ph uicontrol">Overview</span></span>. </div>

                    </div>
<p class="p">A page like the following displays with the container name and storage
                        account name:</p>
<p class="p"><img class="image" id="concept_n42_z2f_sw__image_r2s_snt_px" src="../Graphics/Azure-BlobService.png" height="374" width="498" /></p>
Though the host name for the
                    Hadoop FS URI is <code class="ph codeph">&lt;storage account
                        name&gt;.blob.core.windows.net</code>, you can alternatively use the host
                    name of the Azure blob service endpoint as the hostname for the Hadoop FS
                    URI.</li>

            </ol>
</div>

        <section class="section"><h3 class="title sectiontitle">Example</h3>
            
            <p class="p">The following image shows how to configure the Hadoop FS destination to write to
                HDInsight using the Azure account information in the examples above:</p>

            <p class="p"><img class="image" id="concept_n42_z2f_sw__image_mxh_t44_qx" src="../Graphics/Azure-HadoopFS.png" height="192" width="664" /></p>

        </section>

    </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title9" id="concept_bvb_rxj_px">
 <h2 class="title topictitle2" id="ariaid-title9">Event Generation</h2>

 <div class="body conbody">
        <p class="p">The Hadoop FS destination
                <span class="ph">can generate events that you can use in an event stream. When
                        you enable event generation, the destination generates event records each
                        time the destination closes a file or completes streaming a whole file.
                  </span></p>

        <div class="p">Hadoop FS events can be used in any logical way. For example: <ul class="ul" id="concept_bvb_rxj_px__ul_sww_spb_rx">
                        <li class="li" id="concept_bvb_rxj_px__d24e2152">With the HDFS File Metadata executor to move
                              or change permissions on closed files. <p class="p">For an example, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_d1q_xl4_lx">Case Study: Output File Management</a>.</p>
</li>

                        <li class="li" id="concept_bvb_rxj_px__d24e2159">With the Hive Query executor to run Hive or
                              Impala queries after closing output files. <p class="p">For an example, see
                                          <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_szz_xwm_lx">Case Study: Impala Metadata Updates for DDS for Hive</a>.</p>
</li>

                        <li class="li" id="concept_bvb_rxj_px__d24e2166">With the MapReduce executor to convert
                              completed Avro files to ORC files or to Parquet. <p class="p">For an example,
                                    see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_jkm_rnz_kx">Case Study: Parquet Conversion</a>.</p>
</li>

                        <li class="li" id="concept_bvb_rxj_px__d24e2173">With the Email executor to send a custom email
                              after receiving an event.<p class="p">For an example, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_t2t_lp5_xz">Case Study: Sending Email</a>.</p>
</li>

                        <li class="li" id="concept_bvb_rxj_px__d24e2180">With a destination to store event information.
                                    <p class="p">For an example, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_ocb_nnl_px">Case Study: Event Storage</a>.</p>
</li>

                  </ul>
</div>

        <p class="p"><span class="ph">For more information about dataflow
                        triggers and the event framework, see <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">Dataflow Triggers Overview</a>.</span></p>

 </div>

<article class="topic concept nested2" aria-labelledby="ariaid-title10" id="concept_dmx_1ln_qx">
    <h3 class="title topictitle3" id="ariaid-title10">Event Records</h3>

    <div class="body conbody">
        <p class="p">Hadoop FS event records include the following
            event-related record header attributes. Record header attributes are stored as String
            values:</p>

        <div class="p">
            
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_dmx_1ln_qx__table_ilm_xsc_rx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
      <tr>
       <th class="entry cellrowborder" id="d101775e1205">Record Header Attribute</th>

       <th class="entry cellrowborder" id="d101775e1208">Description</th>

      </tr>

     </thead>
<tbody class="tbody">
      <tr>
       <td class="entry cellrowborder" id="concept_dmx_1ln_qx__d23e2214" headers="d101775e1205 ">sdc.event.type</td>

       <td class="entry cellrowborder" headers="d101775e1208 ">Event type. Uses one of the following types:<ul class="ul" id="concept_dmx_1ln_qx__d23e2219">
         <li class="li">file-closed - Generated when the destination closes a file.</li>

         <li class="li">wholeFileProcessed - Generated when the destination completes streaming a whole
          file.</li>

        </ul>
</td>

      </tr>

      <tr id="concept_dmx_1ln_qx__d23e2229">
       <td class="entry cellrowborder" headers="d101775e1205 ">sdc.event.version</td>

       <td class="entry cellrowborder" headers="d101775e1208 ">An integer that indicates the version of the event record type.</td>

      </tr>

      <tr id="concept_dmx_1ln_qx__d23e2238">
       <td class="entry cellrowborder" headers="d101775e1205 ">sdc.event.creation_timestamp</td>

       <td class="entry cellrowborder" id="concept_dmx_1ln_qx__d23e2243" headers="d101775e1208 ">Epoch timestamp when the stage created the event.
       </td>

      </tr>

     </tbody>
</table>
</div>

        </div>

        <div class="p">The destination can generate the following types of event records:<dl class="dl">
                        
                              <dt class="dt dlterm">File closure</dt>

                              <dd class="dd">The destination generates a file closure event record when it
                                    closes an output file. </dd>

                              <dd class="dd ddexpand">File closure event records have the
                                          <code class="ph codeph">sdc.event.type</code> record header attribute
                                    set to <code class="ph codeph">file-closed</code> and include the following
                                          fields:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_dmx_1ln_qx__d24e4499" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                                  <tr>
                                                  <th class="entry cellrowborder" id="d101775e1286">Field</th>

                                                  <th class="entry cellrowborder" id="d101775e1289">Description</th>

                                                  </tr>

                                                </thead>
<tbody class="tbody">
                                                  <tr>
                                                  <td class="entry cellrowborder" headers="d101775e1286 ">filepath</td>

                                                  <td class="entry cellrowborder" headers="d101775e1289 ">Absolute path to the closed file. </td>

                                                  </tr>

                                                  <tr>
                                                  <td class="entry cellrowborder" headers="d101775e1286 ">filename</td>

                                                  <td class="entry cellrowborder" headers="d101775e1289 ">File name of the closed file.</td>

                                                  </tr>

                                                  <tr>
                                                  <td class="entry cellrowborder" headers="d101775e1286 ">length</td>

                                                  <td class="entry cellrowborder" headers="d101775e1289 ">Size of the closed file in bytes.</td>

                                                  </tr>

                                                </tbody>
</table>
</div>
</dd>

                        
                        
                              <dt class="dt dlterm">Whole file processed</dt>

                              <dd class="dd">The destination generates an event record when it completes
                                    streaming a whole file. Whole file event records have the
                                          <code class="ph codeph">sdc.event.type</code> record header attribute
                                    set to <code class="ph codeph">wholeFileProcessed</code> and have the
                                    following fields:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_dmx_1ln_qx__d24e4565" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                                  <tr>
                                                  <th class="entry cellrowborder" id="d101775e1352">Field</th>

                                                  <th class="entry cellrowborder" id="d101775e1355">Description</th>

                                                  </tr>

                                                </thead>
<tbody class="tbody">
                                                  <tr>
                                                  <td class="entry cellrowborder" headers="d101775e1352 ">sourceFileInfo</td>

                                                  <td class="entry cellrowborder" headers="d101775e1355 ">A map of attributes about the original
                                                  whole file that was processed. The attributes
                                                  include:<ul class="ul" id="concept_dmx_1ln_qx__d24e4594">
                                                  <li class="li">size - Size of the whole file in bytes. </li>

                                                  </ul>
<p class="p">Additional attributes depend on the
                                                  information provided by the origin system.
                                                  </p>
</td>

                                                  </tr>

                                                  <tr>
                                                  <td class="entry cellrowborder" headers="d101775e1352 ">targetFileInfo</td>

                                                  <td class="entry cellrowborder" headers="d101775e1355 ">A map of attributes about the whole file
                                                  written to the destination. The attributes
                                                  include:<ul class="ul" id="concept_dmx_1ln_qx__d24e4610">
                                                  <li class="li">path - An absolute path the processed whole
                                                  file.</li>

                                                  </ul>
</td>

                                                  </tr>

                                                  <tr id="concept_dmx_1ln_qx__d24e4617">
                                                  <td class="entry cellrowborder" headers="d101775e1352 ">checksum</td>

                                                  <td class="entry cellrowborder" headers="d101775e1355 ">Checksum generated for the written file.
                                                  <p class="p">Included only when you configure the
                                                  destination to include checksums in the event
                                                  record. </p>
</td>

                                                  </tr>

                                                  <tr id="concept_dmx_1ln_qx__d24e4628">
                                                  <td class="entry cellrowborder" headers="d101775e1352 ">checksumAlgorithm</td>

                                                  <td class="entry cellrowborder" headers="d101775e1355 ">Algorithm used to generate the checksum.
                                                  <p class="p">Included only when you configure the
                                                  destination to include checksums in the event
                                                  record. </p>
</td>

                                                  </tr>

                                                </tbody>
</table>
</div>
</dd>

                        
                  </dl>
</div>

    </div>

</article>
</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title11" id="concept_xy5_4tm_vs">
  <h2 class="title topictitle2" id="ariaid-title11">Kerberos Authentication</h2>

  <div class="body conbody">
    <p class="p"><span class="ph">You can use Kerberos authentication to connect to HDFS. When you
                use Kerberos authentication, <span class="ph">Data Collector</span>
                uses the Kerberos principal and keytab to connect to HDFS. By default, <span class="ph">Data Collector</span>
                uses the user account who started it to connect.</span></p>

    <p class="p"><span class="ph">The Kerberos principal and keytab are defined in the <span class="ph">Data Collector</span>
                configuration file, <code class="ph codeph">$SDC_CONF/sdc.properties</code>. To use Kerberos
                authentication, configure all Kerberos properties in the <span class="ph">Data Collector</span>
                configuration file, and then enable Kerberos in the</span> Hadoop FS destination.</p>

    <p class="p"><span class="ph">For more information about enabling Kerberos authentication
                        for <span class="ph">Data Collector</span>, see <a class="xref" href="../Configuration/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Kerberos Authentication</a>.</span></p>

  </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title12" id="concept_u4h_lwt_ls">
 <h2 class="title topictitle2" id="ariaid-title12">Using an HDFS User</h2>

 <div class="body conbody">
  <p class="p"><span class="ph"><span class="ph">Data Collector</span>
                        can either use the currently logged in <span class="ph">Data Collector</span> user or a
                        user configured in the</span>
      destination to write to HDFS. </p>

    <p class="p">A <span class="ph">Data Collector</span> configuration property can be set that requires using the currently logged in
                        <span class="ph">Data Collector</span> user. When
                  this property is not set, you can specify a user in the origin. For more
                  information about Hadoop impersonation and the Data Collector property, see <a class="xref" href="../Configuration/DCConfig.html#concept_pmr_sy5_nz">Hadoop Impersonation Mode</a>. </p>

    <p class="p">Note that the destination <span class="ph">uses a different user account to
                        connect to HDFS. <span class="ph" id="concept_u4h_lwt_ls__d24e3772">By default, <span class="ph">Data Collector</span> uses
                              the user account who started it to connect to external systems. When
                              using Kerberos, <span class="ph">Data Collector</span> uses
                              the Kerberos principal.</span>
                  </span></p>

  <div class="p">To configure a user in the destination to write to HDFS, perform the following tasks:<ol class="ol" id="concept_u4h_lwt_ls__ul_mb1_xpt_ls">
                <li class="li">On Hadoop, configure the user as a proxy user and
                              authorize the user to impersonate a Hadoop user. <p class="p">For more
                                    information, see the Hadoop documentation. </p>
</li>

                <li class="li">In the Hadoop FS destination, on the <span class="keyword wintitle">Hadoop FS</span> tab,
                    configure the <span class="ph uicontrol">HDFS User</span> property.</li>

            </ol>
</div>

 </div>

</article>
<article class="topic concept nested1" aria-labelledby="ariaid-title13" id="concept_xh5_y4d_br">
    <h2 class="title topictitle2" id="ariaid-title13">HDFS Properties and Configuration Files</h2>

    <div class="body conbody">
        <div class="p">You can configure the Hadoop FS destination
            to use individual HDFS properties or HDFS configuration files:<dl class="dl">
                
                    <dt class="dt dlterm">HDFS configuration files</dt>

                    <dd class="dd">You can use the following HDFS configuration files with the Hadoop FS
                            destination:<ul class="ul" id="concept_xh5_y4d_br__ul_qhn_ytr_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                  </ul>
</dd>

                    <dd class="dd ddexpand">To use HDFS configuration files: <ol class="ol" id="concept_xh5_y4d_br__ol_rb2_2nr_bt">
                            <li class="li">Store the files or a symlink to the files in the <span class="ph">Data Collector</span> resources directory. </li>

                            <li class="li">In the Hadoop FS destination, specify the location of the files.
                            </li>

                        </ol>
<div class="note note"><span class="notetitle">Note:</span>  For a Cloudera Manager installation, Data Collector
                            automatically creates a symlink to the files named
                                <code class="ph codeph">hadoop-conf</code>. Enter <code class="ph codeph">hadoop-conf</code> for
                            the location of the files in the Hadoop FS destination.</div>
</dd>

                
                
                    <dt class="dt dlterm">Individual properties</dt>

                    <dd class="dd">You can configure individual HDFS properties in the destination. To add an
                        HDFS property, you specify the exact property name and the value. The Hadoop
                        FS destination does not validate the property names or
                            values.<div class="note note"><span class="notetitle">Note:</span> Individual properties override properties defined in the
                            HDFS configuration file. </div>
</dd>

                
            </dl>
</div>

    </div>

</article>
<article class="topic task nested1" aria-labelledby="ariaid-title14" id="task_m2m_skm_zq">
    <h2 class="title topictitle2" id="ariaid-title14">Configuring a Hadoop FS Destination</h2>

    <div class="body taskbody">
        <section class="section context">
            <p class="p">Configure a Hadoop FS
                destination to write data to HDFS.</p>

        </section>

        <ol class="ol steps" id="task_m2m_skm_zq__steps_ljw_44d_br"><li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__table_yxz_pvs_5x" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e1680">General Property</th>

                                    <th class="entry cellrowborder" id="d101775e1683">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
       <td class="entry cellrowborder" headers="d101775e1680 ">Name</td>

       <td class="entry cellrowborder" headers="d101775e1683 ">Stage name.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d101775e1680 ">Description</td>

       <td class="entry cellrowborder" headers="d101775e1683 ">Optional description.</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d101775e1680 ">Stage Library</td>

       <td class="entry cellrowborder" headers="d101775e1683 ">Library version that you want to use. </td>

      </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1680 ">Produce Events <a class="xref" href="HadoopFS-destination.html#concept_bvb_rxj_px">
                                            <img class="image" id="task_m2m_skm_zq__image_xsl_2rx_mx" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1683 ">Generates event records when events occur. Use for event
        handling. <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">
         <img class="image" id="task_m2m_skm_zq__d23e2111" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d101775e1680 ">Required Fields <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_dnj_bkm_vq">
         <img class="image" id="task_m2m_skm_zq__d23e2120" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d101775e1683 ">Fields that must include data for the record to be passed into the stage. <div class="note tip"><span class="tiptitle">Tip:</span> You might include fields that the stage uses.</div>
<p class="p">Records
         that do not include all required fields are processed based on the error handling
         configured for the pipeline.</p>
</td>

      </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d101775e1680 ">Preconditions <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_msl_yd4_fs">
         <img class="image" id="task_m2m_skm_zq__d23e2137" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

       <td class="entry cellrowborder" headers="d101775e1683 ">Conditions that must evaluate to TRUE to allow a record to enter the stage for
        processing. Click <span class="ph uicontrol">Add</span> to create additional preconditions. <p class="p">Records
         that do not meet all preconditions are processed based on the error handling configured for
         the stage.</p>
</td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the Properties panel, on the <span class="keyword wintitle">General</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e6265" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e1797">General Property</th>

                                    <th class="entry cellrowborder" id="d101775e1800">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1797 ">Name</td>

                                    <td class="entry cellrowborder" headers="d101775e1800 ">Stage name.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1797 ">Description</td>

                                    <td class="entry cellrowborder" headers="d101775e1800 ">Optional description.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1797 ">Stage Library</td>

                                    <td class="entry cellrowborder" headers="d101775e1800 ">Library version that you want to use. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1797 ">Produce Events <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_zrl_mhn_lx">
                                            <img class="image" id="task_m2m_skm_zq__d16e6320" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1800 ">Generates event records when events occur. Use for event
                                        handling. <a class="xref" href="../Event_Handling/EventFramework-Title.html#concept_cph_5h4_lx">
                                            <img class="image" id="task_m2m_skm_zq__d16e6326" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1797 ">Required Fields <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_dnj_bkm_vq">
                                            <img class="image" id="task_m2m_skm_zq__d16e6335" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1800 ">Fields that must include data for the record to be passed
                                        into the stage. <div class="note tip"><span class="tiptitle">Tip:</span> You might
                                            include fields that the stage uses.</div>
<p class="p">Records
                                            that do not include all required fields are processed
                                            based on the error handling configured for the
                                            pipeline.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1797 ">Preconditions <a class="xref" href="../Pipeline_Design/DroppingUnwantedRecords.html#concept_msl_yd4_fs">
                                            <img class="image" id="task_m2m_skm_zq__d16e6352" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1800 ">Conditions that must evaluate to TRUE to allow a record
                                        to enter the stage for processing. Click
                                            <span class="ph uicontrol">Add</span> to create additional
                                        preconditions. <p class="p">Records that do not meet all preconditions
                                            are processed based on the error handling configured for
                                            the stage.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1797 ">On Record Error <a class="xref" href="../Pipeline_Design/ErrorHandling.html#concept_atr_j4y_5r">
                                            <img class="image" id="task_m2m_skm_zq__d16e6369" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1800 ">Error record handling for the stage: <ul class="ul" id="task_m2m_skm_zq__d16e6373">
                                            <li class="li">Discard - Discards the record.</li>

                                            <li class="li">Send to Error - Sends the record to the pipeline for
                                                error handling.</li>

                                            <li class="li">Stop Pipeline - Stops the pipeline.</li>

                                        </ul>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Hadoop FS</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__table_rst_t4d_br" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:33.33333333333333%" /><col style="width:66.66666666666666%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e1938">Hadoop FS Property</th>

                                    <th class="entry cellrowborder" id="d101775e1941">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                            <td class="entry cellrowborder" headers="d101775e1938 ">Hadoop FS URI</td>

                            <td class="entry cellrowborder" headers="d101775e1941 ">Optional HDFS URI. <p class="p" id="task_m2m_skm_zq__d76e502">When not configured,
                                    the destination uses the URI defined by the fs.defaultFS
                                    property in the core-site.xml file. </p>
</td>

                        </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1938 ">HDFS User <a class="xref" href="HadoopFS-destination.html#concept_u4h_lwt_ls">
                                            <img class="image" id="task_m2m_skm_zq__image_byg_yqg_xs" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1941 ">The HDFS user to use to access HDFS. When
                                using this property, make sure HDFS is configured
                                    appropriately.<p class="p">When not configured, the pipeline uses the
                                    currently logged in <span class="ph">Data Collector</span> user. </p>
<p class="p">Not configurable when <span class="ph">Data Collector</span> is configured to use the currently logged in <span class="ph">Data Collector</span> user. <span class="ph">For more information, see <a class="xref" href="../Configuration/DCConfig.html#concept_pmr_sy5_nz">Hadoop Impersonation Mode</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1938 ">Kerberos Authentication <a class="xref" href="HadoopFS-destination.html#concept_xy5_4tm_vs">
                                            <img class="image" id="task_m2m_skm_zq__image_a5x_jzn_vs" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1941 ">Uses Kerberos credentials to connect to HDFS.
                                    <p class="p">When selected, uses the Kerberos principal and keytab defined
                                    in the <span class="ph">Data Collector</span> configuration file,
                                    <code class="ph codeph">$SDC_CONF/sdc.properties</code>. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e1938 ">Hadoop FS Configuration Directory <a class="xref" href="HadoopFS-destination.html#concept_xh5_y4d_br">
                                            <img class="image" id="task_m2m_skm_zq__image_br4_fgs_5r" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e1941 ">Location of the HDFS configuration
                                    files.<p class="p">For a Cloudera Manager installation, enter
                                        <code class="ph codeph">hadoop-conf</code>. For all other installations,
                                    use a directory or symlink within the <span class="ph">Data Collector</span> resources directory.</p>
<div class="p">You can use the following files
                                    with the Hadoop FS destination:<ul class="ul" id="task_m2m_skm_zq__ul_qnc_jtt_bt">
                        <li class="li">core-site.xml</li>

                        <li class="li">hdfs-site.xml </li>

                  </ul>
</div>
<div class="note note"><span class="notetitle">Note:</span> Properties in the configuration files are
                                    overridden by individual properties defined in the
                                stage.</div>
</td>

                                </tr>

                                <tr>
                            <td class="entry cellrowborder" headers="d101775e1938 ">Hadoop FS Configuration</td>

                            <td class="entry cellrowborder" headers="d101775e1941 ">Additional HDFS properties to use. <p class="p">To add properties, click
                                        <span class="ph uicontrol">Add</span> and define the property name and
                                    value. Use the property names and values as expected by
                                    HDFS.</p>
</td>

                        </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Output Files</span> tab, configure the following
                    options:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__table_i4x_jh5_sv" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e2086">Output Files Property</th>

                                    <th class="entry cellrowborder" id="d101775e2089">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">File Type</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Output file type:<ul class="ul" id="task_m2m_skm_zq__d16e7880">
                                            <li class="li">Text files</li>

                                            <li class="li">Sequence files</li>

                                            <li class="li">Whole files - Select when using the whole file data
                                                format.</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">File Prefix</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Prefix to use for output files. Use when writing to a
                                        directory that receives files from other sources.<p class="p">Uses the
                                            prefix sdc-${sdc:id()} by default. The prefix evaluates
                                            to sdc-&lt;<span class="ph">Data Collector</span> ID&gt;. </p>
<p class="p">The <span class="ph">Data Collector</span> ID is stored in the following file:
                                                <span class="ph filepath">$SDC_DATA/sdc.id</span>. <span class="ph">For more information about environment variables, see
                              <a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_rng_qym_qr">Data Collector Environment Configuration</a>.</span></p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">File Suffix</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Suffix to use for output files, such as txt or json. When
                                        used, the destination adds a period and the configured
                                        suffix as follows: &lt;filename&gt;.&lt;suffix&gt;.<p class="p">You can
                                            include periods within the suffix, but do not start the
                                            suffix with a period. Forward slashes are not
                                            allowed.</p>
<p class="p">Not available for the whole file data
                                            format. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Directory in Header <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_lmn_gdc_1w">
                                            <img class="image" id="task_m2m_skm_zq__d16e7977" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a>
                                    </td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Indicates that the target directory is defined in record
                                        headers. Use only when the targetDirectory header attribute
                                        is defined for all records. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Directory Template <a class="xref" href="HadoopFS-destination.html#concept_cvc_skd_br">
                                            <img class="image" id="task_m2m_skm_zq__d16e7990" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" id="task_m2m_skm_zq__d16e7992" headers="d101775e2089 ">Template for creating output
                                        directories. You can use constants, field values, and
                                        datetime variables. <p class="p">Output directories are created based
                                            on the smallest datetime variable in the
                                        template.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Data Time Zone</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Time zone for the destination system. Used to resolve
                                        datetimes in the directory template and evaluate where
                                        records are written.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Time Basis <a class="xref" href="HadoopFS-destination.html#concept_gkz_smd_br">
                                            <img class="image" id="task_m2m_skm_zq__d16e8013" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" id="task_m2m_skm_zq__d16e8015" headers="d101775e2089 ">Time basis to use for creating
                                        output directories and writing records to the directories.
                                        Use one of the following expressions:<ul class="ul" id="task_m2m_skm_zq__d16e8017">
                                            <li class="li">${time:now()} - Uses the processing time as the time
                                                basis. </li>

                                            <li class="li">${record:value(&lt;date field path&gt;)} - Uses the
                                                time associated with the record as the time
                                                basis.</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Max Records in a File</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Maximum number of records to be written to an output
                                        file. Additional records are written to a new file. <p class="p">Use 0
                                            to opt out of this property. </p>
<p class="p">Not available when
                                            using the whole file data format. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Max File Size (MB)</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Maximum size of an output file. Additional records are
                                        written to a new file. <p class="p">Use 0 to opt out of this property.
                                            </p>
<p class="p">Not available when using the whole file data
                                            format. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Idle Timeout (secs) <a class="xref" href="HadoopFS-destination.html#concept_qjs_dw3_tv">
                                            <img class="image" id="task_m2m_skm_zq__image_br5_fgs_7r" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a>
                                    </td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Maximum time that an output file
                                        can remain idle. After no records are written to a file for
                                        this amount of time, the destination closes the file. Enter
                                        a time in seconds or use the <code class="ph codeph">MINUTES</code> or
                                            <code class="ph codeph">HOURS</code> constant in an expression to
                                        define the time increment.<p class="p">Use -1 to set no limit. Default
                                            is 1 hour, defined as follows: <code class="ph codeph">${1 *
                                                HOURS}</code>. </p>
<p class="p">Not available when using the
                                            whole file data format. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Compression Codec</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Compression type for output files:<ul class="ul" id="task_m2m_skm_zq__d16e8061">
                                            <li class="li">None </li>

                                            <li class="li">gzip</li>

                                            <li class="li">bzip2</li>

                                            <li class="li">Snappy</li>

                                            <li class="li">LZ4</li>

                                            <li class="li">Other</li>

                                        </ul>
<div class="p">
                                            <div class="note note"><span class="notetitle">Note:</span> Do not use with Avro data. To compress Avro data,
                                                use the Avro Compression Codec property on the Data
                                                Formats tab.</div>

                                        </div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Compression Codec Class</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Full class name of the other compression codec that you
                                        want to use. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Sequence File Key</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Record key for creating sequence files. Use one of the
                                        following options:<ul class="ul" id="task_m2m_skm_zq__d16e8105">
                                            <li class="li">${record:value(&lt;field path&gt;)}</li>

                                            <li class="li">${uuid()}</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Compression Type</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Compression type for sequence files when using a
                                        compression codec:<ul class="ul" id="task_m2m_skm_zq__d16e8122">
                                            <li class="li">Block Compression</li>

                                            <li class="li">Record Compression</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Use Roll Attribute <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_lmn_gdc_1w">
                                            <img class="image" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a>
                                    </td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Checks the record header for the roll header attribute
                                        and closes the current file when the roll attribute exists.
                                            <p class="p">Can be used with Max Records in a File and Max File
                                            Size to close files.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Roll Attribute Name</td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Name of the roll header attribute.<p class="p">Default is
                                        roll.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Validate HDFS Permissions</td>

                                    <td class="entry cellrowborder" id="task_m2m_skm_zq__d16e8164" headers="d101775e2089 ">When you start the
                                        pipeline, the destination tries writing to the configured
                                        directory template to validate permissions. The pipeline
                                        does not start if validation fails.<div class="note note"><span class="notetitle">Note:</span> Do not use this
                                            option when the directory template uses expressions to
                                            represent the entire directory.</div>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2086 ">Skip File Recovery <a class="xref" href="HadoopFS-destination.html#concept_uv2_vfb_vy">
                                            <img class="image" id="task_m2m_skm_zq__image_br4_fgs_2r" src="../Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e2089 ">Determines whether the
                                        destination performs file recovery after an unexpected stop
                                        of the pipeline. </td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Late Records</span> tab, configure the following
                    properties:</span>
                <div class="itemgroup info">
                    <div class="note tip"><span class="tiptitle">Tip:</span> These properties are relevant for a time basis based on the
                        time of a record. If you use processing time as the time basis, set the late
                        record time limit to one second.</div>

                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e9056" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e2431">Late Records Property <a class="xref" href="HadoopFS-destination.html#concept_xgm_g4d_br">
                                            <img class="image" id="task_m2m_skm_zq__d16e9072" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" />
                                        </a>
                                    </th>

                                    <th class="entry cellrowborder" id="d101775e2440">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2431 ">Late Record Time Limit (secs)</td>

                                    <td class="entry cellrowborder" headers="d101775e2440 ">Time limit for output directories to accept data. <p class="p">You
                                            can enter a time in seconds, or use the expression to
                                            enter a time in hours. You can also use MINUTES in the
                                            default expression to define the time in minutes.
                                        </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2431 ">Late Record Handling</td>

                                    <td class="entry cellrowborder" headers="d101775e2440 ">Determines how to handle late records:<ul class="ul" id="task_m2m_skm_zq__d16e9101">
                                            <li class="li">Send to error - Sends the record to the stage for
                                                error handling. </li>

                                            <li class="li">Send to late records file - Sends the record to a
                                                late records file.</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2431 ">Late Record Directory Template <a class="xref" href="HadoopFS-destination.html#concept_cvc_skd_br">
                                            <img class="image" id="task_m2m_skm_zq__d16e9117" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e2440 ">Template for creating late record directories. You can
                                        use constants, field values, and datetime variables.
                                            <p class="p">Output directories are created based on the smallest
                                            datetime variable in the template.</p>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="keyword wintitle">Data Format</span> tab, configure the following
                    property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__table_hvy_pt3_vx" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e2518">Data Format Property</th>

                                    <th class="entry cellrowborder" id="d101775e2521">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2518 ">Data Format <a class="xref" href="HadoopFS-destination.html#concept_lww_3b3_kr">
                                            <img class="image" id="task_m2m_skm_zq__image_ohs_4fj_vx" src="../Graphics/icon_moreInfo.png" height="12" width="12" />
                                        </a></td>

                                    <td class="entry cellrowborder" headers="d101775e2521 ">Format of data to be written.
                                        Use one of the following options:<ul class="ul" id="task_m2m_skm_zq__d16e7900">
                                            <li class="li">Avro</li>

                                            <li class="li">Binary</li>

                                            <li class="li">Delimited</li>

                                            <li class="li">JSON</li>

                                            <li class="li">Protobuf</li>

                                            <li class="li">SDC Record <a class="xref" href="../Pipeline_Design/SDCRecordFormat.html#concept_qkk_mwk_br" title="SDC Record is a proprietary data format that Data Collector uses to generate error records. Data Collector can also use the data format to read and write data.">
                                                  <img class="image" id="task_m2m_skm_zq__d16e7922" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="14" width="14" /></a>
                                            </li>

                                            <li class="li">Text</li>

                                            <li class="li">Whole File <a class="xref" href="../Data_Formats/WholeFile.html#concept_nfc_qkh_xw" title="You can use the whole file data format to transfer entire files from an origin system to a destination system. With the whole file data format, you can transfer any type of file.">
                                                  <img class="image" id="task_m2m_skm_zq__d16e7932" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></li>

                                        </ul>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For Avro data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e6581" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e2617">Avro Property</th>

                                    <th class="entry cellrowborder" id="d101775e2620">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Avro Schema Location</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">Location of the Avro schema definition to use when
                                        writing data:<ul class="ul" id="task_m2m_skm_zq__d16e6610">
                                            <li class="li">In Pipeline Configuration - Use the schema that you
                                                provide in the stage configuration. </li>

                                            <li class="li">In Record Header - Use the schema in the avroSchema
                                                record header attribute. Use only when the
                                                avroSchema attribute is defined for all records.
                                                  <a class="xref" href="../Pipeline_Design/RecordHeaderAttributes.html#concept_lmn_gdc_1w">
                                                  <img class="image" id="task_m2m_skm_zq__d16e6619" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></li>

                                            <li class="li">Confluent Schema Registry - Retrieve the schema from
                                                the Confluent Schema Registry. </li>

                                        </ul>
<p class="p">The destination includes the schema definition in
                                            each generated file. </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Avro Schema</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">Avro schema definition used to write the data. <p class="p">You can
                                            optionally use the runtime:loadResource function to use
                                            a schema definition stored in a runtime resource file.
                                        </p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Register Schema</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">Select to register a new Avro schema with the Confluent
                                        Schema Registry.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Schema Registry URLs</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">Confluent Schema Registry URLs used to look up the schema
                                        or to register a new schema. To add a URL, click
                                            <span class="ph uicontrol">Add</span>. Use the following format to
                                        enter the
                                        URL:<pre class="pre codeblock"><code>http://&lt;host name&gt;:&lt;port number&gt;</code></pre></td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Look Up Schema By</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">Method used to look up the schema in the Confluent Schema
                                            Registry:<ul class="ul" id="task_m2m_skm_zq__d16e6669">
                                            <li class="li">Subject - Look up the specified Avro schema
                                                subject.</li>

                                            <li class="li">Schema ID - Look up the specified Avro schema ID.
                                            </li>

                                        </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Schema Subject</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">Avro schema subject to look up or to register in the
                                        Confluent Schema Registry.<p class="p">If the specified subject to
                                            look up has multiple schema versions, the origin uses
                                            the latest schema version for that subject. To use an
                                            older version, find the corresponding schema ID, and
                                            then set the <span class="ph uicontrol">Look Up Schema By</span>
                                            property to Schema ID.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Schema ID</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">Avro schema ID to look up in the Confluent Schema
                                        Registry.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2617 ">Avro Compression Codec</td>

                                    <td class="entry cellrowborder" headers="d101775e2620 ">The Avro compression type to use. <p class="p">When using Avro
                                            compression, do not enable other compression available
                                            in the destination. </p>
</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For binary data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e7077" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e2766">Binary Property</th>

                                    <th class="entry cellrowborder" id="d101775e2769">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2766 ">Binary Field Path</td>

                                    <td class="entry cellrowborder" headers="d101775e2769 ">Field that contains the binary data.</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For delimited data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e7134" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e2812">Delimited Property</th>

                                    <th class="entry cellrowborder" id="d101775e2815">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2812 ">Delimiter Format</td>

                                    <td class="entry cellrowborder" headers="d101775e2815 ">Format for delimited data:<ul class="ul" id="task_m2m_skm_zq__ul_k3j_vvf_jr">
                        <li class="li"><span class="ph uicontrol">Default CSV</span> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>

                        <li class="li"><span class="ph uicontrol">RFC4180 CSV</span> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>

                        <li class="li"><span class="ph uicontrol">MS Excel CSV</span> - Microsoft Excel comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">MySQL CSV</span> - MySQL comma-separated file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL CSV</span> - PostgreSQL comma-separated
                              file.</li>

                        <li class="li"><span class="ph uicontrol">PostgreSQL Text</span> - PostgreSQL text file.</li>

                        <li class="li"><span class="ph uicontrol">Tab-Separated Values</span> - File that includes
                              tab-separated values.</li>

                        <li class="li"><span class="ph uicontrol">Custom</span> - File that uses user-defined delimiter,
                              escape, and quote characters.</li>

                  </ul>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2812 ">Header Line</td>

                                    <td class="entry cellrowborder" headers="d101775e2815 ">Indicates whether to create a header line.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2812 ">Replace New Line Characters</td>

                                    <td class="entry cellrowborder" headers="d101775e2815 ">Replaces new line characters with the configured
                                            string.<p class="p">Recommended when writing data as a single line
                                            of text.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2812 ">New Line Character Replacement</td>

                                    <td class="entry cellrowborder" headers="d101775e2815 ">String to replace each new line character. For example,
                                        enter a space to replace each new line character with a
                                        space. <p class="p">Leave empty to remove the new line
                                        characters.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2812 ">Delimiter Character</td>

                                    <td class="entry cellrowborder" headers="d101775e2815 ">Delimiter character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                        character. <p class="p">You can enter a Unicode control character
                                            using the format \u<em class="ph i">NNNN</em>, where ​<em class="ph i">N</em> is a
                                            hexadecimal digit from the numbers 0-9 or the letters
                                            A-F. For example, enter \u0000 to use the null character
                                            as the delimiter or \u2028 to use a line separator as
                                            the delimiter.</p>
<p class="p">Default is the pipe character ( |
                                            ).</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2812 ">Escape Character </td>

                                    <td class="entry cellrowborder" headers="d101775e2815 ">Escape character for a custom delimiter format. Select
                                        one of the available options or use Other to enter a custom
                                        character. <p class="p">Default is the backslash character ( \
                                        ).</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2812 ">Quote Character</td>

                                    <td class="entry cellrowborder" headers="d101775e2815 ">Quote character for a custom delimiter format. Select one
                                        of the available options or use Other to enter a custom
                                        character. <p class="p">Default is the quotation mark character ( "
                                            ).</p>
</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d101775e2812 ">Charset</td>

       <td class="entry cellrowborder" headers="d101775e2815 ">Character set to use when writing data. </td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For JSON data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following property:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e7273" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e2983">JSON Property</th>

                                    <th class="entry cellrowborder" id="d101775e2986">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e2983 ">JSON Content</td>

                                    <td class="entry cellrowborder" headers="d101775e2986 ">Determines how JSON data is written:<ul class="ul" id="task_m2m_skm_zq__d16e7302">
                                            <li class="li">JSON Array of Objects - Each file includes a single
                                                array. In the array, each element is a JSON
                                                representation of each record.</li>

                                            <li class="li">Multiple JSON Objects - Each file includes multiple
                                                JSON objects. Each object is a JSON representation
                                                of a record.</li>

                                        </ul>
</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d101775e2983 ">Charset</td>

       <td class="entry cellrowborder" headers="d101775e2986 ">Character set to use when writing data. </td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For protobuf data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e7346" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e3046">Protobuf Property</th>

                                    <th class="entry cellrowborder" id="d101775e3049">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e3046 ">Protobuf Descriptor File </td>

                                    <td class="entry cellrowborder" headers="d101775e3049 ">Descriptor file (.desc) to use. The descriptor file must
                                        be in the <span class="ph">Data Collector</span> resources directory, <code class="ph codeph">$SDC_RESOURCES</code>.
                                                <p class="p"><span class="ph">For more information about environment variables, see
                              <a class="xref" href="../Configuration/DCEnvironmentConfig.html#concept_rng_qym_qr">Data Collector Environment Configuration</a>.</span> For information about generating the descriptor file,
                                            see <a class="xref" href="../Data_Formats/Protobuf-Prerequisites.html" title="Perform the following prerequisites before reading or writing protobuf data.">Protobuf Data Format Prerequisites</a>.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e3046 ">Message Type</td>

                                    <td class="entry cellrowborder" headers="d101775e3049 ">The fully-qualified name for the message type to use when
                                        writing data.<p class="p">Use the following format:
                                                <code class="ph codeph">&lt;package name&gt;.&lt;message
                                            type&gt;</code>. </p>
Use a message type defined in the
                                        descriptor file.</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For text data, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e7519" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e3129">Text Property</th>

                                    <th class="entry cellrowborder" id="d101775e3132">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e3129 ">Text Field Path</td>

                                    <td class="entry cellrowborder" headers="d101775e3132 ">Field that contains the text data to be written. All data
                                        must be incorporated into the specified field. </td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e3129 ">Record Separator</td>

                                    <td class="entry cellrowborder" headers="d101775e3132 ">Characters to use to separate records. Use any valid Java
                                        string literal. For example, when writing to Windows, you
                                        might use \r\n to separate records. <p class="p">By default, the
                                            destination uses \n.</p>
</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e3129 ">On Missing Field</td>

                                    <td class="entry cellrowborder" headers="d101775e3132 ">When a record does not include the text field, determines
                                        whether the destination reports the missing field as an
                                        error or ignores the missing field.</td>

                                </tr>

                                <tr>
                                    <td class="entry cellrowborder" headers="d101775e3129 ">Insert Record Separator if No Text</td>

                                    <td class="entry cellrowborder" headers="d101775e3132 ">When configured to ignore a missing text field, inserts
                                        the configured record separator string to create an empty
                                            line.<p class="p">When not selected, discards records without the
                                            text field.</p>
</td>

                                </tr>

                                <tr>
       <td class="entry cellrowborder" headers="d101775e3129 ">Charset</td>

       <td class="entry cellrowborder" headers="d101775e3132 ">Character set to use when writing data. </td>

      </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">For whole files, on the <span class="keyword wintitle">Data Format</span> tab, configure the
                    following properties:</span>
                <div class="itemgroup info">
                    
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_m2m_skm_zq__d16e7615" class="table" frame="border" border="1" rules="all"><colgroup><col style="width:30%" /><col style="width:70%" /></colgroup><thead class="thead" style="text-align:left;">
                                <tr>
                                    <th class="entry cellrowborder" id="d101775e3215">Whole File Property</th>

                                    <th class="entry cellrowborder" id="d101775e3218">Description</th>

                                </tr>

                            </thead>
<tbody class="tbody">
                                <tr id="task_m2m_skm_zq__d16e7637">
                                    <td class="entry cellrowborder" headers="d101775e3215 ">File Name Expression</td>

                                    <td class="entry cellrowborder" headers="d101775e3218 ">
                                        <p class="p">Expression to use for the file names. </p>

                                        <p class="p">For tips on how to name files based on input file names,
                                            see <a class="xref" href="../Data_Formats/WholeFile.html#concept_a2s_4jw_1x">Writing Whole Files</a>.</p>

                                    </td>

                                </tr>

                                <tr id="task_m2m_skm_zq__d16e7654">
                                    <td class="entry cellrowborder" headers="d101775e3215 ">Permissions Expression <a class="xref" href="../Data_Formats/WholeFile.html#concept_ttm_ywv_1x">
                                            <img class="image" id="task_m2m_skm_zq__d16e7660" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e3218 ">Expression that defines the access permissions for output
                                        files. Expressions should evaluate to a symbolic or
                                        numeric/octal representation of the permissions you want to
                                        use. <p class="p">By default, with no specified expression, files use
                                            the default permissions of the destination system.
                                            </p>
<div class="p">To use the original source file access
                                            permissions, use the following expression:
                                            <pre class="pre codeblock"><code>${record:value('/fileInfo/permissions')}</code></pre></div>
</td>

                                </tr>

                                <tr id="task_m2m_skm_zq__d16e7672">
                                    <td class="entry cellrowborder" headers="d101775e3215 ">File Exists</td>

                                    <td class="entry cellrowborder" headers="d101775e3218 ">Action to take when a file of the same name already
                                        exists in the output directory. Use one of the following
                                            options:<ul class="ul" id="task_m2m_skm_zq__d16e7679">
                                            <li class="li">Send to Error - Handles the record based on stage
                                                error record handling. </li>

                                            <li class="li">Overwrite - Overwrites the existing file.</li>

                                        </ul>
</td>

                                </tr>

                                <tr id="task_m2m_skm_zq__d16e7689">
                                    <td class="entry cellrowborder" headers="d101775e3215 ">Include Checksum in Events <a class="xref" href="../Data_Formats/WholeFile.html#concept_ojv_sr4_vx">
                                            <img class="image" id="task_m2m_skm_zq__d16e7695" src="../../../reusable-content/datacollector/../../datacollector/UserGuide/Graphics/icon_moreInfo.png" height="12" width="12" /></a></td>

                                    <td class="entry cellrowborder" headers="d101775e3218 ">Includes checksum information in whole file event
                                        records. <p class="p">Use only when the destination generates event
                                            records. </p>
</td>

                                </tr>

                                <tr id="task_m2m_skm_zq__d16e7703">
                                    <td class="entry cellrowborder" headers="d101775e3215 ">Checksum Algorithm</td>

                                    <td class="entry cellrowborder" headers="d101775e3218 ">Algorithm to generate the checksum.</td>

                                </tr>

                            </tbody>
</table>
</div>

                </div>
            </li>
</ol>

    </div>

</article>
</article>
</article></main></div>
                        
                        <div class=" wh_related_links "><nav role="navigation" class="related-links">
<div class="linklist linklist relinfo relconcepts"><strong>Related concepts</strong><br />

<div class="related_link"><a class="navheader_parent_path" href="../Hive_Drift_Solution/HiveDriftSolution_title.html#concept_phk_bdf_2w" title="Drift Synchronization Solution for Hive">Drift Synchronization Solution for Hive</a></div></div>
</nav></div>
                        
                    </div>
                    
                </div>
            </div>
        </div> <nav class="navbar navbar-default wh_footer">
  <div class=" footer-container text-center ">
    <!-- Copyright 2018 StreamSets Inc. --><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script>
  </div>
</nav>

        
        <div id="go2top">
            <span class="glyphicon glyphicon-chevron-up"></span>
        </div>
        
        <!-- The modal container for images -->
        <div id="modal_img_large" class="modal">
            <span class="close glyphicon glyphicon-remove"></span>
            <!-- Modal Content (The Image) -->
            <img class="modal-content" id="modal-img" />
            <!-- Modal Caption (Image Text) -->
            <div id="caption"></div>
        </div>
        
        <script src="../../../oxygen-webhelp/lib/bootstrap/js/bootstrap.min.js" type="text/javascript"></script>
        © Apache License, Version 2.0.
    </body>
</html>