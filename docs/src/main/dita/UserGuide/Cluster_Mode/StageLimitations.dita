<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_pdf_r5y_fz">
 <title>Stage Limitations</title>
 <conbody>
  <p><indexterm>cluster mode<indexterm>unsupported stages</indexterm></indexterm>Please note the
            following stage limitations in cluster pipelines:<draft-comment author="alisontaylor"
                >for any updates to supported or non-supported stages, also update the list of
                Origins, Processors, Destinations in the overview of each of those
                chapters</draft-comment><ul id="ul_rrk_s5y_fz">
                <li>Non-cluster origins - Do not use non-cluster origins in cluster pipelines. For a
                    description of the origins to use, see <xref
                        href="ClusterPipelines-ExecutionMode.dita#concept_rjc_4m5_lx"/>.</li>
                <li>Record Deduplicator processor - This processor is not supported in cluster
                    pipelines at this time. </li>
                <li>RabbitMQ Producer destination - This destination is not supported in cluster
                    pipelines at this time. </li>
                <li>Scripting processors - The state object is available only for the instance of
                    the processor stage it is defined in. If the pipeline executes in cluster mode,
                    the state object is not shared across nodes. </li>
                <li>Spark Evaluator processor - Use in cluster streaming pipelines only. Do not use
                    in cluster batch pipelines. You can also use the Spark Evaluator in standalone
                    pipelines. </li>
                <li>Spark Evaluator processor and Spark executor - When using Spark stages, the
                    stages must use the same Spark version as the cluster. For example, if the
                    cluster uses Spark 2.1, the Spark Evaluator must use a Spark 2.1 stage library.
                        <p>Both stages are <ph
                            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/Spark-xrefs"
                        /></p></li>
            </ul></p>
 </conbody>
</concept>
