<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_ulm_qdq_fs">
 <title>Log Parser</title>
 <conbody>
  <p><indexterm>Log Parser
                    processor<indexterm>overview</indexterm></indexterm><indexterm>processors<indexterm>Log
                    Parser</indexterm></indexterm>The Log Parser processor parses log data in a
            field based on the specified log format. Use the Log Parser to process log data within
            the pipeline. To read log data directly from an origin system, you can use an origin
            that processes the log data format, such as File Tail or Kafka Consumer.</p>
        <p>When you configure Log Parser, you define the field that contains the log line and the
            field to contain the parsed fields. </p>
    <p>If the record contains fields in addition to the field to be parsed, those fields are passed
      through by default. Parsed fields are written to the specified location, overwriting any
      existing data. </p>
 </conbody>
</concept>
