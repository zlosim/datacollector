<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_pl5_tmq_tx">
 <title>Google Bigtable</title>
 <conbody>
  <p><indexterm>Google Bigtable
                    destination<indexterm>overview</indexterm></indexterm><indexterm>destinations<indexterm>Google
                    Bigtable</indexterm></indexterm>The Google Bigtable destination writes data to
            Google Cloud Bigtable. You can use other destinations to write to <xref
                href="BigQuery.dita#concept_hj4_brk_dbb">Google BigQuery</xref>, <xref
                href="GCS.dita#concept_p4n_jrl_nbb">Google Cloud Storage</xref>, and <xref
                href="PubSubPublisher.dita#concept_qsj_hk1_v1b">Google Pub/Sub</xref>.</p>
        <p>Before you configure the destination, you must complete several prerequisites including
            installing the BoringSSL library and configuring the Google Application Default
            Credentials.</p>
        <p>When you configure the destination, you define the instance ID, project ID, and the table
            that you want to write to. The destination can write to an existing table or can create
            and write to a new table. You specify the row key for the table, and then map fields
            from the pipeline to Cloud Bigtable columns.</p>
        <p>When necessary, you can configure a time basis and specify the number of records to
            buffer in each commit to Cloud Bigtable.</p>
 </conbody>
</concept>
