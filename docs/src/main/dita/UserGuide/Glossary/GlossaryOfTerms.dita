<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_h2c_pfh_tq">
 <title>Glossary of Terms</title>
 <conbody>
  <dl>
      <dlentry>
        <dt>batch</dt>
        <dd><indexterm>glossary<indexterm>Data Collector terms</indexterm></indexterm>A set of
          records that passes through a pipeline. <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
          processes data in batches.</dd>
      </dlentry>
      <dlentry>
        <dt>CDC-enabled origin</dt>
        <dd>An origin that can process changed data and place CRUD operation information in the
          sdc.operation.type record header attribute. </dd>
      </dlentry>
      <dlentry>
        <dt>cluster execution mode</dt>
        <dd>Pipeline execution mode that allows you to process large volumes of data from Kafka or
          HDFS.</dd>
      </dlentry>
      <dlentry>
        <dt>cluster pipeline, cluster mode pipeline</dt>
        <dd>A pipeline configured to run in cluster execution mode. </dd>
      </dlentry>
      <dlentry>
        <dt>control character</dt>
        <dd>A non-printing character in a character set, such as the acknowledgement or escape
          characters.</dd>
      </dlentry>
      <dlentry>
        <dt>CRUD-enabled stage</dt>
        <dd>A processor or destination that can use the CRUD operation written in the
          sdc.operation.type header attribute to write changed data. </dd>
      </dlentry>
      <dlentry>
        <dt>data alerts</dt>
        <dd>Alerts based on rules that gather information about the data that passes between two
          stages.</dd>
      </dlentry>
      <dlentry>
        <dt><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
          configuration file (sdc.properties)</dt>
        <dd>Configuration file with most <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
          properties. Found in the following location:
          <codeblock>$SDC_CONF/sdc.properties</codeblock></dd>
      </dlentry>
      <dlentry>
        <dt><ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/Edge-Long"/>
            (<ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/Edge-Short"
          />)</dt>
        <dd>
          <p>A lightweight agent without a UI that runs pipelines in edge execution mode on edge
            devices. </p>
        </dd>
      </dlentry>
      <dlentry>
        <dt>data drift alerts</dt>
        <dd>Alerts based on data drift functions that gather information about the structure of data
          that passes between two stages.</dd>
      </dlentry>
      <dlentry>
        <dt>data preview</dt>
        <dd>Preview of data as it moves through a pipeline. Use to develop and test pipelines.</dd>
      </dlentry>
      <dlentry>
        <dt>dataflow triggers</dt>
        <dd>Instructions for the pipeline to kick off asynchronous tasks in external systems in
          response to events that occur in the pipeline. For more information, see <xref
            href="../Event_Handling/EventFramework-Overview.dita#concept_cph_5h4_lx"/>.</dd>
      </dlentry>
      <dlentry>
        <dt>delivery guarantee</dt>
        <dd>Pipeline property that determines how the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
          handles data when the pipeline stops unexpectedly.</dd>
      </dlentry>
      <dlentry>
        <dt>destination</dt>
        <dd>A stage type used in a pipeline to represent where the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> writes
          processed data.</dd>
      </dlentry>
      <dlentry>
        <dt>development stages, dev stages</dt>
        <dd>Stages such as the Dev Data Generator origin and the Dev Random Error processor that
          enable pipeline development and testing. Not meant for use in production pipelines.</dd>
      </dlentry>
      <dlentry>
        <dt>edge pipeline, edge mode pipeline</dt>
        <dd>A pipeline that runs in edge execution mode on a <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/Edge-Long"/> (<ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/Edge-Short"/>)
          installed on an edge device. Use edge pipelines to read data from the edge device or to
          receive data from another pipeline and then act on that data to control the edge
          device.</dd>
      </dlentry>
      <dlentry>
        <dt>event framework</dt>
        <dd>
          <p>The event framework enables the pipeline to trigger tasks in external systems based on
            actions that occur in the pipeline, such as running a MapReduce job after the pipeline
            writes a file to HDFS. You can also use the event framework to store event information,
            such as when an origin starts or completes reading a file. </p>
        </dd>
      </dlentry>
      <dlentry>
        <dt>event record</dt>
        <dd>A record created by an event-generating stage when a stage-related event occurs, like
          when an origin starts reading a new file or a destination closes an output file. </dd>
      </dlentry>
      <dlentry>
        <dt>executor</dt>
        <dd>A stage type used to perform tasks in external systems upon receiving an event
          record.</dd>
      </dlentry>
      <dlentry>
        <dt>explicit validation</dt>
        <dd>A semantic validation that checks all configured values for validity and verifies
          whether the pipeline can run as configured. Occurs when you click the Validate icon,
          request data preview, or start the pipeline.</dd>
      </dlentry>
      <dlentry>
        <dt>field path</dt>
        <dd>The path to a field in a record. Use to reference a field.</dd>
      </dlentry>
      <dlentry>
        <dt>implicit validation</dt>
        <dd>Lists missing or incomplete configuration. Occurs by default as <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> saves
          your changes in the pipeline canvas.</dd>
      </dlentry>
      <dlentry>
        <dt>late directories</dt>
        <dd>Origin directories that appear after a pipeline starts.</dd>
      </dlentry>
      <dlentry>
        <dt>metric alerts</dt>
        <dd><ph product="SDC">Monitoring or email</ph><ph product="SDC">Email</ph> alerts based on
          stage or pipeline metrics. </dd>
      </dlentry>
      <dlentry>
        <dt>multithreaded pipelines</dt>
        <dd>A pipeline with an origin that generates multiple threads, enabling the processing of
          high volumes of data in a single pipeline on one Data Collector.</dd>
      </dlentry>
      <dlentry>
        <dt>origin</dt>
        <dd>A stage type used in a pipeline to represent the source of data in a pipeline.</dd>
      </dlentry>
      <dlentry>
        <dt>pipeline</dt>
        <dd>A representation of a stream of data that is processed by the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>.</dd>
      </dlentry>
      <dlentry>
        <dt>pipeline runner</dt>
        <dd>Used in multithreaded pipelines to run a sourceless instance of a pipeline. </dd>
      </dlentry>
      <dlentry>
        <dt>preconditions</dt>
        <dd>Conditions that a record must satisfy to enter the stage for processing. Records that
          don't meet all preconditions are processed based on stage error handling.</dd>
      </dlentry>
      <dlentry>
        <dt>processors</dt>
        <dd>A stage type that performs specific processing on pipeline data.</dd>
      </dlentry>
      <dlentry>
        <dt>required fields</dt>
        <dd>A required field is a field that must exist in a record to allow it into the stage for
          processing. Records that don't have all required fields are processed based on pipeline
          error handling.</dd>
      </dlentry>
      <dlentry>
        <dt>RPC ID</dt>
        <dd>A user-defined identifier configured in the SDC RPC origin and destination to allow the
          destination to write to the origin.</dd>
      </dlentry>
      <dlentry>
        <dt>runtime parameters</dt>
        <dd>Parameters that you define for the pipeline and call from within that same pipeline. Use
          to specify values for pipeline properties when you start the pipeline.</dd>
      </dlentry>
      <dlentry>
        <dt>runtime properties</dt>
        <dd>Properties that you define in a file local to the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> and
          call from within a pipeline. Use to define different sets of values for different <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
          instances.</dd>
      </dlentry>
      <dlentry>
        <dt>runtime resources</dt>
        <dd>Values that you define in a restricted file local to the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> and
          call from within a pipeline. Use to load sensitive information from files at runtime.</dd>
      </dlentry>
      <dlentry>
        <dt>SDC Record data format</dt>
        <dd>A data format used for <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> error
          records and an optional format to use for output records. </dd>
      </dlentry>
      <dlentry>
        <dt>SDC RPC pipelines</dt>
        <dd>A set of pipelines that use the SDC RPC destination and SDC RPC origin to pass data from
          one pipeline to another without writing to an intermediary system. </dd>
      </dlentry>
      <dlentry>
        <dt>sourceless pipeline instance</dt>
        <dd>An instance of the pipeline that includes all of the processors and destinations in the
          pipeline and represents all pipeline processing after the origin. Used in multithreaded
          pipelines.</dd>
      </dlentry>
      <dlentry product="SDC">
        <dt>snapshot</dt>
        <dd>A set of data captured as a pipeline runs. You can step through the snapshot like data
          preview. You can also use it as a source for data preview.</dd>
      </dlentry>
      <dlentry>
        <dt>standalone pipeline, standalone mode pipeline</dt>
        <dd>A pipeline configured to run in the default standalone execution mode.</dd>
      </dlentry>
    </dl>
 </conbody>
</concept>
