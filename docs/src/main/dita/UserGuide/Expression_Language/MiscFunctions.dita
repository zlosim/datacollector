<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_ddw_ld1_1s">
 <title>Miscellaneous Functions</title>
 <conbody>
  <p><indexterm>functions<indexterm>miscellaneous
        functions</indexterm></indexterm><indexterm>miscellaneous
          functions<indexterm>description</indexterm></indexterm>In miscellaneous functions, you can
      replace any argument with a literal or an expression that evaluates to the argument. String
      literals must be enclosed in single or double quotation marks.</p>
    <p>The expression language provides the following miscellaneous functions:</p>
  <dl>
      <dlentry>
        <dt>alert:info()</dt>
        <dd>Returns information about the trigger for a data drift alert. Use only in alert text for
          data drift alerts. </dd>
      </dlentry>
   <dlentry>
    <dt>emptyList()</dt>
    <dd>Creates an empty list.</dd>
   </dlentry>
   <dlentry>
    <dt>emptyMap()</dt>
    <dd>Creates an empty map. </dd>
   </dlentry>
      <dlentry>
        <dt>every(&lt;interval>, &lt; hh() | mm() | ss() >)</dt>
        <dd>Represents the interval of hours, minutes, or seconds for generating output directories
          for the Hadoop FS, Local FS, or MapR FS destination. </dd>
        <dd>When used, a destination generates output directories for the specified interval
          beginning on the hour. For example, when generating directories every 30 minutes, it
          generates a directory on the hour and on the half-hour.</dd>
        <dd>You can use the function once in the Directory Template property to replace the hour,
          minute, or second datetime variables. </dd>
        <dd>Use the function to replace the smallest time interval in the directory template. </dd>
        <dd>
          <note>Destinations generate a directory for the smallest unit of measure by default, so do
            not use the <codeph>every</codeph> function to generate a directory every hour, minute,
            or second. For more information, see <xref
              href="../Destinations/HadoopFS-DirectoryTemplates.dita#concept_cvc_skd_br"/>.</note>
        </dd>
        <dd>Uses the following arguments:<ul id="ul_p1j_vdr_ns">
            <li>interval - An integer factor or submultiple of 60 that represents the interval of
              minutes or seconds to wait between directory generation. Use one of the following
              values: 1, 2, 3, 4, 5, 6, 10, 12, 15, 20, or 30.</li>
            <li>&lt; hh() | mm() | ss() > - Use <codeph>hh()</codeph> for hours,
                <codeph>mm()</codeph> for minutes, and <codeph>ss()</codeph> for seconds. </li>
          </ul></dd>
        <dd>For example, the following Directory Template generates a new directory every twelve
          hours, beginning on the
          hour:<codeblock>/outputfiles/${YY()}-${MM()}-${DD()}-${every(12,hh())}</codeblock></dd>
        <dd>The following Directory Template generates a new directory every fifteen minutes,
          beginning on the
          hour:<codeblock>/outputfiles/${YY()}-${MM()}-${DD()}-${hh()}-${every(15,mm())}</codeblock></dd>
        <dd>The following Directory Template generates a new directory every 30 seconds, beginning
          on the
          hour:<codeblock>/outputfiles/${YY()}-${MM()}-${DD()}-${hh()}-${mm()}-${every(30,ss())}</codeblock></dd>
      </dlentry>
      <dlentry>
        <dt>field:field()</dt>
        <dd>Returns the field name. Available only in the Decimal field expression properties of the
          Hive Metadata processor. </dd>
        <dd>Return type: String.</dd>
      </dlentry>
      <dlentry>
        <dt>jvm:maxMemoryMB()</dt>
        <dd>Returns the Java heap size allocated to the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> in MB.
          You can use this function in an expression to specify the maximum amount of memory a
          pipeline can use. </dd>
        <dd>For example, since 65% of the Java heap size is the recommended maximum, the following
          expression is the default memory limit for a pipeline:
          <codeblock>${jvm:maxMemoryMB() * 0.65}</codeblock></dd>
      </dlentry>
      <dlentry>
        <dt>list:join(&lt;list field>, &lt;separator>)</dt>
        <dd>Merges elements in a List field into a String field, using the specified separator
          between elements. </dd>
        <dd>Uses the following arguments:<ul id="ul_srh_pzn_z1b">
            <li>list field - The List field that you want to merge. </li>
            <li>separator - The string to use to separate the elements in the merged field.</li>
          </ul></dd>
        <dd>For example, to merge the list in a colors field using a semicolon as a separator
          character, you can use the following
          expression:<codeblock>${list:join(record:value('/colors'), ";")}</codeblock></dd>
        <dd>And if the list field includes "red", "blue", and "yellow" as elements, the expression
          produces the following string data: <codeblock>red;blue;yellow</codeblock></dd>
        <dd>Return type: String.</dd>
      </dlentry>
      <dlentry>
        <dt>list:joinSkipNulls(&lt;list field>, &lt;separator>)</dt>
        <dd>Merges elements in a List field into a String field, using the specified separator
          between elements and skipping null values.</dd>
        <dd>Uses the following arguments:<ul id="ul_or1_wzn_z1b">
            <li>list field - The List field that you want to merge. </li>
            <li>separator - The string to use to separate the elements in the merged field.</li>
          </ul></dd>
        <dd>For example, say you use the following expression to merge the list in the colors
          field:<codeblock>${list:join(record:value('/colors'), ";")}</codeblock></dd>
        <dd>And if the list field includes "red", "blue, null, "yellow", the expression ignores the
          null value and produces the following string
          data:<codeblock>red;blue;yellow</codeblock></dd>
        <dd>Return type: String.</dd>
      </dlentry>
      <dlentry>
        <dt>offset:column(&lt;position>)</dt>
        <dd>Returns the value of the positioned offset column for the current table. Available only
          in the additional offset column conditions of the JDBC Multitable Consumer origin. </dd>
        <dd>Uses the following argument:<ul id="ul_zfx_jjr_qy">
            <li>position - Position of the offset column. For example, enter 0 for the first offset
              column defined in the table configuration. Enter 1 for the second defined offset
              column.</li>
          </ul></dd>
        <dd>Return type: String.</dd>
      </dlentry>
      <dlentry>
        <dt>runtime:availableProcessors()</dt>
        <dd>
          <p>Returns the number of processors available to the Java virtual machine. You can use
            this function when you want to configure multithreaded processing based on the number of
            processors available to <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>.</p>
          <p>Return type: Integer.</p>
        </dd>
      </dlentry>
   <dlentry>
    <dt>runtime:conf(&lt;runtime property>)</dt>
    <dd>Returns the value for the specified runtime configuration. Use to call a runtime property. </dd>
    <dd>Uses the following argument:<ul id="ul_vqc_2h1_1s">
      <li>runtime configuration name - Name of the configuration property to use. The property must
       defined in the sdc.properties file or in a runtime configuration file specified in the
       sdc.properties file. </li>
     </ul></dd>
        <dd>For more information, see <xref
            href="../Pipeline_Configuration/RuntimeProperties.dita#concept_fjx_g31_1s"/>.</dd>
   </dlentry>
      <dlentry>
        <dt>runtime:loadResource(&lt;file name>, &lt;restricted: true | false>)</dt>
        <dd>Returns the value in the specified file. Use to call a runtime resource.</dd>
        <dd>When you call a runtime resource, the Data Collector replaces the expression with the
          entire contents of the file. Avoid including unnecessary characters such as spaces or
          carriage returns. Many text editors add additional characters by default. </dd>
        <dd>Uses the following arguments:<ul id="ul_ytn_xmm_2s">
            <li>file name - Name of the file that contains the information to be loaded. The file
              must reside in the <codeph>$SDC_RESOURCES</codeph> directory: </li>
            <li>restricted - Whether the file has restricted permissions. If set to true, the file
              must be owned by the system user who runs the <ph
                conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
              and read and writable only by the owner.</li>
          </ul></dd>
        <dd>
          <note type="tip">To strip any leading or trailing white space characters from the file,
            add the <codeph>str:trim</codeph> function as
            follows:<codeblock>${str:trim(runtime:loadResource(&lt;file name>, &lt;restricted: true | false>)}</codeblock></note>
        </dd>
        <dd>For example, the following expression returns the contents of the restricted
          JDBCpassword.txt file, stripping any leading or trailing white space
          characters:<codeblock>${str:trim(runtime:loadResource("JDBCpassword.txt", true))}</codeblock></dd>
        <dd>For more information about runtime resources, see <xref
            href="../Pipeline_Configuration/RuntimeResources.dita#concept_bs4_5nm_2s"/>.</dd>
      </dlentry>
      <dlentry>
        <dt>sdc:hostname()</dt>
        <dd>Returns the host name of the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
          machine. </dd>
        <dd>For example, you might use the function in the directory template for the Hadoop FS
          destination to write to a directory that includes the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> host
          name.</dd>
        <dd>Return type: String.</dd>
      </dlentry>
      <dlentry>
        <dt>sdc:id()</dt>
        <dd>Returns the <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> ID.
            <p>For a pipeline that runs in standalone execution mode, the ID is a unique identifier
            associated with the <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>,
            such as 58efbb7c-faf4-4d8e-a056-f38667e325d0. The ID is stored in the following file:
              <filepath>$SDC_DATA/sdc.id</filepath>.</p><p>For a pipeline that runs in cluster mode,
            the ID is the <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
            worker partition ID generated by a cluster application, such as Spark or
          MapReduce.</p></dd>
      </dlentry>
      <dlentry>
        <dt>uuid:uuid()</dt>
        <dd>Returns a randomly generated UUID. For example, you might use the function in an
          Expression Evaluator processor to generate a UUID for an ID field added to each
          record.</dd>
        <dd>Return type: String.</dd>
      </dlentry>
      <dlentry>
        <dt>vault:read(&lt;path>, &lt;key>)</dt>
        <dd>Returns the value for the key on the specified path. You can use the function in <ph
            conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/ph-VaultOneFunction-Usage"
            /><note type="important">This function is now deprecated and will be removed in a future
            release. We recommend using the <xref
              href="CredentialFunctions.dita#concept_yvc_3qs_r1b">credential functions</xref>
            available with the Vault <xref
              href="../Configuration/CredentialStores.dita#concept_bt1_bpj_r1b">credential
              store</xref> integration in pipelines that include JDBC stages.</note></dd>
        <dd>Return type: String.</dd>
        <dd>Uses the following arguments:<ul id="ul_yd1_4gc_mw">
            <li>path - The path in Vault to read.</li>
            <li>key - The key for the value that you want returned.</li>
          </ul></dd>
      </dlentry>
      <dlentry>
        <dt>vault:readWithDelay(&lt;path>, &lt;key>, &lt;delay>)</dt>
        <dd>Returns the value for the key on the specified path after waiting the specified amount
          of time. Use when you want a delayed response to allow time for external processing. <note
            type="important">This function is now deprecated and will be removed in a future
            release. We recommend using the <xref
              href="CredentialFunctions.dita#concept_yvc_3qs_r1b">credential functions</xref>
            available with the Vault <xref
              href="../Configuration/CredentialStores.dita#concept_bt1_bpj_r1b">credential
              store</xref> integration in pipelines that include JDBC stages.</note><p>You can use
            the function in <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/ph-VaultOneFunction-Usage"
            /></p></dd>
        <dd>Return type: String.</dd>
        <dd>Uses the following arguments:<ul id="ul_cc4_rgc_mw">
            <li>path - The path in Vault to read.</li>
            <li>key - The key for the value that you want returned.</li>
            <li>delay - Milliseconds to wait before returning the value.</li>
          </ul></dd>
      </dlentry>
  </dl>
 </conbody>
</concept>
