<?xml version="1.0" encoding="UTF-8"?>
<!--

    Copyright 2017 StreamSets Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_yfx_mhx_4y">
 <title>Offset Column and Value</title>
 <shortdesc>The JDBC Multitable Consumer origin uses an offset column and initial offset value to
        determine where to start reading data within tables and partitions.</shortdesc>
 <conbody>
        <p><indexterm>JDBC Multitable Consumer origin<indexterm>offset column and
                value</indexterm></indexterm><indexterm>offset column and value<indexterm>JDBC
                    Multitable Consumer</indexterm></indexterm>By default, the origin uses the
            primary key of the tables as the offset column and uses no initial offset value. When
            you use multithreaded table processing and the table has a composite primary key, the
            origin uses each primary key as an offset column. You cannot use composite keys with
            multithreaded partition processing. </p>
        <p>By default, the origin reads all available data from each table when you start the
            pipeline. The origin generates SQL queries using the following syntax when you start the
            pipeline:<codeblock>SELECT * FROM &lt;table> ORDER BY &lt;offset column_1>, &lt;offset column_2>, ...</codeblock></p>
        <p>Where <codeph>&lt;offset column_<i>n</i>></codeph> represents each primary key of the
            table, such as when the table has a composite primary key. When you restart the pipeline
            or when the origin switches back to a previously read table, the origin adds a WHERE
            clause to the SQL query to continue reading from the last saved offset.</p>
        <p>To use this default behavior, you do not need to configure any of the offset
            properties.</p>
        <p>You can make the following changes to how the origin handles offset columns and initial
            offset values:<dl>
                <dlentry>
                    <dt>Override the primary key as the offset column</dt>
                    <dd>You can override the primary key and define another offset column or
                        columns. Or if the table doesnâ€™t have a primary key, you can define the
                        offset column or columns to use. </dd>
                    <dd>
                        <note type="important">As a best practice, a user-defined offset column
                            should be an incremental and unique column. If the column is not unique
                            - that is, multiple rows can have the same value for this column - there
                            is a potential for data loss upon pipeline restart. For details, see
                                <xref
                                href="MultiTableJDBCConsumer-MultiOffsetHandling.dita#concept_d52_4l1_q1b"
                            />. </note>
                    </dd>
                    <dd>Having an index on this column is strongly encouraged since the underlying
                        query uses an ORDER BY and inequality operators on this column.</dd>
                </dlentry>
                <dlentry>
                    <dt>Define an initial offset value</dt>
                    <dd>The initial offset value is a value within the offset column where you want
                        JDBC Multitable Consumer to start reading. When you define an initial offset
                        value, you must first enter the offset column name and then the value. If
                        you are using the default primary key as the offset column, enter the name
                        of the primary key.</dd>
                    <dd>If you define an initial offset value for a single offset column, the origin
                        generates SQL queries using the following
                        syntax:<codeblock>SELECT * FROM &lt;table> ORDER BY &lt;offset column> WHERE &lt;offset column> > ${offset}</codeblock></dd>
                    <dd>If you defined multiple offset columns, you must define an initial offset
                        value for each column, in the same order that the columns are defined. The
                        origin uses the initial offset values of all columns to determine where to
                        start reading data. For example, you override the primary key with the
                        following offset columns: p1, p2, p3 and define an initial offset value for
                        each column. The origin generates SQL queries using the following syntax:<codeblock>SELECT * FROM &lt;table> ORDER BY p1, p2, p3 WHERE (p1 > ${offset1}) OR (p1 = ${offset1} AND p2 > ${offset2}) OR (p1 = ${offset1} AND p2 = ${offset2} AND p3 > ${offset3})</codeblock><p>
                            <note><ph
                                    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"
                                /> stores offsets for Datetime columns as Long values. For offset
                                columns with a Datetime data type, enter the initial value as a Long
                                value. You can use the time functions to transform a Datetime value
                                to a Long value. For example, the following expression converts a
                                date entered as a String to a Date object, and then to a Long value:<p>
                                    <codeblock>${time:dateTimeToMilliseconds(time:extractDateFromString('2017-05-01 20:15:30.915','yyyy-MM-dd HH:mm:ss.SSS'))} </codeblock>
                                </p></note>
                        </p></dd>
                </dlentry>
                <dlentry>
                    <dt>Define additional offset column conditions</dt>
                    <dd>You can use the expression language to define additional conditions that the
                        origin uses to determine where to start reading data. The origin adds the
                        defined condition to the WHERE clause of the SQL query.</dd>
                    <dd>You can use the offset:column function in the condition to access an offset
                        column by position. For example, if you have a table with offset columns p1
                        and p2, then offset:column(0) returns the value of p1 while offset:column(1)
                        returns the value of p2.</dd>
                    <dd>Let's say that you defined a transaction_time column as the offset column.
                        While the origin reads the table, multiple active transactions are being
                        written to the table with the current timestamp for the transaction_time
                        column. When the origin finishes reading the first record with the current
                        timestamp, the origin continues reading with the next offset and skips some
                        rows with the current timestamp. You can enter the following offset column
                        condition to ensure that the origin reads from all offset columns with a
                        timestamp less than the current
                        time:<codeblock>${offset:column(0)} &lt; ${time:now()}</codeblock></dd>
                    <dd>If your database requires the datetime in a specific format, you can use the
                            <ph>time:extractStringFromDate</ph> function to specify the format. For
                        example:
                        <pre>${offset:column(0)} &lt; '${time:extractStringFromDate(time:now(), "yyyy-MM-dd HH:mm:ss")}'</pre></dd>
                </dlentry>
            </dl></p>
    </conbody>
</concept>
